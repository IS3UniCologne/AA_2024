{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "In this workshop we provide a very short introduction to neural networks in Python. This is very far from a comprehensive coverage of the topic but can provide a quick start for those who wish to learn more about the topic in their own time. We will cover a classification and a regression taks using `keras` as our python package of choice. If you want to try and implement a NN from scratch there are several good online tutorials that can help you do so (see [here](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6) for example). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological inspiration\n",
    "The (for our purpose) smallest stand-alone element in the human brain is the neuron. Its understanding and computational recreation build the foundation for ANNs. A simplified image of a \"real\" neuron can be seen below\n",
    "\n",
    "![](bio_neuron.png)\n",
    "\n",
    "Dendrites are connecting to the axons (or \"outputs\") of other neurons, for instance nerves in the sensory system or other processing neurons. In the nucleus, these input signals are aggregated and forwarded through the axon. The axon terminals then connect to further neurons to build the neural network. The connection between axon terminal and dendrite is what we are calling a synapse. In the human brain, there are billions of neurons and $10^{14} - 10^{15}$ synapses in the human brain. If each synapse (or more precisely, its connection strength) would be represented by 8 bits or one byte, just storing these numbers would take 1000 TB already. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational implementation\n",
    "To recreate neural networks artificially, neurons have to be defined. The common mathematical model used for this purpose is depicted below.\n",
    "\n",
    "![](math_neuron.jpeg)\n",
    "\n",
    "From a certain number of input synapses $x_i$, signals come in with a weight factor of $w_i$. This represents the strength of the synapse. In the _nuclues_ these weighted inputs are aggregated and a bias is added. (The bias is not shown in every model, but it does make the neural network more generalizable). After adding of the weighted inputs and the bias, everything is fed into a (non-linear) activation function. The output is then either fed forward to further neurons or is the output of your neural network. If there is only one neuron that takes direct inputs and whose output is your interest, the model is called a single-layer perceptron. Many of these neurons can create almost arbitrary logical connections and functions, making ANNs very powerful. In this case, we are talking about a multi-layer perceptron (MLP) model. \n",
    "\n",
    "![](mlp-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "The activation function is (to some degree) the hear of the neural network. Without a non-linear activation function, all hidden layers do not add any value, but are instead a complicated way to represent a liner model. Only with a non-linear activation function, ANNs can recreate non-linear hypothesis functions. In the beginning of research on the ANNs in the scope of AI, typically a unit step was used as activation function. The unit step is $0$ for inputs smaller than $0$ and $1$ otherwise. The idea behind this is to recreate the behavior of a biological neuron that _fires_ if a certain threshold of inputs is exceeded. Today, other activation functions are more typically used. This is linked to better mathematical qualities in terms of learning behavior and convergence. Some of the most popular activation functions are:\n",
    "\n",
    "Sigmoid: $\\sigma(z) = \\frac{1}{1+exp(-z)}$\n",
    "\n",
    "Hyperbolic tangent: $\\sigma(z) = \\frac{2}{1+exp(-2z)} -1 $\n",
    "\n",
    "ReLU (Rectified Linear Unit): $\\sigma(z) = z\\quad  for\\ z>0,\\ 0\\ otherwise$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "As learning of ANNs is a non-trivial mathematical task, we are only aiming for an intuitive understanding here. Let's have a look at our complete MLP first.\n",
    "\n",
    "The general learning tasks consists of two steps, which are repeated until the algorithm converges:\n",
    "1. __Feedforward: Calculating the predicted output Å· and the associated loss__. At first, we randomly assign values for the weights (and the biases). Based on the input features, the output value is calculated.\n",
    "2. __Backpropagation: Updating the weights W and biases b__. If the output value and the target value differ, the weights and biases are updated. To do this, it is calculated how much each weight and bias contributes to the error. Proportionally to this, they are then corrected (scaled with a small learning factor). In this sense, the updating rule has some similarity to gradient descent, only that is is propagated through the entire network, which is why this algorithm is called backpropagation.\n",
    "\n",
    "The training routine for a simple 2-layered MLP is shown in the below figure:\n",
    "\n",
    "![](training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "The main hyperparameters of an MLP are: \n",
    "\n",
    "1. Number of hidden layers\n",
    "1. Number of nodes\n",
    "4. Activation function\n",
    "\n",
    "The number of hidden layers and number of nodes (its activation function could be understood as a hyperparameter, but that is typically not done). The more layers and nodes there are (and the denser the network is, i.e. the more edges have a non-zero weight) the harder it gets to learn the model. That's the reason why bigger ANNs are normally not trained on a local computer anymore, but on specialized computers. Furthermore, there are additional libraries for python to improve the efficiency of ANNs, e.g. TensorFlow or Keras, which we take a first look at in today's tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras` is one of the most popular Deep Learning libraries. `PyTorch`, `PyTorch` and `Jax` are the most used numerical platforms in Python to build Deep Learning algorithms but they can be quite complex and difficult to use.\n",
    "\n",
    "Keras, by contrast is easy to use and is capable of running on top of multiple low-level tensor operation frameworks. The full documentation of the keras API can be found [here](https://keras.io).\n",
    "\n",
    "Note that `scikit learn` also features an MLP implementation (see [here](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)). Yet, `keras` has advanced to be one of the most popular frameworks used in practice, which is why we focus on it in this short tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `Keras` to command `PyTorch`, therefore we need to install both.\n",
    "PyTorch's installation method varies by platform and environment manager, all of the options are listed here: https://pytorch.org/get-started/locally/\n",
    "\n",
    "If you use the provided `environment.yml` specification, you can just recreate your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for classification in `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stay with our example, we will build a NN that predicts the class of a breast cancer by categorizing it as either malignant or begnign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# supress versioning warnings of keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because keras can work with multiple different backends, it is important to specify that we want to use PyTorch before importing keras for the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential # sequential model: https://keras.io/guides/sequential_model/\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Preparation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                       \n",
       "842302         M        17.99         10.38           122.8     1001.0   \n",
       "842517         M        20.57         17.77           132.9     1326.0   \n",
       "\n",
       "        smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                          \n",
       "842302          0.11840           0.27760          0.3001   \n",
       "842517          0.08474           0.07864          0.0869   \n",
       "\n",
       "        concave points_mean  symmetry_mean  ...  radius_worst  texture_worst  \\\n",
       "id                                          ...                                \n",
       "842302              0.14710         0.2419  ...         25.38          17.33   \n",
       "842517              0.07017         0.1812  ...         24.99          23.41   \n",
       "\n",
       "        perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                         \n",
       "842302            184.6      2019.0            0.1622             0.6656   \n",
       "842517            158.8      1956.0            0.1238             0.1866   \n",
       "\n",
       "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                              \n",
       "842302           0.7119                0.2654          0.4601   \n",
       "842517           0.2416                0.1860          0.2750   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "id                               \n",
       "842302                  0.11890  \n",
       "842517                  0.08902  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "cancer_df = pd.read_csv(\"../data/breast_cancer.csv\", index_col = \"id\")\n",
    "cancer_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and Y\n",
    "X = cancer_df.iloc[:,1:31] # include full feature vector\n",
    "y = cancer_df[\"diagnosis\"]\n",
    "\n",
    "\n",
    "# encode categorical target verctor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initializing and Training the ANN__\n",
    "\n",
    "We start by defining the type of model we want to build. There are two types of models available in Keras: the [Sequential model](https://keras.io/models/sequential/) and the Model class used with [functional API](https://keras.io/models/model/). Then we simply add the input-, 2 hidden- and output-layers.\n",
    "\n",
    "Between them, we are using [dropout](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer) to prevent overfitting (dropout rate should be between 20% and 50%).\n",
    "\n",
    "![](dropout.png)\n",
    "\n",
    "At every layer, we use âDenseâ which means that the nodes are fully connected.\n",
    "\n",
    "The input-layer takes 30 inputs (because our feature vector includes 30 features) as input and outputs it with a shape of 16, which is the number of nodes in the first hidden layer that we define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pass the following parameters:\n",
    "\n",
    "- input_shape - number of columns of the dataset (only for input layer)\n",
    "\n",
    "- units - number of neurons and dimensionality of outputs to be fed to the next layer, if any\n",
    "\n",
    "- activation - activation function which is ReLU in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the input layer and the first hidden layer (with 30 nodes)\n",
    "classifier.add(Dense(input_shape = (30,), \n",
    "                     units=30,          #dimensionality of the output space (#nodes in the first hidden layer)\n",
    "                     activation='relu'))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an additional second layer, also with 15 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units= 15,\n",
    "                     activation='relu'))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the output layer. Since we perform a binary classification, a single output node suffices. We use a sigmoidal activation function for this last node which is often used when dealing with binary classfication problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units= 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compile the model to configure it for training. We add the following parameters:\n",
    "- `optimizer`: Here we use the adam optimizer, an optimizer with higher performance in many cases than stochastic gradient descent (SGD). See [here](https://keras.io/optimizers/) for a list of all optimzers implemented in `keras`.\n",
    "- `loss`: specifies the loss to be minimized. In this example we use binary crossentropy, a common loss for binary classification tasks. See [here](https://keras.io/losses/) for an overview of available losses in keras \n",
    "- `metrics`:  metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model and merely function as indicator of model performance to the data scientist. An overview ov available metrics can be found [here](https://keras.io/metrics/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer=\"adam\",    # Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments\n",
    "              loss=\"binary_crossentropy\",  # this is a good loss for binary classification\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ³âââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape              </span>â<span style=\"font-weight: bold\">    Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                â        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                â        <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 â         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ´âââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ³âââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dense (\u001b[38;5;33mDense\u001b[0m)                   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                â        \u001b[38;5;34m930\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dropout (\u001b[38;5;33mDropout\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                â          \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                â        \u001b[38;5;34m465\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                â          \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 â         \u001b[38;5;34m16\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ´âââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to train our model. We do this with a batch_size of 50 and for 100 epochs.\n",
    "\n",
    "- `batch_size` defines the number of samples that will be propagated through the network \n",
    "- `epoch` defines the number of iteration over the entire training data\n",
    "\n",
    "In general a larger batch-size results in faster training, but does not always converge fast. A smaller batch-size is slower in training but it can converge faster. This is definitely problem dependent and you need to try out a few different values (the standard batch-size is 32). The same goes for the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5913 - loss: 0.5998 \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.5146\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.3836\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.3443\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.2755\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2447\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.2087\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.2051\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1761\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.1473\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.1344\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1262\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1125\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.1180\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1215\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.1008\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0790\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1275\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0764\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0867\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0829\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.0700\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0646\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0712\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0778\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0713\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0618\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0615\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9837 - loss: 0.0618\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0545\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0627\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0607\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0648\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0486\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0413\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0573\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0439\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0457\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0531\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0582\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0428\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0422\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0495\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0448\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0303\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0330\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0400\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0499\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0402\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0511\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.0576\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0324\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0369\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0244\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0228\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0379\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0326\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0371\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0384\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0290\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0374\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0246\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0242\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0248\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0316 \n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0224\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0305\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0401\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0262\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0253\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0192\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0269\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0256\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0237\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0277\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0233\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0240\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0152\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0184\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0195\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0227\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0182\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0293\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0139\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0188\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0188\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0218\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0165\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0275\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0212\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0226\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0163\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0087\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0155\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0095\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0097\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0179\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0140\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17c28a290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Confusion Matrix\n",
      "[[105   3]\n",
      " [  1  62]]\n",
      "\n",
      "Accuracy\n",
      "0.9766\n",
      "\n",
      "Precision\n",
      "0.9538\n"
     ]
    }
   ],
   "source": [
    "# Report classification performance on test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "accuracy_score = accuracy_score(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "precision_score = precision_score(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "print(\"Accuracy\")\n",
    "print(round(accuracy_score, ndigits=4))\n",
    "print()\n",
    "print(\"Precision\")\n",
    "print(round(precision_score, ndigits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for regression in `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can also be trained for regression tasks. The logic is exactly the same, yet some of the parameters, such as loss, metrics, input and ouput as well as typical activation functions might have to be adapted to the specific case. There are a range of very good tutorial online which we encourage you to take a look at (for example [here](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)). \n",
    "\n",
    "We will cover a simple implimentation on the `Diamonds` dataset. The objective in this task is to predict the price of a particular dimond based on different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35235</th>\n",
       "      <td>0.39</td>\n",
       "      <td>Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>894</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31394</th>\n",
       "      <td>0.38</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>764</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.68</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36694</th>\n",
       "      <td>0.39</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>952</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9604</th>\n",
       "      <td>1.02</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4633</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.41</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22442</th>\n",
       "      <td>1.35</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>60.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10471</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "35235   0.39       Good     G    VVS2   63.4   57.0    894  4.62  4.65  2.94\n",
       "31394   0.38  Very Good     G     VS1   62.0   57.0    764  4.65  4.68  2.89\n",
       "36694   0.39      Ideal     G    VVS2   62.0   54.5    952  4.67  4.70  2.91\n",
       "9604    1.02       Good     D     SI2   63.4   59.0   4633  6.37  6.41  4.05\n",
       "22442   1.35      Ideal     G     VS1   60.9   54.0  10471  7.18  7.15  4.36"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "sns.heatmap(diamonds.isna(), ax=ax,\n",
    "           vmin=0, vmax=1, cmap=\"Reds\",\n",
    "           cbar_kws={\"ticks\":[0,1]})\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Show Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy variables\n",
    "\n",
    "Since in the diamond dataset we have three categorical input features, we need to convert them into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_I1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46082</th>\n",
       "      <td>0.50</td>\n",
       "      <td>62.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1738</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>3.16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52851</th>\n",
       "      <td>0.67</td>\n",
       "      <td>62.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2577</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42057</th>\n",
       "      <td>0.56</td>\n",
       "      <td>62.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1270</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.31</td>\n",
       "      <td>3.30</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30348</th>\n",
       "      <td>0.37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>728</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.57</td>\n",
       "      <td>2.91</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52625</th>\n",
       "      <td>0.33</td>\n",
       "      <td>60.7</td>\n",
       "      <td>55.0</td>\n",
       "      <td>551</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.73</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table  price     x     y     z  cut_Ideal  cut_Premium  \\\n",
       "46082   0.50   62.6   59.0   1738  5.03  5.06  3.16      False        False   \n",
       "52851   0.67   62.4   55.0   2577  5.60  5.62  3.50       True        False   \n",
       "42057   0.56   62.3   53.0   1270  5.28  5.31  3.30       True        False   \n",
       "30348   0.37   64.0   55.0    728  4.52  4.57  2.91      False        False   \n",
       "52625   0.33   60.7   55.0    551  4.48  4.51  2.73       True        False   \n",
       "\n",
       "       cut_Very Good  ...  color_I  color_J  clarity_IF  clarity_VVS1  \\\n",
       "46082           True  ...    False    False       False         False   \n",
       "52851          False  ...    False    False       False          True   \n",
       "42057          False  ...    False    False       False         False   \n",
       "30348           True  ...    False    False       False         False   \n",
       "52625          False  ...    False    False       False         False   \n",
       "\n",
       "       clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \\\n",
       "46082         False         True        False        False        False   \n",
       "52851         False        False        False        False        False   \n",
       "42057         False        False        False         True        False   \n",
       "30348         False        False         True        False        False   \n",
       "52625         False        False         True        False        False   \n",
       "\n",
       "       clarity_I1  \n",
       "46082       False  \n",
       "52851       False  \n",
       "42057       False  \n",
       "30348       False  \n",
       "52625       False  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.get_dummies(diamonds)\n",
    "diamonds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs and output\n",
    "\n",
    "X = diamonds.drop(\"price\", axis=1)\n",
    "y = diamonds[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing training data\n",
    "\n",
    "st_scaler = StandardScaler()\n",
    "st_scaler.fit(X_train)\n",
    "X_train_scaled = st_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [Dense(36, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "    Dense(36, activation=\"relu\"),\n",
    "     Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "\n",
    "model.compile(loss='mse',\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"mae\", \"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ³âââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape              </span>â<span style=\"font-weight: bold\">    Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                â        <span style=\"color: #00af00; text-decoration-color: #00af00\">972</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                â      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,332</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 â         <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ´âââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ³âââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                â        \u001b[38;5;34m972\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                â      \u001b[38;5;34m1,332\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼âââââââââââââ¤\n",
       "â dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 â         \u001b[38;5;34m37\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ´âââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,341</span> (9.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,341\u001b[0m (9.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,341</span> (9.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,341\u001b[0m (9.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 27882592.0000 - mae: 3625.4453 - mse: 27882592.0000 - val_loss: 3777669.7500 - val_mae: 1295.5267 - val_mse: 3777669.7500\n",
      "Epoch 2/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2974550.5000 - mae: 1056.9423 - mse: 2974550.5000 - val_loss: 1259414.2500 - val_mae: 682.8646 - val_mse: 1259414.2500\n",
      "Epoch 3/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1470991.2500 - mae: 655.5848 - mse: 1470991.2500 - val_loss: 989482.4375 - val_mae: 606.5842 - val_mse: 989482.4375\n",
      "Epoch 4/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1073389.5000 - mae: 612.3300 - mse: 1073389.5000 - val_loss: 915435.2500 - val_mae: 577.7256 - val_mse: 915435.2500\n",
      "Epoch 5/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1100756.6250 - mae: 586.2534 - mse: 1100756.6250 - val_loss: 868910.5625 - val_mae: 555.1326 - val_mse: 868910.5625\n",
      "Epoch 6/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 763432.4375 - mae: 551.1021 - mse: 763432.4375 - val_loss: 840401.2500 - val_mae: 527.6292 - val_mse: 840401.2500\n",
      "Epoch 7/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 979054.0625 - mae: 540.4777 - mse: 979054.0625 - val_loss: 797183.9375 - val_mae: 511.3132 - val_mse: 797183.9375\n",
      "Epoch 8/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 954667.0000 - mae: 520.4095 - mse: 954667.0000 - val_loss: 768453.0625 - val_mae: 492.6441 - val_mse: 768453.0625\n",
      "Epoch 9/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 841799.5625 - mae: 499.4899 - mse: 841799.5625 - val_loss: 747908.0625 - val_mae: 478.8638 - val_mse: 747908.0625\n",
      "Epoch 10/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 804522.6250 - mae: 488.7465 - mse: 804522.6250 - val_loss: 719213.2500 - val_mae: 467.4925 - val_mse: 719213.2500\n",
      "Epoch 11/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 776682.6250 - mae: 475.5320 - mse: 776682.6250 - val_loss: 698013.4375 - val_mae: 453.5007 - val_mse: 698013.4375\n",
      "Epoch 12/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 756017.5000 - mae: 460.0625 - mse: 756017.5000 - val_loss: 702627.5000 - val_mae: 450.0627 - val_mse: 702627.5000\n",
      "Epoch 13/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 705733.1250 - mae: 452.9684 - mse: 705733.1250 - val_loss: 661208.0625 - val_mae: 434.2850 - val_mse: 661208.0625\n",
      "Epoch 14/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 772656.0625 - mae: 438.6325 - mse: 772656.0625 - val_loss: 646012.1875 - val_mae: 427.2712 - val_mse: 646012.1875\n",
      "Epoch 15/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627036.8750 - mae: 429.7557 - mse: 627036.8750 - val_loss: 630614.1875 - val_mae: 418.6808 - val_mse: 630614.1875\n",
      "Epoch 16/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 683867.1875 - mae: 422.2558 - mse: 683867.1875 - val_loss: 617287.3125 - val_mae: 411.3830 - val_mse: 617287.3125\n",
      "Epoch 17/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638128.1250 - mae: 410.2570 - mse: 638128.1250 - val_loss: 602723.3125 - val_mae: 405.0844 - val_mse: 602723.3125\n",
      "Epoch 18/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 583177.1250 - mae: 409.2721 - mse: 583177.1250 - val_loss: 591808.6875 - val_mae: 398.8679 - val_mse: 591808.6875\n",
      "Epoch 19/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635361.7500 - mae: 399.9141 - mse: 635361.7500 - val_loss: 580181.1250 - val_mae: 394.3736 - val_mse: 580181.1250\n",
      "Epoch 20/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 540662.9375 - mae: 399.5081 - mse: 540662.9375 - val_loss: 578829.6875 - val_mae: 392.3174 - val_mse: 578829.6875\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train.values,\n",
    "                   epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2591.8696],\n",
       "       [ 5101.0566],\n",
       "       [10923.248 ],\n",
       "       [ 1527.0719],\n",
       "       [ 6691.058 ],\n",
       "       [ 3455.574 ],\n",
       "       [ 6319.823 ],\n",
       "       [ 1091.8385],\n",
       "       [ 4158.49  ],\n",
       "       [ 9664.818 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.900884e+07</td>\n",
       "      <td>2847.190918</td>\n",
       "      <td>1.900884e+07</td>\n",
       "      <td>3.777670e+06</td>\n",
       "      <td>1295.526733</td>\n",
       "      <td>3.777670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.112673e+06</td>\n",
       "      <td>898.090881</td>\n",
       "      <td>2.112673e+06</td>\n",
       "      <td>1.259414e+06</td>\n",
       "      <td>682.864624</td>\n",
       "      <td>1.259414e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.235172e+06</td>\n",
       "      <td>639.181885</td>\n",
       "      <td>1.235172e+06</td>\n",
       "      <td>9.894824e+05</td>\n",
       "      <td>606.584167</td>\n",
       "      <td>9.894824e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.105440e+06</td>\n",
       "      <td>601.056519</td>\n",
       "      <td>1.105440e+06</td>\n",
       "      <td>9.154352e+05</td>\n",
       "      <td>577.725586</td>\n",
       "      <td>9.154352e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043516e+06</td>\n",
       "      <td>577.251221</td>\n",
       "      <td>1.043516e+06</td>\n",
       "      <td>8.689106e+05</td>\n",
       "      <td>555.132568</td>\n",
       "      <td>8.689106e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.928236e+05</td>\n",
       "      <td>553.581116</td>\n",
       "      <td>9.928236e+05</td>\n",
       "      <td>8.404012e+05</td>\n",
       "      <td>527.629211</td>\n",
       "      <td>8.404012e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.469386e+05</td>\n",
       "      <td>529.720947</td>\n",
       "      <td>9.469386e+05</td>\n",
       "      <td>7.971839e+05</td>\n",
       "      <td>511.313202</td>\n",
       "      <td>7.971839e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.087519e+05</td>\n",
       "      <td>512.429138</td>\n",
       "      <td>9.087519e+05</td>\n",
       "      <td>7.684531e+05</td>\n",
       "      <td>492.644073</td>\n",
       "      <td>7.684531e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.759296e+05</td>\n",
       "      <td>496.009857</td>\n",
       "      <td>8.759296e+05</td>\n",
       "      <td>7.479081e+05</td>\n",
       "      <td>478.863800</td>\n",
       "      <td>7.479081e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.429551e+05</td>\n",
       "      <td>480.892822</td>\n",
       "      <td>8.429551e+05</td>\n",
       "      <td>7.192132e+05</td>\n",
       "      <td>467.492523</td>\n",
       "      <td>7.192132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.149738e+05</td>\n",
       "      <td>468.389832</td>\n",
       "      <td>8.149738e+05</td>\n",
       "      <td>6.980134e+05</td>\n",
       "      <td>453.500732</td>\n",
       "      <td>6.980134e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.874948e+05</td>\n",
       "      <td>455.240753</td>\n",
       "      <td>7.874948e+05</td>\n",
       "      <td>7.026275e+05</td>\n",
       "      <td>450.062714</td>\n",
       "      <td>7.026275e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.648482e+05</td>\n",
       "      <td>446.506897</td>\n",
       "      <td>7.648482e+05</td>\n",
       "      <td>6.612081e+05</td>\n",
       "      <td>434.285004</td>\n",
       "      <td>6.612081e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.415375e+05</td>\n",
       "      <td>436.223724</td>\n",
       "      <td>7.415375e+05</td>\n",
       "      <td>6.460122e+05</td>\n",
       "      <td>427.271240</td>\n",
       "      <td>6.460122e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.209482e+05</td>\n",
       "      <td>428.840088</td>\n",
       "      <td>7.209482e+05</td>\n",
       "      <td>6.306142e+05</td>\n",
       "      <td>418.680786</td>\n",
       "      <td>6.306142e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.028751e+05</td>\n",
       "      <td>420.467957</td>\n",
       "      <td>7.028751e+05</td>\n",
       "      <td>6.172873e+05</td>\n",
       "      <td>411.383026</td>\n",
       "      <td>6.172873e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.850006e+05</td>\n",
       "      <td>413.585388</td>\n",
       "      <td>6.850006e+05</td>\n",
       "      <td>6.027233e+05</td>\n",
       "      <td>405.084381</td>\n",
       "      <td>6.027233e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.689462e+05</td>\n",
       "      <td>407.577057</td>\n",
       "      <td>6.689462e+05</td>\n",
       "      <td>5.918087e+05</td>\n",
       "      <td>398.867859</td>\n",
       "      <td>5.918087e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.528562e+05</td>\n",
       "      <td>402.540527</td>\n",
       "      <td>6.528562e+05</td>\n",
       "      <td>5.801811e+05</td>\n",
       "      <td>394.373596</td>\n",
       "      <td>5.801811e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.388614e+05</td>\n",
       "      <td>397.278473</td>\n",
       "      <td>6.388614e+05</td>\n",
       "      <td>5.788297e+05</td>\n",
       "      <td>392.317444</td>\n",
       "      <td>5.788297e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss          mae           mse      val_loss      val_mae  \\\n",
       "0   1.900884e+07  2847.190918  1.900884e+07  3.777670e+06  1295.526733   \n",
       "1   2.112673e+06   898.090881  2.112673e+06  1.259414e+06   682.864624   \n",
       "2   1.235172e+06   639.181885  1.235172e+06  9.894824e+05   606.584167   \n",
       "3   1.105440e+06   601.056519  1.105440e+06  9.154352e+05   577.725586   \n",
       "4   1.043516e+06   577.251221  1.043516e+06  8.689106e+05   555.132568   \n",
       "5   9.928236e+05   553.581116  9.928236e+05  8.404012e+05   527.629211   \n",
       "6   9.469386e+05   529.720947  9.469386e+05  7.971839e+05   511.313202   \n",
       "7   9.087519e+05   512.429138  9.087519e+05  7.684531e+05   492.644073   \n",
       "8   8.759296e+05   496.009857  8.759296e+05  7.479081e+05   478.863800   \n",
       "9   8.429551e+05   480.892822  8.429551e+05  7.192132e+05   467.492523   \n",
       "10  8.149738e+05   468.389832  8.149738e+05  6.980134e+05   453.500732   \n",
       "11  7.874948e+05   455.240753  7.874948e+05  7.026275e+05   450.062714   \n",
       "12  7.648482e+05   446.506897  7.648482e+05  6.612081e+05   434.285004   \n",
       "13  7.415375e+05   436.223724  7.415375e+05  6.460122e+05   427.271240   \n",
       "14  7.209482e+05   428.840088  7.209482e+05  6.306142e+05   418.680786   \n",
       "15  7.028751e+05   420.467957  7.028751e+05  6.172873e+05   411.383026   \n",
       "16  6.850006e+05   413.585388  6.850006e+05  6.027233e+05   405.084381   \n",
       "17  6.689462e+05   407.577057  6.689462e+05  5.918087e+05   398.867859   \n",
       "18  6.528562e+05   402.540527  6.528562e+05  5.801811e+05   394.373596   \n",
       "19  6.388614e+05   397.278473  6.388614e+05  5.788297e+05   392.317444   \n",
       "\n",
       "         val_mse  \n",
       "0   3.777670e+06  \n",
       "1   1.259414e+06  \n",
       "2   9.894824e+05  \n",
       "3   9.154352e+05  \n",
       "4   8.689106e+05  \n",
       "5   8.404012e+05  \n",
       "6   7.971839e+05  \n",
       "7   7.684531e+05  \n",
       "8   7.479081e+05  \n",
       "9   7.192132e+05  \n",
       "10  6.980134e+05  \n",
       "11  7.026275e+05  \n",
       "12  6.612081e+05  \n",
       "13  6.460122e+05  \n",
       "14  6.306142e+05  \n",
       "15  6.172873e+05  \n",
       "16  6.027233e+05  \n",
       "17  5.918087e+05  \n",
       "18  5.801811e+05  \n",
       "19  5.788297e+05  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4359.913073</td>\n",
       "      <td>1943.622841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1453.503698</td>\n",
       "      <td>1122.236272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111.382697</td>\n",
       "      <td>994.727318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1051.399068</td>\n",
       "      <td>956.783805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021.526064</td>\n",
       "      <td>932.153723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>996.405320</td>\n",
       "      <td>916.734013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>973.107715</td>\n",
       "      <td>892.851576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>953.284814</td>\n",
       "      <td>876.614546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>935.911087</td>\n",
       "      <td>864.816780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>918.125876</td>\n",
       "      <td>848.064414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902.758966</td>\n",
       "      <td>835.471985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>887.409009</td>\n",
       "      <td>838.228787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>874.556030</td>\n",
       "      <td>813.147012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>861.125717</td>\n",
       "      <td>803.748834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>849.086678</td>\n",
       "      <td>794.112201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>838.376482</td>\n",
       "      <td>785.676341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>827.647645</td>\n",
       "      <td>776.352570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>817.891305</td>\n",
       "      <td>769.291029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>807.995166</td>\n",
       "      <td>761.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>799.288082</td>\n",
       "      <td>760.808575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rmse     val_rmse\n",
       "0   4359.913073  1943.622841\n",
       "1   1453.503698  1122.236272\n",
       "2   1111.382697   994.727318\n",
       "3   1051.399068   956.783805\n",
       "4   1021.526064   932.153723\n",
       "5    996.405320   916.734013\n",
       "6    973.107715   892.851576\n",
       "7    953.284814   876.614546\n",
       "8    935.911087   864.816780\n",
       "9    918.125876   848.064414\n",
       "10   902.758966   835.471985\n",
       "11   887.409009   838.228787\n",
       "12   874.556030   813.147012\n",
       "13   861.125717   803.748834\n",
       "14   849.086678   794.112201\n",
       "15   838.376482   785.676341\n",
       "16   827.647645   776.352570\n",
       "17   817.891305   769.291029\n",
       "18   807.995166   761.696216\n",
       "19   799.288082   760.808575"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_metrics_df = history_df[[\"mse\", \"val_mse\"]].apply(np.sqrt)\n",
    "root_metrics_df.rename({\"mse\":\"rmse\", \"val_mse\":\"val_rmse\"}, axis=1, inplace=True)\n",
    "root_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGyCAYAAAAFw9vDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzC0lEQVR4nO3deVyU1eIG8OdlmBlgGEYW2RJRU3FBzaUUs9xQtNyye/WmkqZp5b6V2aZ2c6vU6vrL0kxzKb3dsjILxTVNcUEpNcJ9B1GEYR+Gmff3xzAvDKDMwAzr8/183s/MvO+ZM2dM5Omc854jiKIogoiIiKgOc6rqBhARERFVNQYiIiIiqvMYiIiIiKjOYyAiIiKiOo+BiIiIiOo8BiIiIiKq8xiIiIiIqM5jICIiIqI6j4GIiIiI6jznqm5ATWE0GnHr1i2o1WoIglDVzSEiIiIriKKIjIwMBAYGwsnpAf1AYjWxaNEiEYA4bdo06dzo0aNFABZH586dLd6Xm5srTp48WfT29hbd3NzEgQMHitevX7coc+/ePXHUqFGih4eH6OHhIY4aNUpMTU21qX3Xr18v0RYePHjw4MGDR804imeD4qpFD9Hx48exevVqtG3btsS1fv36Yd26ddJrhUJhcX369OnYvn07tmzZAm9vb8yaNQsDBgxAbGwsZDIZAGDEiBG4ceMGoqKiAAATJkxAZGQktm/fbnUb1Wo1AOD69evw8PCw+TsSERFR5UtPT0dQUJD0e/x+qjwQZWZmYuTIkVizZg3ee++9EteVSiX8/f1Lfa9Wq8XatWuxceNGhIeHAwA2bdqEoKAg7N69GxEREYiPj0dUVBRiYmLQuXNnAMCaNWsQFhaGhIQEhISEWNVO8zCZh4cHAxEREVENU9Z0lyqfVD1p0iQ8/fTTUqApbv/+/fD19UXz5s0xfvx4JCcnS9diY2Oh1+vRt29f6VxgYCBCQ0Nx+PBhAMCRI0eg0WikMAQAXbp0gUajkcqURqfTIT093eIgIiKi2qlKe4i2bNmCkydP4vjx46Ve79+/P/75z38iODgYly9fxttvv41evXohNjYWSqUSSUlJUCgU8PT0tHifn58fkpKSAABJSUnw9fUtUbevr69UpjSLFy/GggULKvDtiIiIqKaoskB0/fp1TJs2Dbt27YKLi0upZYYPHy49Dw0NRadOnRAcHIwdO3Zg6NCh961bFEWLrrHSusmKlylu7ty5mDlzpvTaPAZJREREtU+VBaLY2FgkJyejY8eO0jmDwYDffvsNK1euhE6nkyZFmwUEBCA4OBjnz58HAPj7+yMvLw+pqakWvUTJycno2rWrVOb27dslPv/OnTvw8/O7b/uUSiWUSmWFviMRUV1nMBig1+uruhlUi8nl8hJ5oTyqLBD17t0bp0+ftjj3wgsvoEWLFpgzZ06pXy4lJQXXr19HQEAAAKBjx46Qy+WIjo7GsGHDAACJiYk4c+YM3n//fQBAWFgYtFotjh07hsceewwAcPToUWi1Wik0ERGRfYmiiKSkJKSlpVV1U6gOqFevHvz9/Su0TmCVBSK1Wo3Q0FCLcyqVCt7e3ggNDUVmZibmz5+PZ599FgEBAbhy5QreeOMN+Pj44JlnngEAaDQajBs3DrNmzYK3tze8vLwwe/ZstGnTRpqk3bJlS/Tr1w/jx4/H559/DsB02/2AAQOsvsOMiIhsYw5Dvr6+cHNz44K25BCiKCI7O1u64crcYVIeVX7b/f3IZDKcPn0aGzZsQFpaGgICAtCzZ09s3brVYi2BFStWwNnZGcOGDUNOTg569+6N9evXW/Qwbd68GVOnTpXuRhs0aBBWrlxZ6d+JiKguMBgMUhjy9vau6uZQLefq6grANF3G19e33MNngiiKoj0bVlulp6dDo9FAq9VyHSIiogfIzc3F5cuX0ahRI+mXFZEj5eTk4MqVK2jcuHGJG7Ws/f1d5esQERFR7cRhMqos9vi7xkBEREREdR4DERERkYP06NED06dPt7r8lStXIAgC4uLiHNYmKl21nVRNRERUWcoachk9ejTWr19vc73ff/895HK51eWDgoKQmJgIHx8fmz+LKoaBqIpl6vJxN0MHb3cF1C7W/9AQEZH9JCYmSs+3bt2Kd955BwkJCdK54pPD9Xq9VUHHy8vLpnbIZLL7bmhe1fLy8qBQKCzOiaIIg8EAZ2fb4kR53+dIHDKrYi+sO4YeH+7Hb+fuVnVTiIjqLH9/f+nQaDQQBEF6nZubi3r16uG///0vevToARcXF2zatAkpKSl47rnn0KBBA7i5uaFNmzb45ptvLOotPmTWqFEjLFq0CGPHjoVarUbDhg2xevVq6XrxIbP9+/dDEATs2bMHnTp1gpubG7p27WoR1gDgvffeg6+vL9RqNV588UW8/vrreOSRRx74nf/66y889dRTcHd3h5+fHyIjI3H3buHvoh49emDy5MmYOXMmfHx80KdPH6k9O3fuRKdOnaBUKnHw4EHodDpMnToVvr6+cHFxQbdu3Sz2Kb3f+6oTBqIq5q0ybQ+SkqWr4pYQETmGKIrIzsuvksOeK8vMmTMHU6dORXx8PCIiIpCbm4uOHTvi559/xpkzZzBhwgRERkbi6NGjD6xn2bJl6NSpE06dOoWJEyfilVdewd9///3A97z55ptYtmwZTpw4AWdnZ4wdO1a6tnnzZixcuBBLly5FbGwsGjZsiFWrVj2wvsTERHTv3h2PPPIITpw4gaioKNy+fVva9cHsq6++grOzM37//XdpcWMAeO2117B48WLEx8ejbdu2eO211/Ddd9/hq6++wsmTJ9G0aVNERETg3r17FvUVf191Un36quooH7Wp+/FuZl4Vt4SIyDFy9Aa0emdnlXz2X+9GwE1hn19106dPL7Gx+OzZs6XnU6ZMQVRUFL799lt07tz5vvU89dRTmDhxIgBTyFqxYgX279+PFi1a3Pc9CxcuRPfu3QEAr7/+Op5++mnk5ubCxcUF//nPfzBu3Di88MILAIB33nkHu3btQmZm5n3rW7VqFTp06IBFixZJ57788ksEBQXh3LlzaN68OQCgadOm0lZYgGkFcgB499130adPHwBAVlYWVq1ahfXr16N///4AgDVr1iA6Ohpr167Fq6++Kr2/6PuqG/YQVTFzD9HdTPYQERFVZ506dbJ4bTAYsHDhQrRt2xbe3t5wd3fHrl27cO3atQfWU7RnxDw0Z956wpr3mLenML8nISFB2qvTrPjr4mJjY7Fv3z64u7tLhzmQXbx4USpX/DuXdv7ixYvQ6/V4/PHHpXNyuRyPPfYY4uPj7/u+6oY9RFXMR10wZMZARES1lKtchr/ejaiyz7YXlUpl8XrZsmVYsWIFPvroI7Rp0wYqlQrTp09HXt6De/yLT8YWBAFGo9Hq95jviCv6nuJ3yZU1VGg0GjFw4EAsXbq0xLWi+4EV/86lnTd/VmltKH7ufvVVBwxEVcxHZRoyS+GQGRHVUoIg2G3Yqjo5ePAgBg8ejFGjRgEwhYzz58+jZcuWldqOkJAQHDt2DJGRkdK5EydOPPA9HTp0wHfffYdGjRpV+E6vpk2bQqFQ4NChQxgxYgQA0114J06csGkNpqrGIbMq5u3OITMiopqoadOmiI6OxuHDhxEfH4+XXnpJmmNTmaZMmYK1a9fiq6++wvnz5/Hee+/hzz//fODaSpMmTcK9e/fw3HPP4dixY7h06RJ27dqFsWPHwmAw2PT5KpUKr7zyCl599VVERUXhr7/+wvjx45GdnY1x48ZV9OtVmtoX2WsYH3f2EBER1URvv/02Ll++jIiICLi5uWHChAkYMmQItFptpbZj5MiRuHTpEmbPno3c3FwMGzYMY8aMwbFjx+77nsDAQPz++++YM2cOIiIioNPpEBwcjH79+sHJyfa+kiVLlsBoNCIyMhIZGRno1KkTdu7cCU9Pz4p8tUrF3e6t5Kjd7rU5erRbsAsA8Pe/+8HFjuPdRERVwbzbfWk7j1Pl6NOnD/z9/bFx48aqbkqleNDfOWt/f7OHqIp5uDhDIXNCnsGIlKw8PFTPtew3ERERFcjOzsZnn32GiIgIyGQyfPPNN9i9ezeio6Orumk1CucQVTFBEOAtDZtxHhEREdlGEAT88ssveOKJJ9CxY0ds374d3333HcLDw6u6aTUKe4iqAW93BRK1uZxYTURENnN1dcXu3buruhk1HnuIqgEf6U4zTqwmIiKqCgxE1QBXqyYiIqpaDETVgHk/M956T0REVDUYiKoBHxW37yAiIqpKDETVgPkuM84hIiIiqhoMRNWAD7fvICIiqlIMRNUAe4iIiGqHHj16WGxo2qhRI3z00UcPfI8gCPjhhx8q/Nn2qqeuYiCqBsw9RPeydDAauZMKEVFlGzhw4H0XMjxy5AgEQcDJkydtrvf48eOYMGFCRZtnYf78+XjkkUdKnE9MTET//v3t+ll1CQNRNeClMvUQGUUgLUdfxa0hIqp7xo0bh7179+Lq1aslrn355Zd45JFH0KFDB5vrrV+/Ptzc3OzRxDL5+/tDqVRWymfZQq8v+XuttHPlrcteGIiqAbnMCfXc5AA4j4iIqCoMGDAAvr6+WL9+vcX57OxsbN26FePGjUNKSgqee+45NGjQAG5ubmjTpg2++eabB9ZbfMjs/PnzePLJJ+Hi4oJWrVqVut/YnDlz0Lx5c7i5uaFJkyZ4++23pSCwfv16LFiwAH/88QcEQYAgCFKbiw+ZnT59Gr169YKrqyu8vb0xYcIEZGZmStfHjBmDIUOG4MMPP0RAQAC8vb0xadKkMkPH9u3b0bFjR7i4uKBJkyZYsGAB8vPzpeuCIOCzzz7D4MGDoVKp8N5770m9Wl9++SWaNGkCpVIJURRx7do1DB48GO7u7vDw8MCwYcNw+/Ztqa77vc8RuHVHNeHjrkRath53M3Vo7qeu6uYQEdmPKAL67Kr5bLkbIAhlFnN2dsbzzz+P9evX45133oFQ8J5vv/0WeXl5GDlyJLKzs9GxY0fMmTMHHh4e2LFjByIjI9GkSRN07ty5zM8wGo0YOnQofHx8EBMTg/T0dIv5RmZqtRrr169HYGAgTp8+jfHjx0OtVuO1117D8OHDcebMGURFRUnbdWg0mhJ1ZGdno1+/fujSpQuOHz+O5ORkvPjii5g8ebJF6Nu3bx8CAgKwb98+XLhwAcOHD8cjjzyC8ePHl/oddu7ciVGjRuGTTz7BE088gYsXL0pDgvPmzZPKzZs3D4sXL8aKFSsgk8mwbt06XLhwAf/973/x3XffQSaTAQCGDBkClUqFAwcOID8/HxMnTsTw4cOxf/9+qa7S3ucIDETVhLdKgQvgxGoiqoX02cCiwKr57DduAQqVVUXHjh2LDz74APv370fPnj0BmIbLhg4dCk9PT3h6emL27NlS+SlTpiAqKgrffvutVYFo9+7diI+Px5UrV9CgQQMAwKJFi0rM+3nrrbek540aNcKsWbOwdetWvPbaa3B1dYW7uzucnZ3h7+9/38/avHkzcnJysGHDBqhUpu+/cuVKDBw4EEuXLoWfnx8AwNPTEytXroRMJkOLFi3w9NNPY8+ePfcNRAsXLsTrr7+O0aNHAwCaNGmCf//733jttdcsAtGIESMwduxYi/fm5eVh48aNqF+/PgAgOjoaf/75Jy5fvoygoCAAwMaNG9G6dWscP34cjz76aKnvcxQGomrCPLGaizMSEVWNFi1aoGvXrvjyyy/Rs2dPXLx4EQcPHsSuXbsAAAaDAUuWLMHWrVtx8+ZN6HQ66HQ6KXCUJT4+Hg0bNpTCEACEhYWVKPe///0PH330ES5cuIDMzEzk5+fDw8PDpu8SHx+Pdu3aWbTt8ccfh9FoREJCghSIWrdubdHrEhAQgNOnT9+33tjYWBw/fhwLFy6UzhkMBuTm5iI7O1uaL9WpU6cS7w0ODrYINfHx8QgKCpLCEAC0atUK9erVQ3x8vBSIir/PURiIqgkfd27fQUS1lNzN1FNTVZ9tg3HjxmHy5Mn4v//7P6xbtw7BwcHo3bs3AGDZsmVYsWIFPvroI7Rp0wYqlQrTp09HXp51/26XNvdFKDacFxMTg3/9619YsGABIiIioNFosGXLFixbtsym7yGKYom6S/tMuVxe4prRaLxvvUajEQsWLMDQoUNLXHNxcZGelxYSi5+7XxuLn7c2cFYUA1E14c3FGYmothIEq4etqtqwYcMwbdo0fP311/jqq68wfvx46ZfzwYMHMXjwYIwaNQqAKRycP38eLVu2tKruVq1a4dq1a7h16xYCA01DiEeOHLEo8/vvvyM4OBhvvvmmdK74nW8KhQIGg6HMz/rqq6+QlZUlBYrff/8dTk5OaN68uVXtLU2HDh2QkJCApk2blruOom28du0arl+/LvUS/fXXX9BqtVb/mdoT7zKrJgpXq2YPERFRVXF3d8fw4cPxxhtv4NatWxgzZox0rWnTpoiOjsbhw4cRHx+Pl156CUlJSVbXHR4ejpCQEDz//PP4448/cPDgQYvgY/6Ma9euYcuWLbh48SI++eQTbNu2zaJMo0aNcPnyZcTFxeHu3bvQ6Ur+j/TIkSPh4uKC0aNH48yZM9i3bx+mTJmCyMhIabisPN555x1s2LAB8+fPx9mzZxEfH4+tW7dazHuyVnh4ONq2bYuRI0fi5MmTOHbsGJ5//nl079691CE3R2MgqibMq1WnZLGHiIioKo0bNw6pqakIDw9Hw4YNpfNvv/02OnTogIiICPTo0QP+/v4YMmSI1fU6OTlh27Zt0Ol0eOyxx/Diiy9azMUBgMGDB2PGjBmYPHkyHnnkERw+fBhvv/22RZlnn30W/fr1Q8+ePVG/fv1Sb/13c3PDzp07ce/ePTz66KP4xz/+gd69e2PlypW2/WEUExERgZ9//hnR0dF49NFH0aVLFyxfvhzBwcE212VeJsDT0xNPPvkkwsPD0aRJE2zdurVCbSwvQXTUDf21THp6OjQaDbRarc2T26wRe/Uenl11BEFerjj4Wi+7109EVFlyc3Nx+fJlNG7c2GJeCZGjPOjvnLW/v9lDVE0U3mXGITMiIqLKVm0C0eLFiyEIgsUiVaIoYv78+QgMDISrqyt69OiBs2fPWrxPp9NhypQp8PHxgUqlwqBBg3Djxg2LMqmpqYiMjIRGo4FGo0FkZCTS0tIq4VtZzzypOjvPgOy8/DJKExERkT1Vi0B0/PhxrF69Gm3btrU4//7772P58uVYuXIljh8/Dn9/f/Tp0wcZGRlSmenTp2Pbtm3YsmULDh06hMzMTAwYMMBiBv6IESMQFxeHqKgoREVFIS4uDpGRkZX2/ayhUsjgIjf952AvERERUeWq8kCUmZmJkSNHYs2aNfD09JTOi6KIjz76CG+++SaGDh2K0NBQfPXVV8jOzsbXX38NANBqtVi7di2WLVuG8PBwtG/fHps2bcLp06elJc3j4+MRFRWFL774AmFhYQgLC8OaNWvw888/IyEhoUq+c2kEQYC3irfeExERVYUqD0STJk3C008/jfDwcIvzly9fRlJSEvr27SudUyqV6N69Ow4fPgzAtGKmXq+3KBMYGIjQ0FCpzJEjR6DRaCyWVe/SpQs0Go1UpjQ6nQ7p6ekWh6OZF2fkrfdEVBvwnh2qLPb4u1algWjLli04efIkFi9eXOKaeW2H4usl+Pn5SdeSkpKgUCgsepZKK+Pr61uifl9f3weuH7F48WJpzpFGo7FYWtxRuH0HEdUG5tWPs7OraENXqnPMf9eKr7xtiypbqfr69euYNm0adu3a9cDbMosv6/2g5cjvV8aapcGLmzt3LmbOnCm9Tk9Pd3go8pZ6iBiIiKjmkslkqFevHpKTkwGY1sQp699tovIQRRHZ2dlITk5GvXr1LPZls1WVBaLY2FgkJyejY8eO0jmDwYDffvsNK1eulOb3JCUlISAgQCqTnJws9Rr5+/sjLy8PqampFr1EycnJ6Nq1q1Tm9u3bJT7/zp07D1ytU6lUQqlUVuxL2oirVRNRbWHeid0ciogcqV69etLfufKqskDUu3fvEjvqvvDCC2jRogXmzJmDJk2awN/fH9HR0Wjfvj0AIC8vDwcOHMDSpUsBAB07doRcLkd0dDSGDRsGAEhMTMSZM2fw/vvvAzDtJKzVanHs2DE89thjAICjR49Cq9VKoam6MN96n5LFQERENZsgCAgICICvry/0en1VN4dqMblcXqGeIbMqC0RqtRqhoaEW51QqFby9vaXz06dPx6JFi9CsWTM0a9YMixYtgpubG0aMGAEA0Gg0GDduHGbNmgVvb294eXlh9uzZaNOmjTRJu2XLlujXrx/Gjx+Pzz//HAAwYcIEDBgwACEhIZX4jcsmTarO4JAZEdUOMpnMLr+siBytWu92/9prryEnJwcTJ05EamoqOnfujF27dkGtVktlVqxYAWdnZwwbNgw5OTno3bs31q9fb/EDuHnzZkydOlW6G23QoEEV3s/FEaRJ1dzPjIiIqFJxLzMrOXovMwD4Oykd/T46CC+VAiff7uOQzyAiIqpLuJdZDWTuIUrNzkO+wVjFrSEiIqo7GIiqEU83BQQBEEUgNZuTEImIiCoLA1E1InMS4OXGtYiIiIgqGwNRNVO4WjVvvSciIqosDETVjHm1at5pRkREVHkYiKoZ8+KMd7gWERERUaVhIKpmfKQeIg6ZERERVRYGompG2s+MPURERESVhoGommEPERERUeVjIKpmvFXmu8zYQ0RERFRZGIiqGfNdZnd52z0REVGlYSCqZqQ5RJk6cJs5IiKiysFAVM2YA5Eu34hMXX4Vt4aIiKhuYCCqZlwVMqgUMgBcrZqIiKiyMBBVQ+bFGblaNRERUeVgIKqGzBOr72Swh4iIiKgyMBBVQz7sISIiIqpUDETVkHlxxrvsISIiIqoUDETVEHuIiIiIKhcDUTXkrSrYvoN3mREREVUKBqJqyHyX2R1u30FERFQpGIiqIWnIjIGIiIioUjAQVUM+3M+MiIioUjEQVUPmHiJtjh55+cYqbg0REVHtx0BUDWlc5ZA5CQCA1Gz2EhERETkaA1E15OQkwEtlXq2a84iIiIgcjYGomipci4g9RERERI7GQFRNmSdW804zIiIix2MgqqbMPUR3GYiIiIgcjoGomuJq1URERJWHgaia4mrVRERElYeBqJoqnEPEHiIiIiJHYyCqprjjPRERUeVhIKqmvM3bd2Swh4iIiMjRGIiqqaI9RKIoVnFriIiIarcqDUSrVq1C27Zt4eHhAQ8PD4SFheHXX3+Vro8ZMwaCIFgcXbp0sahDp9NhypQp8PHxgUqlwqBBg3Djxg2LMqmpqYiMjIRGo4FGo0FkZCTS0tIq4yuWm3mlar1BRHpOfhW3hoiIqHar0kDUoEEDLFmyBCdOnMCJEyfQq1cvDB48GGfPnpXK9OvXD4mJidLxyy+/WNQxffp0bNu2DVu2bMGhQ4eQmZmJAQMGwGAwSGVGjBiBuLg4REVFISoqCnFxcYiMjKy071keLnIZ1C7OAIC7nEdERETkUM5V+eEDBw60eL1w4UKsWrUKMTExaN26NQBAqVTC39+/1PdrtVqsXbsWGzduRHh4OABg06ZNCAoKwu7duxEREYH4+HhERUUhJiYGnTt3BgCsWbMGYWFhSEhIQEhIiAO/YcX4uCuRkZuPlMw8PFy/qltDRERUe1WbOUQGgwFbtmxBVlYWwsLCpPP79++Hr68vmjdvjvHjxyM5OVm6FhsbC71ej759+0rnAgMDERoaisOHDwMAjhw5Ao1GI4UhAOjSpQs0Go1UpjQ6nQ7p6ekWR2UzL87I1aqJiIgcq8oD0enTp+Hu7g6lUomXX34Z27ZtQ6tWrQAA/fv3x+bNm7F3714sW7YMx48fR69evaDTmQJCUlISFAoFPD09Ler08/NDUlKSVMbX17fE5/r6+kplSrN48WJpzpFGo0FQUJC9vrLVpInVDEREREQOVaVDZgAQEhKCuLg4pKWl4bvvvsPo0aNx4MABtGrVCsOHD5fKhYaGolOnTggODsaOHTswdOjQ+9YpiiIEQZBeF31+vzLFzZ07FzNnzpRep6enV3ooMt96f4eLMxIRETmUTT1E+fn5WLBgAa5fv263BigUCjRt2hSdOnXC4sWL0a5dO3z88cellg0ICEBwcDDOnz8PAPD390deXh5SU1MtyiUnJ8PPz08qc/v27RJ13blzRypTGqVSKd39Zj4qG3uIiIiIKodNgcjZ2RkffPCBxR1c9iaKojQkVlxKSgquX7+OgIAAAEDHjh0hl8sRHR0tlUlMTMSZM2fQtWtXAEBYWBi0Wi2OHTsmlTl69Ci0Wq1Uprri9h1ERESVw+Y5ROHh4di/f79dPvyNN97AwYMHceXKFZw+fRpvvvkm9u/fj5EjRyIzMxOzZ8/GkSNHcOXKFezfvx8DBw6Ej48PnnnmGQCARqPBuHHjMGvWLOzZswenTp3CqFGj0KZNG+mus5YtW6Jfv34YP348YmJiEBMTg/Hjx2PAgAHV+g4zoHCDV06qJiIiciyb5xD1798fc+fOxZkzZ9CxY0eoVCqL64MGDbK6rtu3byMyMhKJiYnQaDRo27YtoqKi0KdPH+Tk5OD06dPYsGED0tLSEBAQgJ49e2Lr1q1Qq9VSHStWrICzszOGDRuGnJwc9O7dG+vXr4dMJpPKbN68GVOnTpXuRhs0aBBWrlxp61evdIWrVbOHiIiIyJEE0cZ9IZyc7t+pJAiCQ4fTqlJ6ejo0Gg20Wm2lzSe6eCcTvZcdgFrpjNMLIirlM4mIiGoTa39/29xDZDQaK9Qwsp65hyhDl49cvQEuclkZ7yAiIqLyqPJ1iOj+PFycIZeZlga4x2EzIiIihylXIDpw4AAGDhyIpk2bolmzZhg0aBAOHjxo77bVeYIgwFvFidVERESOZnMg2rRpE8LDw+Hm5oapU6di8uTJcHV1Re/evfH11187oo11mo+at94TERE5ms1ziBYuXIj3338fM2bMkM5NmzYNy5cvx7///W+MGDHCrg2s69hDRERE5Hg29xBdunSpxC71gOlW9suXL9ulUVTIR1qLiD1EREREjmJzIAoKCsKePXtKnN+zZ0+VbIBa2xWuVs0eIiIiIkexechs1qxZmDp1KuLi4tC1a1cIgoBDhw5h/fr1992DjMrPvMErh8yIiIgcx+ZA9Morr8Df3x/Lli3Df//7XwCm7TG2bt2KwYMH272BdR1XqyYiInI8mwJRfn4+Fi5ciLFjx+LQoUOOahMV4c05RERERA5X7Xa7J0veKg6ZEREROVqV7nZPZauvNvUQ3cvKg9Fo07ZzREREZKUq3e2eyuZV0ENkMIpIy9FLr4mIiMh+yjWpGgCWL19e4lpt3u2+qshlTqjnJkdath4pmToGIiIiIgewecjMaDTe92AYcozCeUScWE1EROQINgWi/Px8ODs748yZM45qD5Wi8E4zTqwmIiJyBJvvMgsODmZPUCWrb16LiIGIiIjIIWweMnvrrbcwd+5c3Lt3zxHtoVIUrlbNITMiIiJHsHlS9SeffIILFy4gMDAQwcHBJe4yO3nypN0aRyaFq1Wzh4iIiMgRbA5EQ4YMcUAz6EHYQ0RERORYNgeiefPmOaId9ADeKk6qJiIiciSr5xAdO3bMYjK1KFqumqzT6aTNXsm+6qtNPUQp7CEiIiJyCKsDUVhYGFJSUqTXGo0Gly5dkl6npaXhueees2/rCEBhDxHvMiMiInIMqwNR8R6h4q/vd44qzqdgP7OsPANy8rjkARERkb3ZfNv9gwiCYM/qqIBKIYPS2fSfivOIiIiI7M+ugYgcQxAE6dZ7BiIiIiL7s+kus7/++gtJSUkATMNjf//9NzIzMwEAd+/etX/rSOLjrsDNtBxOrCYiInIAmwJR7969LeYJDRgwAICpB0MURQ6ZOZA3F2ckIiJyGKsD0eXLlx3ZDiqDDxdnJCIichirA1FwcLAj20Fl4I73REREjsNJ1TWEt4o9RERERI7CQFRD1FdzcUYiIiJHYSCqIQpXq2YPERERkb0xENUQPmrzkBl7iIiIiOyNgaiGMPcQ3cvOg8HILVKIiIjsyaq7zNq3b2/1GkMnT56sUIOodJ5ucggCIIrAvaw8aU4RERERVZxVPURDhgzB4MGDMXjwYERERODixYtQKpXo0aMHevToARcXF1y8eBERERE2ffiqVavQtm1beHh4wMPDA2FhYfj111+l66IoYv78+QgMDISrqyt69OiBs2fPWtSh0+kwZcoU+Pj4QKVSYdCgQbhx44ZFmdTUVERGRkKj0UCj0SAyMhJpaWk2tbWqOcuc4OVmGjbj4oxERET2ZVUP0bx586TnL774IqZOnYp///vfJcpcv37dpg9v0KABlixZgqZNmwIAvvrqKwwePBinTp1C69at8f7772P58uVYv349mjdvjvfeew99+vRBQkIC1Go1AGD69OnYvn07tmzZAm9vb8yaNQsDBgxAbGwsZDIZAGDEiBG4ceMGoqKiAAATJkxAZGQktm/fblN7q5q3uwIpWXmcWE1ERGRvoo08PDzEc+fOlTh/7tw50cPDw9bqSvD09BS/+OIL0Wg0iv7+/uKSJUuka7m5uaJGoxE/++wzURRFMS0tTZTL5eKWLVukMjdv3hSdnJzEqKgoURRF8a+//hIBiDExMVKZI0eOiADEv//+2+p2abVaEYCo1Wor+hXL7V+fHxGD5/ws/nDqRpW1gYiIqCax9ve3zZOqXV1dcejQoRLnDx06BBcXl3IHM4PBgC1btiArKwthYWG4fPkykpKS0LdvX6mMUqlE9+7dcfjwYQBAbGws9Hq9RZnAwECEhoZKZY4cOQKNRoPOnTtLZbp06QKNRiOVKY1Op0N6errFUdV81ObVqtlDREREZE82be4KmIaoXnnlFcTGxqJLly4AgJiYGHz55Zd45513bG7A6dOnERYWhtzcXLi7u2Pbtm1o1aqVFFb8/Pwsyvv5+eHq1asAgKSkJCgUCnh6epYok5SUJJXx9fUt8bm+vr5SmdIsXrwYCxYssPn7OFLhatWcQ0RERGRPNgei119/HU2aNMHHH3+Mr7/+GgDQsmVLrF+/HsOGDbO5ASEhIYiLi0NaWhq+++47jB49GgcOHJCuF7+7TRTFMu94K16mtPJl1TN37lzMnDlTep2eno6goKAyv48jcbVqIiIix7A5EAHAsGHDyhV+SqNQKKRJ1Z06dcLx48fx8ccfY86cOQBMPTwBAQFS+eTkZKnXyN/fH3l5eUhNTbXoJUpOTkbXrl2lMrdv3y7xuXfu3CnR+1SUUqmEUlm9bm039xBxUjUREZF9lWthxrS0NHzxxRd44403cO/ePQCm9Ydu3rxZ4QaJogidTofGjRvD398f0dHR0rW8vDwcOHBACjsdO3aEXC63KJOYmIgzZ85IZcLCwqDVanHs2DGpzNGjR6HVaqUyNQV3vCciInIMm3uI/vzzT4SHh0Oj0eDKlSt48cUX4eXlhW3btuHq1avYsGGD1XW98cYb6N+/P4KCgpCRkYEtW7Zg//79iIqKgiAImD59OhYtWoRmzZqhWbNmWLRoEdzc3DBixAgAgEajwbhx4zBr1ix4e3vDy8sLs2fPRps2bRAeHg7ANJzXr18/jB8/Hp9//jkA0233AwYMQEhIiK1fv0r5uHPHeyIiIkewORDNnDkTY8aMwfvvvy+tBQQA/fv3l4KKtW7fvo3IyEgkJiZCo9Ggbdu2iIqKQp8+fQAAr732GnJycjBx4kSkpqaic+fO2LVrl8XnrlixAs7Ozhg2bBhycnLQu3dvrF+/XlqDCAA2b96MqVOnSnejDRo0CCtXrrT1q1c5n4IeopQsnVVzqYiIiMg6giiKNm2MpdFocPLkSTz88MNQq9X4448/0KRJE1y9ehUhISHIzc11VFurVHp6OjQaDbRaLTw8PKqkDdl5+Wj1zk4AwJkFEXBXlmsKGBERUZ1h7e9vm+cQubi4lLomT0JCAurXr29rdWQDN4Uz3BSmni/eaUZERGQ/NgeiwYMH491334VerwdguqX92rVreP311/Hss8/avYFkydudaxERERHZm82B6MMPP8SdO3fg6+uLnJwcdO/eHU2bNoVarcbChQsd0UYqwsedq1UTERHZm82TUDw8PHDo0CHs3bsXJ0+ehNFoRIcOHaS7usixvFXmxRkZiIiIiOzFpkCUn58PFxcXxMXFoVevXujVq5ej2kX3UV/NITMiIiJ7s2nIzNnZGcHBwTAYDI5qD5WhsIeIgYiIiMhebJ5D9NZbb2Hu3LnSCtVUuby5OCMREZHd2TyH6JNPPsGFCxcQGBiI4OBgqFQqi+snT560W+OoJB9u30FERGR3NgeiIUOGOKAZZC1zD1FKFnuIiIiI7MXmQDRv3jxHtIOsVJ89RERERHZXrt3uqeqYd7xPy9ZDbzBWcWuIiIhqB5sDkcFgwIcffojHHnsM/v7+8PLysjjIseq5yiFzMm3qeo/DZkRERHZhcyBasGABli9fjmHDhkGr1WLmzJkYOnQonJycMH/+fAc0kYpychLgpeJaRERERPZkcyDavHkz1qxZg9mzZ8PZ2RnPPfccvvjiC7zzzjuIiYlxRBupGO+CQMTVqomIiOzD5kCUlJSENm3aAADc3d2h1WoBAAMGDMCOHTvs2zoqVX01J1YTERHZk82BqEGDBkhMTAQANG3aFLt27QIAHD9+HEql0r6to1Kxh4iIiMi+bA5EzzzzDPbs2QMAmDZtGt5++200a9YMzz//PMaOHWv3BlJJ3rz1noiIyK5sXodoyZIl0vN//OMfaNCgAQ4fPoymTZti0KBBdm0cla5wtWr2EBEREdmDzYGouC5duqBLly72aAtZqXC1avYQERER2YPNgWjDhg0PvP7888+XuzFkHR933nZPRERkTzYHomnTplm81uv1yM7OhkKhgJubGwNRJTAPmXFSNRERkX3YPKk6NTXV4sjMzERCQgK6deuGb775xhFtpGK8iwQiURSruDVEREQ1n132MmvWrBmWLFlSoveIHMN8232ewYj03Pwqbg0REVHNZ7fNXWUyGW7dumWv6ugBXOQyqJWm0c4UziMiIiKqMJvnEP30008Wr0VRRGJiIlauXInHH3/cbg2jB/N2VyBDl4+7mXloUr+qW0NERFSz2RyIhgwZYvFaEATUr18fvXr1wrJly+zVLiqDj7sSV1Ky2UNERERkBzYHIqPR6Ih2kI3MaxHdzeKdZkRERBVltzlEVLmk1aoz2ENERERUUTb3EM2cOdPqssuXL7e1erKSdOs9V6smIiKqMJsD0alTp3Dy5Enk5+cjJCQEAHDu3DnIZDJ06NBBKicIgv1aSSVIq1VncMiMiIioomwORAMHDoRarcZXX30FT09PAKbFGl944QU88cQTmDVrlt0bSSX5sIeIiIjIbmyeQ7Rs2TIsXrxYCkMA4Onpiffee493mVUi8+KM3L6DiIio4mwOROnp6bh9+3aJ88nJycjIyLBLo6hsPmpTD9Ed3nZPRERUYTYHomeeeQYvvPAC/ve//+HGjRu4ceMG/ve//2HcuHEYOnSoI9pIpfBRmQJRRm4+dPmGKm4NERFRzWbzHKLPPvsMs2fPxqhRo6DX602VODtj3Lhx+OCDD+zeQCqdh6sz5DIBeoOIlMw8BNZzreomERER1Vg2ByI3Nzd8+umn+OCDD3Dx4kWIooimTZtCpVI5on10H4IgwFulRFJ6LgMRERFRBZV7YUaVSoW2bduiXr16uHr1arlWsF68eDEeffRRqNVq+Pr6YsiQIUhISLAoM2bMGAiCYHF06dLFooxOp8OUKVPg4+MDlUqFQYMG4caNGxZlUlNTERkZCY1GA41Gg8jISKSlpdnc5uqkcLVqziMiIiKqCKsD0VdffYWPPvrI4tyECRPQpEkTtGnTBqGhobh+/bpNH37gwAFMmjQJMTExiI6ORn5+Pvr27YusrCyLcv369UNiYqJ0/PLLLxbXp0+fjm3btmHLli04dOgQMjMzMWDAABgMhXNrRowYgbi4OERFRSEqKgpxcXGIjIy0qb3VDVerJiIisg+rh8w+++wzTJgwQXodFRWFdevWYcOGDWjZsiUmT56MBQsW4IsvvrD6w6Oioixer1u3Dr6+voiNjcWTTz4pnVcqlfD39y+1Dq1Wi7Vr12Ljxo0IDw8HAGzatAlBQUHYvXs3IiIiEB8fj6ioKMTExKBz584AgDVr1iAsLAwJCQnSApM1jbmHKIX7mREREVWI1T1E586dQ6dOnaTXP/74IwYNGoSRI0eiQ4cOWLRoEfbs2VOhxmi1WgCAl5eXxfn9+/fD19cXzZs3x/jx45GcnCxdi42NhV6vR9++faVzgYGBCA0NxeHDhwEAR44cgUajkcIQAHTp0gUajUYqU5xOp0N6errFUd1IizPy1nsiIqIKsToQ5eTkwMPDQ3p9+PBhi16cJk2aICkpqdwNEUURM2fORLdu3RAaGiqd79+/PzZv3oy9e/di2bJlOH78OHr16gWdzhQCkpKSoFAoLBaKBAA/Pz+pPUlJSfD19S3xmb6+vvdt8+LFi6X5RhqNBkFBQeX+bo4ibd/BxRmJiIgqxOohs+DgYMTGxiI4OBh3797F2bNn0a1bN+l6UlISNBpNuRsyefJk/Pnnnzh06JDF+eHDh0vPQ0ND0alTJwQHB2PHjh0PXPdIFEWL/dRK21uteJmi5s6da7GRbXp6erULRd4FaxHdZQ8RERFRhVgdiJ5//nlMmjQJZ8+exd69e9GiRQt07NhRun748GGLnh1bTJkyBT/99BN+++03NGjQ4IFlAwICEBwcjPPnzwMA/P39kZeXh9TUVIteouTkZHTt2lUqU9rq2nfu3IGfn1+pn6NUKqFUKsv1fSqLebVq9hARERFVjNVDZnPmzMGLL76I77//Hi4uLvj2228trv/+++947rnnbPpwURQxefJkfP/999i7dy8aN25c5ntSUlJw/fp1BAQEAAA6duwIuVyO6OhoqUxiYiLOnDkjBaKwsDBotVocO3ZMKnP06FFotVqpTE1UuJ8Ze4iIiIgqQhBFUayqD584cSK+/vpr/PjjjxZ3emk0Gri6uiIzMxPz58/Hs88+i4CAAFy5cgVvvPEGrl27hvj4eKjVagDAK6+8gp9//hnr16+Hl5cXZs+ejZSUFMTGxkImkwEwzUW6desWPv/8cwCmJQOCg4Oxfft2q9qanp4OjUYDrVZrMZeqKiVpc9Fl8R44Owk4915/ODmVPvxHRERUV1n7+9vmlartadWqVQCAHj16WJxft24dxowZA5lMhtOnT2PDhg1IS0tDQEAAevbsia1bt0phCABWrFgBZ2dnDBs2DDk5OejduzfWr18vhSEA2Lx5M6ZOnSrdjTZo0CCsXLnS8V/SgbwKeojyjSK0OXp4FrwmIiIi21RpD1FNUh17iACg3YJd0ObosXvmk2jqqy77DURERHWItb+/y711B1UP5sUZ72RwYjUREVF5MRDVcNLijNzPjIiIqNwYiGo48+KMKbz1noiIqNxsnlRtMBiwfv167NmzB8nJySV2ud+7d6/dGkdlkzZ45a33RERE5WZzIJo2bRrWr1+Pp59+GqGhofdd6ZkqR+Fq1ewhIiIiKi+bA9GWLVvw3//+F0899ZQj2kM28pb2M2MPERERUXnZPIdIoVCgadOmjmgLlQN3vCciIqo4mwPRrFmz8PHHH4PLF1UP0qTqLA6ZERERlZfNQ2aHDh3Cvn378Ouvv6J169aQy+UW17///nu7NY7KJk2qzmAPERERUXnZHIjq1auHZ555xhFtoXIwzyHKyjMgJ88AV4WsjHcQERFRcTYHonXr1jmiHVRO7kpnKJydkJdvxN1MHYK83Kq6SURERDUOF2as4QRBQH1ptWrOIyIiIiqPcu12/7///Q///e9/ce3aNeTlWf4SPnnypF0aRtbzdlfgZloO7zQjIiIqJ5t7iD755BO88MIL8PX1xalTp/DYY4/B29sbly5dQv/+/R3RRioDV6smIiKqGJsD0aefforVq1dj5cqVUCgUeO211xAdHY2pU6dCq9U6oo1UBm+VeXFGDpkRERGVh82B6Nq1a+jatSsAwNXVFRkZGQCAyMhIfPPNN/ZtHVnFW1qckYGIiIioPGwORP7+/khJSQEABAcHIyYmBgBw+fJlLtZYRXy4fQcREVGF2ByIevXqhe3btwMAxo0bhxkzZqBPnz4YPnw41yeqItL2HVkMREREROVh811mq1evhtFoBAC8/PLL8PLywqFDhzBw4EC8/PLLdm8gla1wtWoOmREREZWHzYHIyckJTk6FHUvDhg3DsGHD7Nooso23tJ8Ze4iIiIjKo1wLMx48eBCjRo1CWFgYbt68CQDYuHEjDh06ZNfGkXXMgeheVh4MRs7jIiIispXNgei7775DREQEXF1dcerUKeh0pl6JjIwMLFq0yO4NpLJ5uSkgCIBRBFKzOWxGRERkK5sD0XvvvYfPPvsMa9assdjpvmvXrlyluoo4y5zg6VYwbMZb74mIiGxmcyBKSEjAk08+WeK8h4cH0tLS7NEmKgfeek9ERFR+NgeigIAAXLhwocT5Q4cOoUmTJnZpFNnOW8XtO4iIiMrL5kD00ksvYdq0aTh69CgEQcCtW7ewefNmzJ49GxMnTnREG8kK0p1mHDIjIiKymc233b/22mvQarXo2bMncnNz8eSTT0KpVGL27NmYPHmyI9pIVuAGr0REROVncyACgIULF+LNN9/EX3/9BaPRiFatWsHd3d3ebSMb+LCHiIiIqNzKFYgAwM3NDZ06dbJnW6gCvNlDREREVG5WB6KxY8daVe7LL78sd2Oo/KQhsyz2EBEREdnK6kC0fv16BAcHo3379tzVvhoqnFTNHiIiIiJbWR2IXn75ZWzZsgWXLl3C2LFjMWrUKHh5eTmybWSD+kWGzERRhCAIVdwiIiKimsPq2+4//fRTJCYmYs6cOdi+fTuCgoIwbNgw7Ny5kz1G1YC5hyhXb0R2nqGKW0NERFSz2LQOkVKpxHPPPYfo6Gj89ddfaN26NSZOnIjg4GBkZmY6qo1kBTeFM1zlMgCcWE1ERGSrcu12DwCCIEAQBIiiCKPRaM82UTn5qM3bd3BiNRERkS1sCkQ6nQ7ffPMN+vTpg5CQEJw+fRorV67EtWvXyrUO0eLFi/Hoo49CrVbD19cXQ4YMQUJCgkUZURQxf/58BAYGwtXVFT169MDZs2dLtGvKlCnw8fGBSqXCoEGDcOPGDYsyqampiIyMhEajgUajQWRkZK3be828fQcnVhMREdnG6kA0ceJEBAQEYOnSpRgwYABu3LiBb7/9Fk899RScnMrX0XTgwAFMmjQJMTExiI6ORn5+Pvr27YusrCypzPvvv4/ly5dj5cqVOH78OPz9/dGnTx9kZGRIZaZPn45t27Zhy5YtOHToEDIzMzFgwAAYDIVzaUaMGIG4uDhERUUhKioKcXFxiIyMLFe7q6vC1arZQ0RERGQLQbRyRrSTkxMaNmyI9u3bP/AOpu+//77cjblz5w58fX1x4MABPPnkkxBFEYGBgZg+fTrmzJkDwNQb5Ofnh6VLl+Kll16CVqtF/fr1sXHjRgwfPhwAcOvWLQQFBeGXX35BREQE4uPj0apVK8TExKBz584AgJiYGISFheHvv/9GSEhImW1LT0+HRqOBVquFh4dHub+jI73+3Z/Ycvw6ZvVpjim9m1V1c4iIiKqctb+/rb7t/vnnn3f4rdxarRYApNv5L1++jKSkJPTt21cqo1Qq0b17dxw+fBgvvfQSYmNjodfrLcoEBgYiNDQUhw8fRkREBI4cOQKNRiOFIQDo0qULNBoNDh8+XGog0ul00OkKh57S09Pt/n3tTVqLiIszEhER2cSmhRkdSRRFzJw5E926dUNoaCgAICkpCQDg5+dnUdbPzw9Xr16VyigUCnh6epYoY35/UlISfH19S3ymr6+vVKa4xYsXY8GCBRX7UpXMPGR2h3OIiIiIbFLuu8zsbfLkyfjzzz/xzTfflLhWvGfKmoUHi5cprfyD6pk7dy60Wq10XL9+3ZqvUaXM+5lxUjUREZFtqkUgmjJlCn766Sfs27cPDRo0kM77+/sDQIlenOTkZKnXyN/fH3l5eUhNTX1gmdu3b5f43Dt37pTofTJTKpXw8PCwOKo78473nFRNRERkmyoNRKIoYvLkyfj++++xd+9eNG7c2OJ648aN4e/vj+joaOlcXl4eDhw4gK5duwIAOnbsCLlcblEmMTERZ86ckcqEhYVBq9Xi2LFjUpmjR49Cq9VKZWoDH/YQERERlYvVc4gcYdKkSfj666/x448/Qq1WSz1BGo0Grq6uEAQB06dPx6JFi9CsWTM0a9YMixYtgpubG0aMGCGVHTduHGbNmgVvb294eXlh9uzZaNOmDcLDwwEALVu2RL9+/TB+/Hh8/vnnAIAJEyZgwIABVt1h5lBnfwDitwN93gU0D1WoKm+VqYcoNVuPfIMRzrJq0QFIRERU7dn8G/O3335Dfn5+ifP5+fn47bffbKpr1apV0Gq16NGjBwICAqRj69atUpnXXnsN06dPx8SJE9GpUyfcvHkTu3btglqtlsqsWLECQ4YMwbBhw/D444/Dzc0N27dvh0wmk8ps3rwZbdq0Qd++fdG3b1+0bdsWGzdutPXr21/Mp8CZ/wEJv1S4Kk83BZwKpkTd451mREREVrN6HSIzmUyGxMTEEndtpaSkwNfX12IxxNrEYesQHfoI2D0PeLgXELmtwtV1em837mbq8MvUJ9AqsPrPeyIiInIka39/29xDdL87s1JSUqBSqWytjlo8bXq8fBDI1Va4usKJ1ZxHREREZC2r5xANHToUgOn29TFjxkCpVErXDAYD/vzzz1o1QbnS+DQDvJsBKeeB89FAm39UrDp3JYAMpGQxEBEREVnL6kCk0WgAmHqI1Go1XF1dpWsKhQJdunTB+PHj7d/CuqDFU8DvH5vmEVUwEEmrVfPWeyIiIqtZHYjWrVsHAGjUqBFmz57N4TF7ajHAFIjORwP5eYCzotxVcbVqIiIi29l82/28efMAmBY1TEhIgCAIaN68OerXr2/3xtUZD3UCVL5AVjJw5SDQtHe5q2IPERERke1snlSdnZ2NsWPHIiAgAE8++SSeeOIJBAYGYty4ccjOznZEG2s/JycgpJ/peQVvv/dRmXqIOKmaiIjIejYHohkzZuDAgQPYvn070tLSkJaWhh9//BEHDhzArFmzHNHGuiGk4G6zhF8B21ZCsOCjZg8RERGRrWweMvvuu+/wv//9Dz169JDOPfXUU3B1dcWwYcOwatUqe7av7mjSHZCrgPSbQGIcENi+XNV4q7h9BxERka3KNWRW2oaovr6+HDKrCLkr0LSX6fnf5R8281Gbh8zyYOOam0RERHWWzYEoLCwM8+bNQ25urnQuJycHCxYsQFhYmF0bV+eYh83+3lHuKsz7meUZjMjQldxihYiIiEqyecjs448/Rr9+/dCgQQO0a9cOgiAgLi4OLi4u2LlzpyPaWHc0jwAEGZB8Fki9Ang2srkKF7kM7kpnZOrykZKZBw8Xud2bSUREVNvY3EMUGhqK8+fPY/HixXjkkUfQtm1bLFmyBOfPn0fr1q0d0ca6w80LCC5Y7bsiw2bcvoOIiMgmNvcQAYCrqytXpXaUkKdMaxEl/AKETSxXFd7uSlxJyebEaiIiIivZ3EMEABcvXsSUKVMQHh6OPn36YOrUqbh48aK921Y3tXjK9Hj1dyD7XrmqMPcQ3eGt90RERFaxORDt3LkTrVq1wrFjx9C2bVuEhobi6NGjaN26NaKjox3RxrrFsxHg2xoQjcC58s3J8nbnrfdERES2sHnI7PXXX8eMGTOwZMmSEufnzJmDPn362K1xdVaLp0wTqxN2AI88Z/PbfVRcnJGIiMgWNvcQxcfHY9y4cSXOjx07Fn/99ZddGlXntSi4/f7CXkCf++CypShci4g9RERERNawORDVr18fcXFxJc7HxcXB19fXHm2igEcAj4cAfRZw+YDNby9crZo9RERERNawechs/PjxmDBhAi5duoSuXbtCEAQcOnQIS5cu5V5m9iIIQEh/4PgXwN8/m9YnsgFvuyciIrKNzYHo7bffhlqtxrJlyzB37lwAQGBgIObPn4+pU6favYF1VshTpkCUEAUYjYCT9Z155knVDERERETWsXnITBAEzJgxAzdu3IBWq4VWq8WNGzcwbdo03Lp1yxFtrJsaPQEoPYCsZODmCZveau4hSs/NR16+0RGtIyIiqlXKtQ6RmVqthlqtRlJSEqZMmYKmTZvaq13krACaFdyxZ+PeZhpXOZydBABAShZ7iYiIiMpidSBKS0vDyJEjUb9+fQQGBuKTTz6B0WjEO++8gyZNmiAmJgZffvmlI9ta94QULNJoYyASBAHe7rz1noiIyFpWzyF644038Ntvv2H06NGIiorCjBkzEBUVhdzcXPz666/o3r27I9tZNzXrAzjJgZTzwN3zgE8zq9/q467E7XQd7nAeERERUZms7iHasWMH1q1bhw8//BA//fQTRFFE8+bNsXfvXoYhR3HRAI26mZ7b2EtUuFo1e4iIiIjKYnUgunXrFlq1agUAaNKkCVxcXPDiiy86rGFUwLxIY8IvNr2tcLVq9hARERGVxepAZDQaIZfLpdcymQwqlcohjaIizPOIrh8DMpOtfhtXqyYiIrKe1XOIRFHEmDFjoFSaftHm5ubi5ZdfLhGKvv/+e/u2sK7TPGRauToxDkj4Feg42qq3eXM/MyIiIqtZHYhGj7b8RTxq1Ci7N4buo8XTBYHoF6sDkU/BHCJOqiYiIiqb1YFo3bp1jmwHPUiLp4F9C4FL+4G8LEBR9lAlb7snIiKyXoUWZqRK4tsKqBcM5OcCF/da9RZzDxEXZiQiIiobA1FNIAiFd5v9bd3dZj5Fbrs3GkVHtYyIiKhWYCCqKcx3m537FTDkl1ncq2BSdb5RRHqu3pEtIyIiqvEYiGqKhmGAqyeQkwpcjymzuMLZCR4upilidzmPiIiI6IEYiGoKmTPQvJ/pubXDZlyLiIiIyCoMRDWJedgsYQcglj0vyEfF7TuIiIisUaWB6LfffsPAgQMRGBgIQRDwww8/WFwfM2YMBEGwOLp06WJRRqfTYcqUKfDx8YFKpcKgQYNw48YNizKpqamIjIyERqOBRqNBZGQk0tLSHPztHODhXoBMCaReAZL/KrO4j9o0j4g9RERERA9WpYEoKysL7dq1w8qVK+9bpl+/fkhMTJSOX36xHC6aPn06tm3bhi1btuDQoUPIzMzEgAEDYDAYpDIjRoxAXFwcoqKiEBUVhbi4OERGRjrsezmM0h1o0sP03IphM2+ph4iBiIiI6EGsXpjREfr374/+/fs/sIxSqYS/v3+p17RaLdauXYuNGzciPDwcALBp0yYEBQVh9+7diIiIQHx8PKKiohATE4POnTsDANasWYOwsDAkJCQgJCTEvl/K0Vo8DZzfaRo26/7qA4uaF2e8m8UhMyIiogep9nOI9u/fD19fXzRv3hzjx49HcnLhBqexsbHQ6/Xo27evdC4wMBChoaE4fPgwAODIkSPQaDRSGAKALl26QKPRSGVKo9PpkJ6ebnFUCyH9AQjArVNA+q0HFjWvRXQ3gz1ERERED1KtA1H//v2xefNm7N27F8uWLcPx48fRq1cv6HSmX/BJSUlQKBTw9PS0eJ+fnx+SkpKkMr6+viXq9vX1lcqUZvHixdKcI41Gg6CgIDt+swpw9wUaPGp6nvDgYTMf8/Yd7CEiIiJ6oGodiIYPH46nn34aoaGhGDhwIH799VecO3cOO3bseOD7RFGEIAjS66LP71emuLlz50Kr1UrH9evXy/9F7K1Fwd1mfz/4z0HqIeIcIiIiogeq1oGouICAAAQHB+P8+fMAAH9/f+Tl5SE1NdWiXHJyMvz8/KQyt2/fLlHXnTt3pDKlUSqV8PDwsDiqjRYDTI+XDwK52vsW83bnbfdERETWqFGBKCUlBdevX0dAQAAAoGPHjpDL5YiOjpbKJCYm4syZM+jatSsAICwsDFqtFseOHZPKHD16FFqtVipT4/g0A7ybAUY9cGH3fYuZJ1Vn6vKRnVf2dh9ERER1VZUGoszMTMTFxSEuLg4AcPnyZcTFxeHatWvIzMzE7NmzceTIEVy5cgX79+/HwIED4ePjg2eeeQYAoNFoMG7cOMyaNQt79uzBqVOnMGrUKLRp00a666xly5bo168fxo8fj5iYGMTExGD8+PEYMGBAzbvDrChp2Oz+84jUSmfUL1it+pM9FyqjVURERDVSlQaiEydOoH379mjfvj0AYObMmWjfvj3eeecdyGQynD59GoMHD0bz5s0xevRoNG/eHEeOHIFarZbqWLFiBYYMGYJhw4bh8ccfh5ubG7Zv3w6ZTCaV2bx5M9q0aYO+ffuib9++aNu2LTZu3Fjp39euQp42PZ7fBeSXPiQmCAL+Pbg1AOCzAxexLyG51HJERER1nSCKVuwBQUhPT4dGo4FWq60e84mMBmBZCJB1B4jcZlrF+j7m/XgGXx25Ci+VAr9MfQL+GpdKbCgREVHVsfb3d42aQ0RFOMkK1iRCmatWz32qJVoHeuBeVh6mbjmFfIOxEhpIRERUczAQ1WTmYbOEXx+42auLXIaVIzpApZDh2OV7+GQv5xMREREVxUBUkzXpDsjdgPQbQOIfDyza2EeFRUPbAAD+s/c8fr9wtzJaSEREVCMwENVkctfCuUNlLNIIAIMfeQj/ejQIoghM2xKHO9zSg4iICAADUc1nXqSxjG08zOYNbI0QPzXuZuowY2scjEbOqSciImIgqumaRwCCDLh9Bki9UmZxV4UMK0e0h6tchkMX7mLVgYuObyMREVE1x0BU07l5AQ3DTM8TfrXqLc381Hi3YH2iZbsScOzyPUe1joiIqEZgIKoNrNzstah/dGyAoe0fglEEpn5zCveyuN8ZERHVXQxEtUFIQSC6ehjItq63RxAE/HtIKJrUVyEpPRezv/2D84mIiKjOYiCqDbwaA76tAdFg2srDSiqlM/5vRAconJ2w9+9krD102YGNJCIiqr4YiGqLcgybAUDLAA/MG9gKALA06m+cvJZq75YRERFVewxEtYV52OzCHkCfa9NbRzzWEE+3DUC+UcSUr09Bm613QAOJiIiqLwai2iKwPaAOBPRZwOUDNr1VEAQsHtoGDb3ccDMtB6999we45y8REdUlDES1hSCUe9gMADxc5Pi/ER0glwnYefY2Nhy5aucGEhERVV8MRLWJedjsXBRgtH1H+zYNNHjjqZYAgIU74nHmptaerSMiIqq2GIhqk0ZPAEoPIPM2cDO2XFWM6doIfVr5Ic9gxKSvTyIjl/OJiIio9mMgqk2cFUDTcNPzv38uVxWCIOCDf7TFQ/VccTUlG3O/P835REREVOsxENU2LZ42PVq52Wtp6rkp8J8R7eHsJODnPxOx5fh1OzWOiIioemIgqm2a9QGc5MDdc8DdC+WupkNDT7waEQIAmP/TWcQnpturhURERNUOA1Ft46IBGnUzPU+w/W6zosY/0QQ9QupDl2/E5K9PIkuXb4cGEhERVT8MRLWRedjs7/IPmwGAk5OAZf9sBz8PJS7eycI7P561Q+OIiIiqHwai2iikv+nx+lEgM7lCVXm7K/HJv9rDSQC+O3kD/4u9YYcGEhERVS8MRLWRpgEQ8AgA0bQmUQV1buKNGeHNAQBv/3AGF5IzKlwnERFRdcJAVFvZadjMbGLPpni8qTdy9AZM2nwKuXqDXeolIiKqDhiIaivzqtWX9gF5WRWuTuYkYMXwR+DjrkDC7Qws2P5XheskIiKqLhiIaiu/1kC9hkB+LnBxn12q9FW74KPh7SEIwDfHruGnP27ZpV4iIqKqxkBUWwkC0GKA6Xk5Nnu9n27NfDC5Z1MAwBvfn8aVuxXvfSIiIqpqDES1mXnYLGEHcGk/YKctOKb1bobHGnkhU5ePSV+fhC6f84mIiKhmYyCqzRqGAV5NgFwtsGEwsO4p4NKBCgcjZ5kTPn7uEXi6yXH2VjqeWx2D/9t3AUcvpXCyNRER1UiCyJ07rZKeng6NRgOtVgsPD4+qbo71Mm4DB5cBsesBg850LvhxoMfrQKMnTENr5bTv72S8uOEEDMbCv0IKmRPaNNDg0UZeeLSRJzoGe6Kem6KCX4KIiKh8rP39zUBkpRobiMzSbwGHVhQEozzTueDHgR5zgcZPlLvai3cy8du5Ozh+5R6OXU7F3UxdiTIhfmp0auSJxxp7oVMjLzxUz7Xcn0dERGQLBiI7q/GByEx7E/j9o2LBqBvQc27hHmjlJIoirqZk4/iVezh+5R5OXEnFpVImXT9UzxWdGnmiUyMvPNbIC8183eHkVP6eKiIiovthILKzWhOIzLQ3TT1GJ78qDEaNnigYSqtYMCrqbqYOJ67cw/ErqTh+5R7O3kq3GGIDAI2rHJ2CCwJSY0+EPqSB0llmtzYQEVHdxUBkZ7UuEJlpbxQEow3FgtFcoNHjdv+4LF0+4q6n4djlezhx9R5OXk1DTrGJ2EpnJ7QLqodHG3miU7AXGvuo4K9xgYucIYmIiGzDQGRntTYQmWlvAAeXm4KRUW861/hJUzAK7uqwj9UbjPjrVrrFMFtKVl6pZX3clXiongsC67lKR9HX3ioFhApMEiciotqHgcjOan0gMku7XthjZBGM3gCCwxz+8aIo4tLdLJwomKT9x4003EzNKdGLVBqlsxMeksKSS5HQZHoMYC8TEVGdUyMC0W+//YYPPvgAsbGxSExMxLZt2zBkyBDpuiiKWLBgAVavXo3U1FR07twZ//d//4fWrVtLZXQ6HWbPno1vvvkGOTk56N27Nz799FM0aNBAKpOamoqpU6fip59+AgAMGjQI//nPf1CvXj2r21pnApFZ2nXg0HLg5MYiwah7QY+R44NRUaIoIi1bj5tpObhlPrS5Fq+TM3RWLa/k464wBSWNKx7yNIUkXw8X+KqV8Ct4VCmdHf+liIioUtSIQPTrr7/i999/R4cOHfDss8+WCERLly7FwoULsX79ejRv3hzvvfcefvvtNyQkJECtVgMAXnnlFWzfvh3r16+Ht7c3Zs2ahXv37iE2NhYymak3oH///rhx4wZWr14NAJgwYQIaNWqE7du3W93WOheIzNKumYbSTm0qDEZNepiCUcMuVdq0ovLyjbidnosbqUVDUw5upuXiVlqO1b1MAKBSyKSQVBiWlPBVFznnoYRa6cwhOiKiaq5GBKKiBEGwCESiKCIwMBDTp0/HnDlzAJh6g/z8/LB06VK89NJL0Gq1qF+/PjZu3Ijhw4cDAG7duoWgoCD88ssviIiIQHx8PFq1aoWYmBh07twZABATE4OwsDD8/fffCAkJsap9dTYQmaVdMy3weGoTYMw3nWvSsyAYda7atllBFEVoc8y9TLkWPU3J6blIztAhOT0XWXnWr7TtIneCr9pFCkv1i/Qy+RYJUPXc5AxORERVxNrf39V2bODy5ctISkpC3759pXNKpRLdu3fH4cOH8dJLLyE2NhZ6vd6iTGBgIEJDQ3H48GFERETgyJEj0Gg0UhgCgC5dukCj0eDw4cP3DUQ6nQ46XeEig+np6Q74ljVIvYbAwI+BbjNNwShuM3Bpn+moFwz4NAO8mxYcDwPezQCPhwCn6rE7jCAIqOemQD03BVoHau5bLlOXXxiQCkJS0cfbBY8ZufnI1Rtx7V42rt3LfuBny2UCvFVK1Fcr4eOugI+7+bnlY313JTxc2etERFQVqm0gSkpKAgD4+flZnPfz88PVq1elMgqFAp6eniXKmN+flJQEX1/fEvX7+vpKZUqzePFiLFiwoELfoVbyDAYGfQI8MaswGKVdNR0XdluWdXYBvB42BSSLwNQUcPOqmvaXwV3pDPf67mhS3/2B5XLyDEjOMIelwqCUnJGL5HSddC0tWw+9QURSei6S0nPL/HyFzAk+7opSA1Pho+m6O4fsiIjsptoGIrPi/+CLoljmL4HiZUorX1Y9c+fOxcyZM6XX6enpCAoKsrbZtZ85GIXPB5LjgZQLBcdFIOU8cO8ykJ8LJJ81HcW5ehXrUWpqCk1eTQB59d/aw1UhQ7C3CsHeqgeW0+UbkJKZh7uZOtzJ0BV5zMOdYucycvORZzDiljYXt7RlhyelsxO8VQp4qhTwUing6Vb0UW4671Z4vZ6bnAteEhHdR7UNRP7+/gBMPTwBAQHS+eTkZKnXyN/fH3l5eUhNTbXoJUpOTkbXrl2lMrdv3y5R/507d0r0PhWlVCqhVCrt8l1qNTcv0wKOxRdxNOQD2mumgHT3vGVgSr8B5NwDbhwzHcVpggpDkndTQB0AqP0Bdz/TYw0ITGZKZ5l0+39ZcvUG3M0sCEsW4alYkMrQIVOXD12+9eHJzF3pDE+VHF4Fw4cPClCebgpoXOVQOFePYU8iIkeqtoGocePG8Pf3R3R0NNq3bw8AyMvLw4EDB7B06VIAQMeOHSGXyxEdHY1hw4YBABITE3HmzBm8//77AICwsDBotVocO3YMjz32GADg6NGj0Gq1UmgiB5A5m3p7vJoAzfpYXsvLBu5dtAxJd8+bepZytYD2uum4tL/0upUeheFIevQF3P0BtZ/p0d0XcPUEatCQkotchgaebmjg6VZm2Zw8U3i6l5WHe9l5SM3Kw72sPKRm5+Felt70uuB8anYeUrP1MBhFZOrykanLx/V7OVa3y00hg8ZVLh313MyPitLPu5rOq12cuUcdEdUYVRqIMjMzceHCBen15cuXERcXBy8vLzRs2BDTp0/HokWL0KxZMzRr1gyLFi2Cm5sbRowYAQDQaDQYN24cZs2aBW9vb3h5eWH27Nlo06YNwsPDAQAtW7ZEv379MH78eHz++ecATLfdDxgwwOo7zMjOFG6AfxvTUZQoAtn3igSl88C9S0DGbSAzyfSYnwPo0k1HyvkHf45MWRCY/EyPpYUolS/gogEUqhoVnlwVMgR5uSHIq+zwBABGo4iM3HxTYCojQJkf03L0pv8keQZk5xmQaENPFGD64/RwKQxKpQYnNznqFYSrouW4gCYRVbYqve1+//796NmzZ4nzo0ePxvr166WFGT///HOLhRlDQ0Olsrm5uXj11Vfx9ddfWyzMWHS+z71790oszLhy5UouzFjTiKIpCJkDUmYykJFUGJaKnstNs61uQWYKRi4epkdlwaP5kF57lHKu4Lms2na4lovBKCIjVw9tjulIyy54zNEjPUePtOw8i/NFy1m75tP9uMidUM9VUaQ3Sl742q2wF8riupsCKoWME82JyEKNW4eoumMgqmH0uUDm7cIjI6mUx2Qg6w4gVuyXt0SuKhmaXL0KhvPMvVS+hY81bEjPFrp8A7RScCojUOXooc02PaZl58FYgX+RnJ0EKSR5uMrh4WIauvMoGMLzcJHDo8hrtYtlGQYqotqHgcjOGIhqKVEE9NmmuUu56aZHXcGj+ZBeF79e8KjPKt9nO8lLhiSLxyLPFdYNjdV0RqOIzLx8U0DK1iMtJ6/gsTBEmV9ri17P1iPPYKzw5zsJgNqlMDw9KEyZrpcsw0noRNVLjV+YkahSCIJp/pBCBXgElq8Ogx7QZZiG6YqHpuwUU0+U1FtV8Dwn1bQVSvoN01EWhbr04OTmVdAbVa/g0ACuBY8yefm+TxVychIKgoccQTYsVSWKInL1RqTlmHqdUrP0SM/VIyM3H+k5BY+5emTk6pGek48MXcFjrh7pBWXyjSKMIqShP8D6iedFKZ2dioUm54LeqpIhS62UF5YteHRXcDI6UVVgD5GV2ENEdpWvMw3XZd4umP90u/TglHnbtJ5TecjdSoYkKTxp7n/etZ4pgFWTVcYrgzlQmQJSYUgqDFKWr83Pi17P1OXbpS2CULBAqNIZqoLDXSmDSmE656aUmc4pzNfM5WTS86LnuPYU1XXsISKqzpyVgKaB6XgQUTT1Pt0vLOWkFQzfpVkO8QGmoUB9NpBxqxwNFEwTxZXuhT1oiqLPVaY5U6VeK1auaPlqGrIEQYCrQgbXgo19y8NgFJFpDky5lj1QGUVeW4SsImErPde0qrkoQgpb9iCXCaZwVCRQmQOXOTipXSyfqxTOcHcpWUbp7MQ5VlRrMRARVWeCUDBJ2wPwaWrdewz5BUN2aYUhKafIc/P50s7lagt6pERApzUd9iR3KxKS1EV6qerd/7FoGWeFfdtjRzInAZqCu+DKQxRF6PKNUkjKKlgzKktnKPLcfL7gXF7huSydAVl5he/L1ZvmVOkNojTPyh7f0TJMyeDuIod7kd4pdcGjm9IZKoUMbgpTOXMoc1OYnrspZAxYVK0wEBHVNjJn09yi8u4Xp88tDEd5mUBelunQZxU+L3peep19/2soGJk391pl3Slf28zDgA8KTdI5j8LeKqXa9FzuWm3v7BMEAS5yGVzkMviqK15fvsGIrDxDkRBlCk1SsMrLtwhembp8ZOaazmfm5iPD/L7cfGTlme7ENBjFInOsKk7mJJgCUpHQZH5dNFC5K2UWr90UMrgoZHCTm167KmRwU8jgKjf18jFoUXkwEBGRJbmL6VDff2sbm4gioM8pGapyzb1YaQW9VWmWQ4DSuSI9VRUaBgQgOBWEJHNQci98LQ0PuhcEqNKeF3kvBNOSDUaD6VEUC58bDYBoLHhuLOWcoci1YudEo6mdqvoFq6/7mz7XRs4yJ2hcnaBxrfjkeqNRLOh9MiBTp0emzoDM3MIgVVqoyi7SY5WdZ7A4Z+69MhQsGGqv4UEzJwFSUHKVF4Qli9DkDDd58XOFYavk+5yLlJFBLqueQ79UMQxERORYgmBaNkDhBqB++eowGiyH9ywCVFrpQUqXAegyLXupRGPhSuc1icK9cIV1tX/hNjXqAMsV2F00DukBc3ISCpYYkAMo3xyrogxGEdl5hcN85qBkPidd05l6p4qeNw0HmlZPzylYRT27IGSZl14wipACmiPIZYJFiCoangqfm8KVm8LU62d+7qpwhouzk1TWpaAeF3lBMJOberh4p2HlYyAiourPSVaxYUCj0dSzZA5Huoz7PM8sGPLLLBKmigUrcxlBMPXkCDJT+wQn0+EkM50r+tzJqVhZ8/Xi7y94bswvXHVdX/C59zJNewA+iLNr4X5+pQUm80bJVbwoqMwiYNmP3mBEjt4UlMxhKUefL20/Yw5SpjCVX3C9aLAylS98b8H78gzI1htgKFg1VG8QoTfkIz03H4DOrt/BzEXuVBiYigQn03OnwgBVJFiZzjlZBixFyfdzaLF0DEREVPs5OZmGnZTuAOw0FFhZdBlF9vNLKrldTUbBc53WtNdf6hXT8UCCaT6Vs4tpXpbcpeC1a8Fzt2LXzK9dS3nfg8q6me6orKRfunKZE+QyJ3jYOWgBpknveQajRViy7KEqGraKlikIZEWCWm5+waO+sJ7cfCPy8gsXF83VGwuGFu0zX6s0ggC4OFsGLYsAVUqgcnGWQSl3gouzkxTClAXPlQVBTVnkmouzE5QFj87VfKiRgYiIqDpTqk1HWXcZ5mUX2ZYmyXJT5IzEwms59wCIhfOxcu45+AsIhUFK7lYsULlaBjKLcOVqGbKkMFYQ2pyLHEVfOyh8CYIApbNpXad6Dlo43mAULUOS3oBcfUGvl8U5g3QuN89Q5LoRufnFzxULXkWGFkURUrnK4OwklAxQzqYgpix4nNGnOdo2qFcp7SnRvir5VCIisi+FG+DV2HQ8SL7ONM8qP8d0R6E+27TUgj7HdOQXnLO4Vvx1TpHyOcXeW/DcaO7ZKBK+kOLgPwQAMmXJwOSsLAhTSlOgKut1qb1i9ztvvxAmcxKkxTgdKd9gRG6+sURYKj1kFS1TELj0BujyjdAVBLZcvanXS6c3XzdKZYr2euUbxYK5Xfdv29huZfz9dSAGIiKiusRZab87CB/EoC8lNGUXPOYWeV40dOUUO0q7lm0Kdfm5pnryc0yT5aXP1ZkO2HkNrQd5UFgy93I5FznnrDAFN2eF6bX5ucWjEpApipU3nyv6qLR5wVNnmRPcZU5wd3DwAkx3KOryCwOSOTzl6gsClflcwfXmfnZYc6KcGIiIiMj+ZHLT4VIJWx0Z9EUCUpGj+Ot8XWFP1v3KmF/fr1fMfM1Y5A62/ILQl5Pq+O9aGid5yQBl7hkzBylnZSnnipSVFXnP/crKFAU3EwgAhCI9Y8XPFT46CQJcAbgWvSYXADlKr8e16nYTYyAiIqKazRy+lJXYu2DItxwulHrCyhiGzM8B8vNMvVj5OsCQV8pj7gOumXvAijDqgTzHTb6uVKO+B5r2rpKPZiAiIiKylcwZkKkrN4SZiWLpISlfVyxU5RX2fBUNWtJR9HzR8kXrK3YeounzpUeUcq7Io7m9EAtellHGqeo2I2YgIiIiqkkEoXBoi+ymei8KQERERFQJGIiIiIiozmMgIiIiojqPgYiIiIjqPAYiIiIiqvMYiIiIiKjOYyAiIiKiOo+BiIiIiOo8BiIiIiKq8xiIiIiIqM5jICIiIqI6j4GIiIiI6jwGIiIiIqrzGIiIiIioznOu6gbUFKIoAgDS09OruCVERERkLfPvbfPv8fthILJSRkYGACAoKKiKW0JERES2ysjIgEajue91QSwrMhEAwGg04tatW1Cr1RAEoaqbY7X09HQEBQXh+vXr8PDwYP2VVHdNr78mt72m11+T217T66/Jba/p9TuyblEUkZGRgcDAQDg53X+mEHuIrOTk5IQGDRpUdTPKzcPDwyE/ILWh/prcdkfXX5PbXtPrr8ltr+n11+S21/T6HVX3g3qGzDipmoiIiOo8BiIiIiKq8xiIajmlUol58+ZBqVSy/kqsu6bXX5PbXtPrr8ltr+n11+S21/T6Hd12a3BSNREREdV57CEiIiKiOo+BiIiIiOo8BiIiIiKq8xiIiIiIqM5jIKqlfvvtNwwcOBCBgYEQBAE//PCD3epevHgxHn30UajVavj6+mLIkCFISEiwW/2rVq1C27ZtpQW6wsLC8Ouvv9qt/uIWL14MQRAwffp0u9Q3f/58CIJgcfj7+9ulbgC4efMmRo0aBW9vb7i5ueGRRx5BbGysXepu1KhRibYLgoBJkybZpf78/Hy89dZbaNy4MVxdXdGkSRO8++67MBqNdqk/IyMD06dPR3BwMFxdXdG1a1ccP368XHWV9TMkiiLmz5+PwMBAuLq6okePHjh79qzd6v/+++8REREBHx8fCIKAuLg4u7Vfr9djzpw5aNOmDVQqFQIDA/H888/j1q1bdmv//Pnz0aJFC6hUKnh6eiI8PBxHjx61S91FvfTSSxAEAR999JHd2j5mzJgSPwNdunSxW/0AEB8fj0GDBkGj0UCtVqNLly64du1ahesu7edXEAR88MEHdml7ZmYmJk+ejAYNGsDV1RUtW7bEqlWrrKrbmvpv376NMWPGIDAwEG5ubujXrx/Onz9vdf0VwUBUS2VlZaFdu3ZYuXKl3es+cOAAJk2ahJiYGERHRyM/Px99+/ZFVlaWXepv0KABlixZghMnTuDEiRPo1asXBg8ebNMvG2sdP34cq1evRtu2be1ab+vWrZGYmCgdp0+ftku9qampePzxxyGXy/Hrr7/ir7/+wrJly1CvXj271H/8+HGLdkdHRwMA/vnPf9ql/qVLl+Kzzz7DypUrER8fj/fffx8ffPAB/vOf/9il/hdffBHR0dHYuHEjTp8+jb59+yI8PBw3b960ua6yfobef/99LF++HCtXrsTx48fh7++PPn36SPseVrT+rKwsPP7441iyZInNbS+r/uzsbJw8eRJvv/02Tp48ie+//x7nzp3DoEGD7FI/ADRv3hwrV67E6dOncejQITRq1Ah9+/bFnTt3Kly32Q8//ICjR48iMDDQ6nZbW3+/fv0sfhZ++eUXu9V/8eJFdOvWDS1atMD+/fvxxx9/4O2334aLi0uF6y7a5sTERHz55ZcQBAHPPvusXdo+Y8YMREVFYdOmTYiPj8eMGTMwZcoU/PjjjxWuXxRFDBkyBJcuXcKPP/6IU6dOITg4GOHh4Xb7/fJAItV6AMRt27Y5rP7k5GQRgHjgwAGHfYanp6f4xRdf2LXOjIwMsVmzZmJ0dLTYvXt3cdq0aXapd968eWK7du3sUldxc+bMEbt16+aQukszbdo08eGHHxaNRqNd6nv66afFsWPHWpwbOnSoOGrUqArXnZ2dLcpkMvHnn3+2ON+uXTvxzTffrFDdxX+GjEaj6O/vLy5ZskQ6l5ubK2o0GvGzzz6rcP1FXb58WQQgnjp1yuZ6ranf7NixYyIA8erVqw6pX6vVigDE3bt326XuGzduiA899JB45swZMTg4WFyxYoVN9T6o/tGjR4uDBw8uV33W1D98+HC7/J235s998ODBYq9evexWf+vWrcV3333X4lyHDh3Et956q8L1JyQkiADEM2fOSOfy8/NFLy8vcc2aNTbXbyv2EFGFabVaAICXl5fd6zYYDNiyZQuysrIQFhZm17onTZqEp59+GuHh4XatFwDOnz+PwMBANG7cGP/6179w6dIlu9T7008/oVOnTvjnP/8JX19ftG/fHmvWrLFL3cXl5eVh06ZNGDt2rN02NO7WrRv27NmDc+fOAQD++OMPHDp0CE899VSF687Pz4fBYCjxf9murq44dOhQhesv6vLly0hKSkLfvn2lc0qlEt27d8fhw4ft+lmVRavVQhAEu/U2FpWXl4fVq1dDo9GgXbt2Fa7PaDQiMjISr776Klq3bm2HFpa0f/9++Pr6onnz5hg/fjySk5PtUq/RaMSOHTvQvHlzREREwNfXF507d7brtAaz27dvY8eOHRg3bpzd6uzWrRt++ukn3Lx5E6IoYt++fTh37hwiIiIqXLdOpwMAi59hmUwGhUJh95/h0jAQUYWIooiZM2eiW7duCA0NtVu9p0+fhru7O5RKJV5++WVs27YNrVq1slv9W7ZswcmTJ7F48WK71WnWuXNnbNiwATt37sSaNWuQlJSErl27IiUlpcJ1X7p0CatWrUKzZs2wc+dOvPzyy5g6dSo2bNhgh5Zb+uGHH5CWloYxY8bYrc45c+bgueeeQ4sWLSCXy9G+fXtMnz4dzz33XIXrVqvVCAsLw7///W/cunULBoMBmzZtwtGjR5GYmGiH1hdKSkoCAPj5+Vmc9/Pzk67VJLm5uXj99dcxYsQIu26s+fPPP8Pd3R0uLi5YsWIFoqOj4ePjU+F6ly5dCmdnZ0ydOtUOrSypf//+2Lx5M/bu3Ytly5bh+PHj6NWrl/QLuyKSk5ORmZmJJUuWoF+/fti1axeeeeYZDB06FAcOHLBD6wt99dVXUKvVGDp0qN3q/OSTT9CqVSs0aNAACoUC/fr1w6effopu3bpVuO4WLVogODgYc+fORWpqKvLy8rBkyRIkJSXZ/We4NNztnipk8uTJ+PPPP+2e3kNCQhAXF4e0tDR89913GD16NA4cOGCXUHT9+nVMmzYNu3btsmrM3lb9+/eXnrdp0wZhYWF4+OGH8dVXX2HmzJkVqttoNKJTp05YtGgRAKB9+/Y4e/YsVq1aheeff75CdRe3du1a9O/f3+b5GQ+ydetWbNq0CV9//TVat26NuLg4TJ8+HYGBgRg9enSF69+4cSPGjh2Lhx56CDKZDB06dMCIESNw8uRJO7S+pOI9Z6Io2q03rbLo9Xr861//gtFoxKeffmrXunv27Im4uDjcvXsXa9aswbBhw3D06FH4+vqWu87Y2Fh8/PHHOHnypMP+rIcPHy49Dw0NRadOnRAcHIwdO3ZUOFyYbyAYPHgwZsyYAQB45JFHcPjwYXz22Wfo3r17heov6ssvv8TIkSPt+u/cJ598gpiYGPz0008IDg7Gb7/9hokTJyIgIKDCve1yuRzfffcdxo0bBy8vL8hkMoSHh1v8m+pI7CGicpsyZQp++ukn7Nu3Dw0aNLBr3QqFAk2bNkWnTp2wePFitGvXDh9//LFd6o6NjUVycjI6duwIZ2dnODs748CBA/jkk0/g7OwMg8Fgl88xU6lUaNOmjV3ulAgICCgRClu2bGnV3Sm2uHr1Knbv3o0XX3zRrvW++uqreP311/Gvf/0Lbdq0QWRkJGbMmGG3nrqHH34YBw4cQGZmJq5fv45jx45Br9ejcePGdqnfzHzXYPHeoOTk5BK9RtWZXq/HsGHDcPnyZURHR9u1dwgw/d1v2rQpunTpgrVr18LZ2Rlr166tUJ0HDx5EcnIyGjZsKP38Xr16FbNmzUKjRo3s0/BiAgICEBwcbJefYR8fHzg7Ozv85/jgwYNISEiw689wTk4O3njjDSxfvhwDBw5E27ZtMXnyZAwfPhwffvihXT6jY8eO0v8MJyYmIioqCikpKXb/GS4NAxHZTBRFTJ48Gd9//z327t1bKX9RRVG0S3c1APTu3RunT59GXFycdHTq1AkjR45EXFwcZDKZXT7HTKfTIT4+HgEBARWu6/HHHy+xxMG5c+cQHBxc4bqLWrduHXx9ffH000/btd7s7Gw4OVn+syOTyex2272ZSqVCQEAAUlNTsXPnTgwePNiu9Tdu3Bj+/v7SXXiAaZ7MgQMH0LVrV7t+lqOYw9D58+exe/dueHt7O/wz7fFzHBkZiT///NPi5zcwMBCvvvoqdu7caaeWWkpJScH169ft8jOsUCjw6KOPOvzneO3atejYsaNd5myZ6fV66PX6SvkZ1mg0qF+/Ps6fP48TJ07Y/We4NBwyq6UyMzNx4cIF6fXly5cRFxcHLy8vNGzYsEJ1T5o0CV9//TV+/PFHqNVq6f+SNRoNXF1dK1Q3ALzxxhvo378/goKCkJGRgS1btmD//v2IioqqcN2Aaa5J8flOKpUK3t7edpkHNXv2bAwcOBANGzZEcnIy3nvvPaSnp9tlSGjGjBno2rUrFi1ahGHDhuHYsWNYvXo1Vq9eXeG6zYxGI9atW4fRo0fD2dm+/0QMHDgQCxcuRMOGDdG6dWucOnUKy5cvx9ixY+1S/86dOyGKIkJCQnDhwgW8+uqrCAkJwQsvvGBzXWX9DE2fPh2LFi1Cs2bN0KxZMyxatAhubm4YMWKEXeq/d+8erl27Jq0NZP4F6u/vb9W6Vg+qPzAwEP/4xz9w8uRJ/PzzzzAYDNLPsZeXFxQKRYXq9/b2xsKFCzFo0CAEBAQgJSUFn376KW7cuGHVEg5l/dkUD29yuRz+/v4ICQkps+6y6vfy8sL8+fPx7LPPIiAgAFeuXMEbb7wBHx8fPPPMMxWuv2HDhnj11VcxfPhwPPnkk+jZsyeioqKwfft27N+/v8J1A0B6ejq+/fZbLFu2zKr22lJ/9+7d8eqrr8LV1RXBwcE4cOAANmzYgOXLl9ul/m+//Rb169dHw4YNcfr0aUybNg1DhgyxuIHBYRx+HxtViX379okAShyjR4+ucN2l1QtAXLduXYXrFkVRHDt2rBgcHCwqFAqxfv36Yu/evcVdu3bZpe77sedt98OHDxcDAgJEuVwuBgYGikOHDhXPnj1rl7pFURS3b98uhoaGikqlUmzRooW4evVqu9UtiqK4c+dOEYCYkJBg13pFURTT09PFadOmiQ0bNhRdXFzEJk2aiG+++aao0+nsUv/WrVvFJk2aiAqFQvT39xcnTZokpqWllauusn6GjEajOG/ePNHf319UKpXik08+KZ4+fdpu9a9bt67U6/Pmzatw/eZb+Us79u3bV+H6c3JyxGeeeUYMDAwUFQqFGBAQIA4aNEg8duyYXf5sirP1tvsH1Z+dnS327dtXrF+/viiXy8WGDRuKo0ePFq9du2aX+s3Wrl0rNm3aVHRxcRHbtWsn/vDDD3ar+/PPPxddXV3L9Xe/rPoTExPFMWPGiIGBgaKLi4sYEhIiLlu2zOqlOcqq/+OPPxYbNGgg/dm/9dZbdvv3oSyCKIpiudMUERERUS3AOURERERU5zEQERERUZ3HQERERER1HgMRERER1XkMRERERFTnMRARERFRncdARERERHUeAxERERHVeQxERERWEgQBP/zwQ1U3g4gcgIGIiGqEMWPGQBCEEke/fv2qumlEVAtwc1ciqjH69euHdevWWZxTKpVV1Boiqk3YQ0RENYZSqZR2ezcfnp6eAEzDWatWrUL//v3h6uqKxo0b49tvv7V4/+nTp9GrVy+4urrC29sbEyZMQGZmpkWZL7/8Eq1bt4ZSqURAQAAmT55scf3u3bt45pln4ObmhmbNmuGnn36SrqWmpmLkyJGoX78+XF1d0axZsxIBjoiqJwYiIqo13n77bTz77LP4448/MGrUKDz33HOIj48HAGRnZ6Nfv37w9PTE8ePH8e2332L37t0WgWfVqlWYNGkSJkyYgNOnT+Onn35C06ZNLT5jwYIFGDZsGP7880889dRTGDlyJO7duyd9/l9//YVff/0V8fHxWLVqFXx8fCrvD4CIyk8kIqoBRo8eLcpkMlGlUlkc7777riiKoghAfPnlly3e07lzZ/GVV14RRVEUV69eLXp6eoqZmZnS9R07dohOTk5iUlKSKIqiGBgYKL755pv3bQMA8a233pJeZ2ZmioIgiL/++qsoiqI4cOBA8YUXXrDPFyaiSsU5RERUY/Ts2ROrVq2yOOfl5SU9DwsLs7gWFhaGuLg4AEB8fDzatWsHlUolXX/88cdhNBqRkJAAQRBw69Yt9O7d+4FtaNu2rfRcpVJBrVYjOTkZAPDKK6/g2WefxcmTJ9G3b18MGTIEXbt2Ldd3JaLKxUBERDWGSqUqMYRVFkEQAACiKErPSyvj6upqVX1yubzEe41GIwCgf//+uHr1Knbs2IHdu3ejd+/emDRpEj788EOb2kxElY9ziIio1oiJiSnxukWLFgCAVq1aIS4uDllZWdL133//HU5OTmjevDnUajUaNWqEPXv2VKgN9evXx5gxY7Bp0yZ89NFHWL16dYXqI6LKwR4iIqoxdDodkpKSLM45OztLE5e//fZbdOrUCd26dcPmzZtx7NgxrF27FgAwcuRIzJs3D6NHj8b8+fNx584dTJkyBZGRkfDz8wMAzJ8/Hy+//DJ8fX3Rv39/ZGRk4Pfff8eUKVOsat8777yDjh07onXr1tDpdPj555/RsmVLO/4JEJGjMBARUY0RFRWFgIAAi3MhISH4+++/AZjuANuyZQsmTpwIf39/bN68Ga1atQIAuLm5YefOnZg2bRoeffRRuLm54dlnn8Xy5culukaPHo3c3FysWLECs2fPho+PD/7xj39Y3T6FQoG5c+fiypUrcHV1xRNPPIEtW7bY4ZsTkaMJoiiKVd0IIqKKEgQB27Ztw5AhQ6q6KURUA3EOEREREdV5DERERERU53EOERHVChz9J6KKYA8RERER1XkMRERERFTnMRARERFRncdARERERHUeAxERERHVeQxEREREVOcxEBEREVGdx0BEREREdd7/Aw4aJqRFh3RuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.Figure(figsize=(14,6), dpi=100)\n",
    "\n",
    "plt.plot(root_metrics_df[\"rmse\"], label = 'Training error')\n",
    "plt.plot(root_metrics_df[\"val_rmse\"], label = 'Validation error')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "# plt.xlim([0, epochs])\n",
    "plt.xticks(range(1,20))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m506/506\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  686.3221619890909\n",
      "MAE:  382.1221505234525\n"
     ]
    }
   ],
   "source": [
    "# Report regression performance on test set\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** In this workshop notebook, you learned how to use the keras framework for both classifcation and regression prediction. The classification example above was for a binary output (cancer cells being benign or malignant). Now we would like to employ neural network for multi-class classification on the flower example.\n",
    "\n",
    "1. Use the `../data/iris.csv` data set and preproccess it as usual\n",
    "2. Think of an architecture you would employ to enable multi-class classification. You can get some inspiration here: https://keras.io/guides/sequential_model/\n",
    "3. Implement a pipeline that consists of the following:\n",
    "    1. Train the model on training data set\n",
    "    3. Evaluate and visualize loss on training and validation set throughout the fitting of the network\n",
    "    4. [optional] Visualize classification along relevant dimensions\n",
    "4. Use that pipeline to test different architectures / hyperparameters\n",
    "5. Give a reasoning for complexity vs. performance of your final model - is this the best overall model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
