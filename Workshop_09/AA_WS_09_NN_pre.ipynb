{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "In this workshop we provide a very short introduction to neural networks in Python. This is very far from a comprehensive coverage of the topic but can provide a quick start for those who wish to learn more about the topic in their own time. We will cover a classification and a regression taks using `keras` as our python package of choice. If you want to try and implement a NN from scratch there are several good online tutorials that can help you do so (see [here](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6) for example). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological inspiration\n",
    "The (for our purpose) smallest stand-alone element in the human brain is the neuron. Its understanding and computational recreation build the foundation for ANNs. A simplified image of a \"real\" neuron can be seen below\n",
    "\n",
    "![](bio_neuron.png)\n",
    "\n",
    "Dendrites are connecting to the axons (or \"outputs\") of other neurons, for instance nerves in the sensory system or other processing neurons. In the nucleus, these input signals are aggregated and forwarded through the axon. The axon terminals then connect to further neurons to build the neural network. The connection between axon terminal and dendrite is what we are calling a synapse. In the human brain, there are billions of neurons and $10^{14} - 10^{15}$ synapses in the human brain. If each synapse (or more precisely, its connection strength) would be represented by 8 bits or one byte, just storing these numbers would take 1000 TB already. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational implementation\n",
    "To recreate neural networks artificially, neurons have to be defined. The common mathematical model used for this purpose is depicted below.\n",
    "\n",
    "![](math_neuron.jpeg)\n",
    "\n",
    "From a certain number of input synapses $x_i$, signals come in with a weight factor of $w_i$. This represents the strength of the synapse. In the _nuclues_ these weighted inputs are aggregated and a bias is added. (The bias is not shown in every model, but it does make the neural network more generalizable). After adding of the weighted inputs and the bias, everything is fed into a (non-linear) activation function. The output is then either fed forward to further neurons or is the output of your neural network. If there is only one neuron that takes direct inputs and whose output is your interest, the model is called a single-layer perceptron. Many of these neurons can create almost arbitrary logical connections and functions, making ANNs very powerful. In this case, we are talking about a multi-layer perceptron (MLP) model. \n",
    "\n",
    "![](mlp-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "The activation function is (to some degree) the hear of the neural network. Without a non-linear activation function, all hidden layers do not add any value, but are instead a complicated way to represent a liner model. Only with a non-linear activation function, ANNs can recreate non-linear hypothesis functions. In the beginning of research on the ANNs in the scope of AI, typically a unit step was used as activation function. The unit step is $0$ for inputs smaller than $0$ and $1$ otherwise. The idea behind this is to recreate the behavior of a biological neuron that _fires_ if a certain threshold of inputs is exceeded. Today, other activation functions are more typically used. This is linked to better mathematical qualities in terms of learning behavior and convergence. Some of the most popular activation functions are:\n",
    "\n",
    "Sigmoid: $\\sigma(z) = \\frac{1}{1+exp(-z)}$\n",
    "\n",
    "Hyperbolic tangent: $\\sigma(z) = \\frac{2}{1+exp(-2z)} -1 $\n",
    "\n",
    "ReLU (Rectified Linear Unit): $\\sigma(z) = z\\quad  for\\ z>0,\\ 0\\ otherwise$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "As learning of ANNs is a non-trivial mathematical task, we are only aiming for an intuitive understanding here. Let's have a look at our complete MLP first.\n",
    "\n",
    "The general learning tasks consists of two steps, which are repeated until the algorithm converges:\n",
    "1. __Feedforward: Calculating the predicted output ŷ and the associated loss__. At first, we randomly assign values for the weights (and the biases). Based on the input features, the output value is calculated.\n",
    "2. __Backpropagation: Updating the weights W and biases b__. If the output value and the target value differ, the weights and biases are updated. To do this, it is calculated how much each weight and bias contributes to the error. Proportionally to this, they are then corrected (scaled with a small learning factor). In this sense, the updating rule has some similarity to gradient descent, only that is is propagated through the entire network, which is why this algorithm is called backpropagation.\n",
    "\n",
    "The training routine for a simple 2-layered MLP is shown in the below figure:\n",
    "\n",
    "![](training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "The main hyperparameters of an MLP are: \n",
    "\n",
    "1. Number of hidden layers\n",
    "1. Number of nodes\n",
    "4. Activation function\n",
    "\n",
    "The number of hidden layers and number of nodes (its activation function could be understood as a hyperparameter, but that is typically not done). The more layers and nodes there are (and the denser the network is, i.e. the more edges have a non-zero weight) the harder it gets to learn the model. That's the reason why bigger ANNs are normally not trained on a local computer anymore, but on specialized computers. Furthermore, there are additional libraries for python to improve the efficiency of ANNs, e.g. TensorFlow or Keras, which we take a first look at in today's tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras` is one of the most popular Deep Learning libraries. `PyTorch`, `PyTorch` and `Jax` are the most used numerical platforms in Python to build Deep Learning algorithms but they can be quite complex and difficult to use.\n",
    "\n",
    "Keras, by contrast is easy to use and is capable of running on top of multiple low-level tensor operation frameworks. The full documentation of the keras API can be found [here](https://keras.io).\n",
    "\n",
    "Note that `scikit learn` also features an MLP implementation (see [here](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)). Yet, `keras` has advanced to be one of the most popular frameworks used in practice, which is why we focus on it in this short tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `Keras` to command `PyTorch`, therefore we need to install both.\n",
    "PyTorch's installation method varies by platform and environment manager, all of the options are listed here: https://pytorch.org/get-started/locally/\n",
    "\n",
    "If you use the provided `environment.yml` specification, you can just recreate your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for classification in `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stay with our example, we will build a NN that predicts the class of a breast cancer by categorizing it as either malignant or begnign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# supress versioning warnings of keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because keras can work with multiple different backends, it is important to specify that we want to use PyTorch before importing keras for the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential # sequential model: https://keras.io/guides/sequential_model/\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Preparation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                       \n",
       "842302         M        17.99         10.38           122.8     1001.0   \n",
       "842517         M        20.57         17.77           132.9     1326.0   \n",
       "\n",
       "        smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                          \n",
       "842302          0.11840           0.27760          0.3001   \n",
       "842517          0.08474           0.07864          0.0869   \n",
       "\n",
       "        concave points_mean  symmetry_mean  ...  radius_worst  texture_worst  \\\n",
       "id                                          ...                                \n",
       "842302              0.14710         0.2419  ...         25.38          17.33   \n",
       "842517              0.07017         0.1812  ...         24.99          23.41   \n",
       "\n",
       "        perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                         \n",
       "842302            184.6      2019.0            0.1622             0.6656   \n",
       "842517            158.8      1956.0            0.1238             0.1866   \n",
       "\n",
       "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                              \n",
       "842302           0.7119                0.2654          0.4601   \n",
       "842517           0.2416                0.1860          0.2750   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "id                               \n",
       "842302                  0.11890  \n",
       "842517                  0.08902  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "cancer_df = pd.read_csv(\"../data/breast_cancer.csv\", index_col = \"id\")\n",
    "cancer_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and Y\n",
    "X = cancer_df.iloc[:,1:31] # include full feature vector\n",
    "y = cancer_df[\"diagnosis\"]\n",
    "\n",
    "\n",
    "# encode categorical target verctor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initializing and Training the ANN__\n",
    "\n",
    "We start by defining the type of model we want to build. There are two types of models available in Keras: the [Sequential model](https://keras.io/models/sequential/) and the Model class used with [functional API](https://keras.io/models/model/). Then we simply add the input-, 2 hidden- and output-layers.\n",
    "\n",
    "Between them, we are using [dropout](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer) to prevent overfitting (dropout rate should be between 20% and 50%).\n",
    "\n",
    "![](dropout.png)\n",
    "\n",
    "At every layer, we use “Dense” which means that the nodes are fully connected.\n",
    "\n",
    "The input-layer takes 30 inputs (because our feature vector includes 30 features) as input and outputs it with a shape of 16, which is the number of nodes in the first hidden layer that we define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pass the following parameters:\n",
    "\n",
    "- input_shape - number of columns of the dataset (only for input layer)\n",
    "\n",
    "- units - number of neurons and dimensionality of outputs to be fed to the next layer, if any\n",
    "\n",
    "- activation - activation function which is ReLU in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the input layer and the first hidden layer (with 30 nodes)\n",
    "classifier.add(Dense(input_shape = (30,), \n",
    "                     units=30,          #dimensionality of the output space (#nodes in the first hidden layer)\n",
    "                     activation='relu'))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an additional second layer, also with 15 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units= 15,\n",
    "                     activation='relu'))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the output layer. Since we perform a binary classification, a single output node suffices. We use a sigmoidal activation function for this last node which is often used when dealing with binary classfication problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units= 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compile the model to configure it for training. We add the following parameters:\n",
    "- `optimizer`: Here we use the adam optimizer, an optimizer with higher performance in many cases than stochastic gradient descent (SGD). See [here](https://keras.io/optimizers/) for a list of all optimzers implemented in `keras`.\n",
    "- `loss`: specifies the loss to be minimized. In this example we use binary crossentropy, a common loss for binary classification tasks. See [here](https://keras.io/losses/) for an overview of available losses in keras \n",
    "- `metrics`:  metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model and merely function as indicator of model performance to the data scientist. An overview ov available metrics can be found [here](https://keras.io/metrics/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer=\"adam\",    # Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments\n",
    "              loss=\"binary_crossentropy\",  # this is a good loss for binary classification\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                │        \u001b[38;5;34m930\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                │        \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411</span> (5.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,411\u001b[0m (5.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to train our model. We do this with a batch_size of 50 and for 100 epochs.\n",
    "\n",
    "- `batch_size` defines the number of samples that will be propagated through the network \n",
    "- `epoch` defines the number of iteration over the entire training data\n",
    "\n",
    "In general a larger batch-size results in faster training, but does not always converge fast. A smaller batch-size is slower in training but it can converge faster. This is definitely problem dependent and you need to try out a few different values (the standard batch-size is 32). The same goes for the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5913 - loss: 0.5998 \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.5146\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.3836\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.3443\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.2755\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2447\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.2087\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.2051\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1761\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.1473\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.1344\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1262\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1125\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.1180\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1215\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.1008\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0790\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1275\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0764\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0867\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0829\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.0700\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0646\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0712\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0778\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0713\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0618\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0615\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9837 - loss: 0.0618\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0545\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0627\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0607\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0648\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0486\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0413\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0573\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0439\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0457\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0531\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0582\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0428\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0422\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0495\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0448\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0303\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0330\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0400\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0499\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0402\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0511\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.0576\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0324\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0369\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0244\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0228\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0379\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0326\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0371\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0384\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0290\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0374\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0246\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0242\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0248\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0316 \n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0224\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0305\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0401\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0262\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0253\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0192\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0269\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0256\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0237\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0277\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0233\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0240\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0152\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0184\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0195\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0227\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0182\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0293\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0139\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0188\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0188\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0218\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0165\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0275\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0212\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0226\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0163\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0087\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0155\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0095\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0097\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0179\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0140\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17c28a290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Confusion Matrix\n",
      "[[105   3]\n",
      " [  1  62]]\n",
      "\n",
      "Accuracy\n",
      "0.9766\n",
      "\n",
      "Precision\n",
      "0.9538\n"
     ]
    }
   ],
   "source": [
    "# Report classification performance on test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "accuracy_score = accuracy_score(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "precision_score = precision_score(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "print(\"Accuracy\")\n",
    "print(round(accuracy_score, ndigits=4))\n",
    "print()\n",
    "print(\"Precision\")\n",
    "print(round(precision_score, ndigits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for regression in `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can also be trained for regression tasks. The logic is exactly the same, yet some of the parameters, such as loss, metrics, input and ouput as well as typical activation functions might have to be adapted to the specific case. There are a range of very good tutorial online which we encourage you to take a look at (for example [here](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)). \n",
    "\n",
    "We will cover a simple implimentation on the `Diamonds` dataset. The objective in this task is to predict the price of a particular dimond based on different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35235</th>\n",
       "      <td>0.39</td>\n",
       "      <td>Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>894</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31394</th>\n",
       "      <td>0.38</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>764</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.68</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36694</th>\n",
       "      <td>0.39</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>952</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9604</th>\n",
       "      <td>1.02</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4633</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.41</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22442</th>\n",
       "      <td>1.35</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>60.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10471</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "35235   0.39       Good     G    VVS2   63.4   57.0    894  4.62  4.65  2.94\n",
       "31394   0.38  Very Good     G     VS1   62.0   57.0    764  4.65  4.68  2.89\n",
       "36694   0.39      Ideal     G    VVS2   62.0   54.5    952  4.67  4.70  2.91\n",
       "9604    1.02       Good     D     SI2   63.4   59.0   4633  6.37  6.41  4.05\n",
       "22442   1.35      Ideal     G     VS1   60.9   54.0  10471  7.18  7.15  4.36"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "sns.heatmap(diamonds.isna(), ax=ax,\n",
    "           vmin=0, vmax=1, cmap=\"Reds\",\n",
    "           cbar_kws={\"ticks\":[0,1]})\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Show Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy variables\n",
    "\n",
    "Since in the diamond dataset we have three categorical input features, we need to convert them into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_I1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46082</th>\n",
       "      <td>0.50</td>\n",
       "      <td>62.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1738</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>3.16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52851</th>\n",
       "      <td>0.67</td>\n",
       "      <td>62.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2577</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42057</th>\n",
       "      <td>0.56</td>\n",
       "      <td>62.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1270</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.31</td>\n",
       "      <td>3.30</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30348</th>\n",
       "      <td>0.37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>728</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.57</td>\n",
       "      <td>2.91</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52625</th>\n",
       "      <td>0.33</td>\n",
       "      <td>60.7</td>\n",
       "      <td>55.0</td>\n",
       "      <td>551</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.73</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table  price     x     y     z  cut_Ideal  cut_Premium  \\\n",
       "46082   0.50   62.6   59.0   1738  5.03  5.06  3.16      False        False   \n",
       "52851   0.67   62.4   55.0   2577  5.60  5.62  3.50       True        False   \n",
       "42057   0.56   62.3   53.0   1270  5.28  5.31  3.30       True        False   \n",
       "30348   0.37   64.0   55.0    728  4.52  4.57  2.91      False        False   \n",
       "52625   0.33   60.7   55.0    551  4.48  4.51  2.73       True        False   \n",
       "\n",
       "       cut_Very Good  ...  color_I  color_J  clarity_IF  clarity_VVS1  \\\n",
       "46082           True  ...    False    False       False         False   \n",
       "52851          False  ...    False    False       False          True   \n",
       "42057          False  ...    False    False       False         False   \n",
       "30348           True  ...    False    False       False         False   \n",
       "52625          False  ...    False    False       False         False   \n",
       "\n",
       "       clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \\\n",
       "46082         False         True        False        False        False   \n",
       "52851         False        False        False        False        False   \n",
       "42057         False        False        False         True        False   \n",
       "30348         False        False         True        False        False   \n",
       "52625         False        False         True        False        False   \n",
       "\n",
       "       clarity_I1  \n",
       "46082       False  \n",
       "52851       False  \n",
       "42057       False  \n",
       "30348       False  \n",
       "52625       False  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.get_dummies(diamonds)\n",
    "diamonds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs and output\n",
    "\n",
    "X = diamonds.drop(\"price\", axis=1)\n",
    "y = diamonds[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing training data\n",
    "\n",
    "st_scaler = StandardScaler()\n",
    "st_scaler.fit(X_train)\n",
    "X_train_scaled = st_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [Dense(36, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "    Dense(36, activation=\"relu\"),\n",
    "     Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "\n",
    "model.compile(loss='mse',\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"mae\", \"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">972</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,332</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                │        \u001b[38;5;34m972\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                │      \u001b[38;5;34m1,332\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,341</span> (9.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,341\u001b[0m (9.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,341</span> (9.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,341\u001b[0m (9.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 27882592.0000 - mae: 3625.4453 - mse: 27882592.0000 - val_loss: 3777669.7500 - val_mae: 1295.5267 - val_mse: 3777669.7500\n",
      "Epoch 2/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2974550.5000 - mae: 1056.9423 - mse: 2974550.5000 - val_loss: 1259414.2500 - val_mae: 682.8646 - val_mse: 1259414.2500\n",
      "Epoch 3/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1470991.2500 - mae: 655.5848 - mse: 1470991.2500 - val_loss: 989482.4375 - val_mae: 606.5842 - val_mse: 989482.4375\n",
      "Epoch 4/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1073389.5000 - mae: 612.3300 - mse: 1073389.5000 - val_loss: 915435.2500 - val_mae: 577.7256 - val_mse: 915435.2500\n",
      "Epoch 5/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1100756.6250 - mae: 586.2534 - mse: 1100756.6250 - val_loss: 868910.5625 - val_mae: 555.1326 - val_mse: 868910.5625\n",
      "Epoch 6/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 763432.4375 - mae: 551.1021 - mse: 763432.4375 - val_loss: 840401.2500 - val_mae: 527.6292 - val_mse: 840401.2500\n",
      "Epoch 7/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 979054.0625 - mae: 540.4777 - mse: 979054.0625 - val_loss: 797183.9375 - val_mae: 511.3132 - val_mse: 797183.9375\n",
      "Epoch 8/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 954667.0000 - mae: 520.4095 - mse: 954667.0000 - val_loss: 768453.0625 - val_mae: 492.6441 - val_mse: 768453.0625\n",
      "Epoch 9/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 841799.5625 - mae: 499.4899 - mse: 841799.5625 - val_loss: 747908.0625 - val_mae: 478.8638 - val_mse: 747908.0625\n",
      "Epoch 10/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 804522.6250 - mae: 488.7465 - mse: 804522.6250 - val_loss: 719213.2500 - val_mae: 467.4925 - val_mse: 719213.2500\n",
      "Epoch 11/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 776682.6250 - mae: 475.5320 - mse: 776682.6250 - val_loss: 698013.4375 - val_mae: 453.5007 - val_mse: 698013.4375\n",
      "Epoch 12/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 756017.5000 - mae: 460.0625 - mse: 756017.5000 - val_loss: 702627.5000 - val_mae: 450.0627 - val_mse: 702627.5000\n",
      "Epoch 13/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 705733.1250 - mae: 452.9684 - mse: 705733.1250 - val_loss: 661208.0625 - val_mae: 434.2850 - val_mse: 661208.0625\n",
      "Epoch 14/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 772656.0625 - mae: 438.6325 - mse: 772656.0625 - val_loss: 646012.1875 - val_mae: 427.2712 - val_mse: 646012.1875\n",
      "Epoch 15/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627036.8750 - mae: 429.7557 - mse: 627036.8750 - val_loss: 630614.1875 - val_mae: 418.6808 - val_mse: 630614.1875\n",
      "Epoch 16/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 683867.1875 - mae: 422.2558 - mse: 683867.1875 - val_loss: 617287.3125 - val_mae: 411.3830 - val_mse: 617287.3125\n",
      "Epoch 17/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638128.1250 - mae: 410.2570 - mse: 638128.1250 - val_loss: 602723.3125 - val_mae: 405.0844 - val_mse: 602723.3125\n",
      "Epoch 18/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 583177.1250 - mae: 409.2721 - mse: 583177.1250 - val_loss: 591808.6875 - val_mae: 398.8679 - val_mse: 591808.6875\n",
      "Epoch 19/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635361.7500 - mae: 399.9141 - mse: 635361.7500 - val_loss: 580181.1250 - val_mae: 394.3736 - val_mse: 580181.1250\n",
      "Epoch 20/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 540662.9375 - mae: 399.5081 - mse: 540662.9375 - val_loss: 578829.6875 - val_mae: 392.3174 - val_mse: 578829.6875\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train.values,\n",
    "                   epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2591.8696],\n",
       "       [ 5101.0566],\n",
       "       [10923.248 ],\n",
       "       [ 1527.0719],\n",
       "       [ 6691.058 ],\n",
       "       [ 3455.574 ],\n",
       "       [ 6319.823 ],\n",
       "       [ 1091.8385],\n",
       "       [ 4158.49  ],\n",
       "       [ 9664.818 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.900884e+07</td>\n",
       "      <td>2847.190918</td>\n",
       "      <td>1.900884e+07</td>\n",
       "      <td>3.777670e+06</td>\n",
       "      <td>1295.526733</td>\n",
       "      <td>3.777670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.112673e+06</td>\n",
       "      <td>898.090881</td>\n",
       "      <td>2.112673e+06</td>\n",
       "      <td>1.259414e+06</td>\n",
       "      <td>682.864624</td>\n",
       "      <td>1.259414e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.235172e+06</td>\n",
       "      <td>639.181885</td>\n",
       "      <td>1.235172e+06</td>\n",
       "      <td>9.894824e+05</td>\n",
       "      <td>606.584167</td>\n",
       "      <td>9.894824e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.105440e+06</td>\n",
       "      <td>601.056519</td>\n",
       "      <td>1.105440e+06</td>\n",
       "      <td>9.154352e+05</td>\n",
       "      <td>577.725586</td>\n",
       "      <td>9.154352e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043516e+06</td>\n",
       "      <td>577.251221</td>\n",
       "      <td>1.043516e+06</td>\n",
       "      <td>8.689106e+05</td>\n",
       "      <td>555.132568</td>\n",
       "      <td>8.689106e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.928236e+05</td>\n",
       "      <td>553.581116</td>\n",
       "      <td>9.928236e+05</td>\n",
       "      <td>8.404012e+05</td>\n",
       "      <td>527.629211</td>\n",
       "      <td>8.404012e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.469386e+05</td>\n",
       "      <td>529.720947</td>\n",
       "      <td>9.469386e+05</td>\n",
       "      <td>7.971839e+05</td>\n",
       "      <td>511.313202</td>\n",
       "      <td>7.971839e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.087519e+05</td>\n",
       "      <td>512.429138</td>\n",
       "      <td>9.087519e+05</td>\n",
       "      <td>7.684531e+05</td>\n",
       "      <td>492.644073</td>\n",
       "      <td>7.684531e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.759296e+05</td>\n",
       "      <td>496.009857</td>\n",
       "      <td>8.759296e+05</td>\n",
       "      <td>7.479081e+05</td>\n",
       "      <td>478.863800</td>\n",
       "      <td>7.479081e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.429551e+05</td>\n",
       "      <td>480.892822</td>\n",
       "      <td>8.429551e+05</td>\n",
       "      <td>7.192132e+05</td>\n",
       "      <td>467.492523</td>\n",
       "      <td>7.192132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.149738e+05</td>\n",
       "      <td>468.389832</td>\n",
       "      <td>8.149738e+05</td>\n",
       "      <td>6.980134e+05</td>\n",
       "      <td>453.500732</td>\n",
       "      <td>6.980134e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.874948e+05</td>\n",
       "      <td>455.240753</td>\n",
       "      <td>7.874948e+05</td>\n",
       "      <td>7.026275e+05</td>\n",
       "      <td>450.062714</td>\n",
       "      <td>7.026275e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.648482e+05</td>\n",
       "      <td>446.506897</td>\n",
       "      <td>7.648482e+05</td>\n",
       "      <td>6.612081e+05</td>\n",
       "      <td>434.285004</td>\n",
       "      <td>6.612081e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.415375e+05</td>\n",
       "      <td>436.223724</td>\n",
       "      <td>7.415375e+05</td>\n",
       "      <td>6.460122e+05</td>\n",
       "      <td>427.271240</td>\n",
       "      <td>6.460122e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.209482e+05</td>\n",
       "      <td>428.840088</td>\n",
       "      <td>7.209482e+05</td>\n",
       "      <td>6.306142e+05</td>\n",
       "      <td>418.680786</td>\n",
       "      <td>6.306142e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.028751e+05</td>\n",
       "      <td>420.467957</td>\n",
       "      <td>7.028751e+05</td>\n",
       "      <td>6.172873e+05</td>\n",
       "      <td>411.383026</td>\n",
       "      <td>6.172873e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.850006e+05</td>\n",
       "      <td>413.585388</td>\n",
       "      <td>6.850006e+05</td>\n",
       "      <td>6.027233e+05</td>\n",
       "      <td>405.084381</td>\n",
       "      <td>6.027233e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.689462e+05</td>\n",
       "      <td>407.577057</td>\n",
       "      <td>6.689462e+05</td>\n",
       "      <td>5.918087e+05</td>\n",
       "      <td>398.867859</td>\n",
       "      <td>5.918087e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.528562e+05</td>\n",
       "      <td>402.540527</td>\n",
       "      <td>6.528562e+05</td>\n",
       "      <td>5.801811e+05</td>\n",
       "      <td>394.373596</td>\n",
       "      <td>5.801811e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.388614e+05</td>\n",
       "      <td>397.278473</td>\n",
       "      <td>6.388614e+05</td>\n",
       "      <td>5.788297e+05</td>\n",
       "      <td>392.317444</td>\n",
       "      <td>5.788297e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss          mae           mse      val_loss      val_mae  \\\n",
       "0   1.900884e+07  2847.190918  1.900884e+07  3.777670e+06  1295.526733   \n",
       "1   2.112673e+06   898.090881  2.112673e+06  1.259414e+06   682.864624   \n",
       "2   1.235172e+06   639.181885  1.235172e+06  9.894824e+05   606.584167   \n",
       "3   1.105440e+06   601.056519  1.105440e+06  9.154352e+05   577.725586   \n",
       "4   1.043516e+06   577.251221  1.043516e+06  8.689106e+05   555.132568   \n",
       "5   9.928236e+05   553.581116  9.928236e+05  8.404012e+05   527.629211   \n",
       "6   9.469386e+05   529.720947  9.469386e+05  7.971839e+05   511.313202   \n",
       "7   9.087519e+05   512.429138  9.087519e+05  7.684531e+05   492.644073   \n",
       "8   8.759296e+05   496.009857  8.759296e+05  7.479081e+05   478.863800   \n",
       "9   8.429551e+05   480.892822  8.429551e+05  7.192132e+05   467.492523   \n",
       "10  8.149738e+05   468.389832  8.149738e+05  6.980134e+05   453.500732   \n",
       "11  7.874948e+05   455.240753  7.874948e+05  7.026275e+05   450.062714   \n",
       "12  7.648482e+05   446.506897  7.648482e+05  6.612081e+05   434.285004   \n",
       "13  7.415375e+05   436.223724  7.415375e+05  6.460122e+05   427.271240   \n",
       "14  7.209482e+05   428.840088  7.209482e+05  6.306142e+05   418.680786   \n",
       "15  7.028751e+05   420.467957  7.028751e+05  6.172873e+05   411.383026   \n",
       "16  6.850006e+05   413.585388  6.850006e+05  6.027233e+05   405.084381   \n",
       "17  6.689462e+05   407.577057  6.689462e+05  5.918087e+05   398.867859   \n",
       "18  6.528562e+05   402.540527  6.528562e+05  5.801811e+05   394.373596   \n",
       "19  6.388614e+05   397.278473  6.388614e+05  5.788297e+05   392.317444   \n",
       "\n",
       "         val_mse  \n",
       "0   3.777670e+06  \n",
       "1   1.259414e+06  \n",
       "2   9.894824e+05  \n",
       "3   9.154352e+05  \n",
       "4   8.689106e+05  \n",
       "5   8.404012e+05  \n",
       "6   7.971839e+05  \n",
       "7   7.684531e+05  \n",
       "8   7.479081e+05  \n",
       "9   7.192132e+05  \n",
       "10  6.980134e+05  \n",
       "11  7.026275e+05  \n",
       "12  6.612081e+05  \n",
       "13  6.460122e+05  \n",
       "14  6.306142e+05  \n",
       "15  6.172873e+05  \n",
       "16  6.027233e+05  \n",
       "17  5.918087e+05  \n",
       "18  5.801811e+05  \n",
       "19  5.788297e+05  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4359.913073</td>\n",
       "      <td>1943.622841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1453.503698</td>\n",
       "      <td>1122.236272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111.382697</td>\n",
       "      <td>994.727318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1051.399068</td>\n",
       "      <td>956.783805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021.526064</td>\n",
       "      <td>932.153723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>996.405320</td>\n",
       "      <td>916.734013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>973.107715</td>\n",
       "      <td>892.851576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>953.284814</td>\n",
       "      <td>876.614546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>935.911087</td>\n",
       "      <td>864.816780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>918.125876</td>\n",
       "      <td>848.064414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902.758966</td>\n",
       "      <td>835.471985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>887.409009</td>\n",
       "      <td>838.228787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>874.556030</td>\n",
       "      <td>813.147012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>861.125717</td>\n",
       "      <td>803.748834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>849.086678</td>\n",
       "      <td>794.112201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>838.376482</td>\n",
       "      <td>785.676341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>827.647645</td>\n",
       "      <td>776.352570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>817.891305</td>\n",
       "      <td>769.291029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>807.995166</td>\n",
       "      <td>761.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>799.288082</td>\n",
       "      <td>760.808575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rmse     val_rmse\n",
       "0   4359.913073  1943.622841\n",
       "1   1453.503698  1122.236272\n",
       "2   1111.382697   994.727318\n",
       "3   1051.399068   956.783805\n",
       "4   1021.526064   932.153723\n",
       "5    996.405320   916.734013\n",
       "6    973.107715   892.851576\n",
       "7    953.284814   876.614546\n",
       "8    935.911087   864.816780\n",
       "9    918.125876   848.064414\n",
       "10   902.758966   835.471985\n",
       "11   887.409009   838.228787\n",
       "12   874.556030   813.147012\n",
       "13   861.125717   803.748834\n",
       "14   849.086678   794.112201\n",
       "15   838.376482   785.676341\n",
       "16   827.647645   776.352570\n",
       "17   817.891305   769.291029\n",
       "18   807.995166   761.696216\n",
       "19   799.288082   760.808575"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_metrics_df = history_df[[\"mse\", \"val_mse\"]].apply(np.sqrt)\n",
    "root_metrics_df.rename({\"mse\":\"rmse\", \"val_mse\":\"val_rmse\"}, axis=1, inplace=True)\n",
    "root_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGyCAYAAAAFw9vDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzC0lEQVR4nO3deVyU1eIG8OdlmBlgGEYW2RJRU3FBzaUUs9xQtNyye/WmkqZp5b6V2aZ2c6vU6vrL0kxzKb3dsjILxTVNcUEpNcJ9B1GEYR+Gmff3xzAvDKDMwAzr8/183s/MvO+ZM2dM5Omc854jiKIogoiIiKgOc6rqBhARERFVNQYiIiIiqvMYiIiIiKjOYyAiIiKiOo+BiIiIiOo8BiIiIiKq8xiIiIiIqM5jICIiIqI6j4GIiIiI6jznqm5ATWE0GnHr1i2o1WoIglDVzSEiIiIriKKIjIwMBAYGwsnpAf1AYjWxaNEiEYA4bdo06dzo0aNFABZH586dLd6Xm5srTp48WfT29hbd3NzEgQMHitevX7coc+/ePXHUqFGih4eH6OHhIY4aNUpMTU21qX3Xr18v0RYePHjw4MGDR804imeD4qpFD9Hx48exevVqtG3btsS1fv36Yd26ddJrhUJhcX369OnYvn07tmzZAm9vb8yaNQsDBgxAbGwsZDIZAGDEiBG4ceMGoqKiAAATJkxAZGQktm/fbnUb1Wo1AOD69evw8PCw+TsSERFR5UtPT0dQUJD0e/x+qjwQZWZmYuTIkVizZg3ee++9EteVSiX8/f1Lfa9Wq8XatWuxceNGhIeHAwA2bdqEoKAg7N69GxEREYiPj0dUVBRiYmLQuXNnAMCaNWsQFhaGhIQEhISEWNVO8zCZh4cHAxEREVENU9Z0lyqfVD1p0iQ8/fTTUqApbv/+/fD19UXz5s0xfvx4JCcnS9diY2Oh1+vRt29f6VxgYCBCQ0Nx+PBhAMCRI0eg0WikMAQAXbp0gUajkcqURqfTIT093eIgIiKi2qlKe4i2bNmCkydP4vjx46Ve79+/P/75z38iODgYly9fxttvv41evXohNjYWSqUSSUlJUCgU8PT0tHifn58fkpKSAABJSUnw9fUtUbevr69UpjSLFy/GggULKvDtiIiIqKaoskB0/fp1TJs2Dbt27YKLi0upZYYPHy49Dw0NRadOnRAcHIwdO3Zg6NCh961bFEWLrrHSusmKlylu7ty5mDlzpvTaPAZJREREtU+VBaLY2FgkJyejY8eO0jmDwYDffvsNK1euhE6nkyZFmwUEBCA4OBjnz58HAPj7+yMvLw+pqakWvUTJycno2rWrVOb27dslPv/OnTvw8/O7b/uUSiWUSmWFviMRUV1nMBig1+uruhlUi8nl8hJ5oTyqLBD17t0bp0+ftjj3wgsvoEWLFpgzZ06pXy4lJQXXr19HQEAAAKBjx46Qy+WIjo7GsGHDAACJiYk4c+YM3n//fQBAWFgYtFotjh07hsceewwAcPToUWi1Wik0ERGRfYmiiKSkJKSlpVV1U6gOqFevHvz9/Su0TmCVBSK1Wo3Q0FCLcyqVCt7e3ggNDUVmZibmz5+PZ599FgEBAbhy5QreeOMN+Pj44JlnngEAaDQajBs3DrNmzYK3tze8vLwwe/ZstGnTRpqk3bJlS/Tr1w/jx4/H559/DsB02/2AAQOsvsOMiIhsYw5Dvr6+cHNz44K25BCiKCI7O1u64crcYVIeVX7b/f3IZDKcPn0aGzZsQFpaGgICAtCzZ09s3brVYi2BFStWwNnZGcOGDUNOTg569+6N9evXW/Qwbd68GVOnTpXuRhs0aBBWrlxZ6d+JiKguMBgMUhjy9vau6uZQLefq6grANF3G19e33MNngiiKoj0bVlulp6dDo9FAq9VyHSIiogfIzc3F5cuX0ahRI+mXFZEj5eTk4MqVK2jcuHGJG7Ws/f1d5esQERFR7cRhMqos9vi7xkBEREREdR4DERERkYP06NED06dPt7r8lStXIAgC4uLiHNYmKl21nVRNRERUWcoachk9ejTWr19vc73ff/895HK51eWDgoKQmJgIHx8fmz+LKoaBqIpl6vJxN0MHb3cF1C7W/9AQEZH9JCYmSs+3bt2Kd955BwkJCdK54pPD9Xq9VUHHy8vLpnbIZLL7bmhe1fLy8qBQKCzOiaIIg8EAZ2fb4kR53+dIHDKrYi+sO4YeH+7Hb+fuVnVTiIjqLH9/f+nQaDQQBEF6nZubi3r16uG///0vevToARcXF2zatAkpKSl47rnn0KBBA7i5uaFNmzb45ptvLOotPmTWqFEjLFq0CGPHjoVarUbDhg2xevVq6XrxIbP9+/dDEATs2bMHnTp1gpubG7p27WoR1gDgvffeg6+vL9RqNV588UW8/vrreOSRRx74nf/66y889dRTcHd3h5+fHyIjI3H3buHvoh49emDy5MmYOXMmfHx80KdPH6k9O3fuRKdOnaBUKnHw4EHodDpMnToVvr6+cHFxQbdu3Sz2Kb3f+6oTBqIq5q0ybQ+SkqWr4pYQETmGKIrIzsuvksOeK8vMmTMHU6dORXx8PCIiIpCbm4uOHTvi559/xpkzZzBhwgRERkbi6NGjD6xn2bJl6NSpE06dOoWJEyfilVdewd9///3A97z55ptYtmwZTpw4AWdnZ4wdO1a6tnnzZixcuBBLly5FbGwsGjZsiFWrVj2wvsTERHTv3h2PPPIITpw4gaioKNy+fVva9cHsq6++grOzM37//XdpcWMAeO2117B48WLEx8ejbdu2eO211/Ddd9/hq6++wsmTJ9G0aVNERETg3r17FvUVf191Un36quooH7Wp+/FuZl4Vt4SIyDFy9Aa0emdnlXz2X+9GwE1hn19106dPL7Gx+OzZs6XnU6ZMQVRUFL799lt07tz5vvU89dRTmDhxIgBTyFqxYgX279+PFi1a3Pc9CxcuRPfu3QEAr7/+Op5++mnk5ubCxcUF//nPfzBu3Di88MILAIB33nkHu3btQmZm5n3rW7VqFTp06IBFixZJ57788ksEBQXh3LlzaN68OQCgadOm0lZYgGkFcgB499130adPHwBAVlYWVq1ahfXr16N///4AgDVr1iA6Ohpr167Fq6++Kr2/6PuqG/YQVTFzD9HdTPYQERFVZ506dbJ4bTAYsHDhQrRt2xbe3t5wd3fHrl27cO3atQfWU7RnxDw0Z956wpr3mLenML8nISFB2qvTrPjr4mJjY7Fv3z64u7tLhzmQXbx4USpX/DuXdv7ixYvQ6/V4/PHHpXNyuRyPPfYY4uPj7/u+6oY9RFXMR10wZMZARES1lKtchr/ejaiyz7YXlUpl8XrZsmVYsWIFPvroI7Rp0wYqlQrTp09HXt6De/yLT8YWBAFGo9Hq95jviCv6nuJ3yZU1VGg0GjFw4EAsXbq0xLWi+4EV/86lnTd/VmltKH7ufvVVBwxEVcxHZRoyS+GQGRHVUoIg2G3Yqjo5ePAgBg8ejFGjRgEwhYzz58+jZcuWldqOkJAQHDt2DJGRkdK5EydOPPA9HTp0wHfffYdGjRpV+E6vpk2bQqFQ4NChQxgxYgQA0114J06csGkNpqrGIbMq5u3OITMiopqoadOmiI6OxuHDhxEfH4+XXnpJmmNTmaZMmYK1a9fiq6++wvnz5/Hee+/hzz//fODaSpMmTcK9e/fw3HPP4dixY7h06RJ27dqFsWPHwmAw2PT5KpUKr7zyCl599VVERUXhr7/+wvjx45GdnY1x48ZV9OtVmtoX2WsYH3f2EBER1URvv/02Ll++jIiICLi5uWHChAkYMmQItFptpbZj5MiRuHTpEmbPno3c3FwMGzYMY8aMwbFjx+77nsDAQPz++++YM2cOIiIioNPpEBwcjH79+sHJyfa+kiVLlsBoNCIyMhIZGRno1KkTdu7cCU9Pz4p8tUrF3e6t5Kjd7rU5erRbsAsA8Pe/+8HFjuPdRERVwbzbfWk7j1Pl6NOnD/z9/bFx48aqbkqleNDfOWt/f7OHqIp5uDhDIXNCnsGIlKw8PFTPtew3ERERFcjOzsZnn32GiIgIyGQyfPPNN9i9ezeio6Orumk1CucQVTFBEOAtDZtxHhEREdlGEAT88ssveOKJJ9CxY0ds374d3333HcLDw6u6aTUKe4iqAW93BRK1uZxYTURENnN1dcXu3buruhk1HnuIqgEf6U4zTqwmIiKqCgxE1QBXqyYiIqpaDETVgHk/M956T0REVDUYiKoBHxW37yAiIqpKDETVgPkuM84hIiIiqhoMRNWAD7fvICIiqlIMRNUAe4iIiGqHHj16WGxo2qhRI3z00UcPfI8gCPjhhx8q/Nn2qqeuYiCqBsw9RPeydDAauZMKEVFlGzhw4H0XMjxy5AgEQcDJkydtrvf48eOYMGFCRZtnYf78+XjkkUdKnE9MTET//v3t+ll1CQNRNeClMvUQGUUgLUdfxa0hIqp7xo0bh7179+Lq1aslrn355Zd45JFH0KFDB5vrrV+/Ptzc3OzRxDL5+/tDqVRWymfZQq8v+XuttHPlrcteGIiqAbnMCfXc5AA4j4iIqCoMGDAAvr6+WL9+vcX57OxsbN26FePGjUNKSgqee+45NGjQAG5ubmjTpg2++eabB9ZbfMjs/PnzePLJJ+Hi4oJWrVqVut/YnDlz0Lx5c7i5uaFJkyZ4++23pSCwfv16LFiwAH/88QcEQYAgCFKbiw+ZnT59Gr169YKrqyu8vb0xYcIEZGZmStfHjBmDIUOG4MMPP0RAQAC8vb0xadKkMkPH9u3b0bFjR7i4uKBJkyZYsGAB8vPzpeuCIOCzzz7D4MGDoVKp8N5770m9Wl9++SWaNGkCpVIJURRx7do1DB48GO7u7vDw8MCwYcNw+/Ztqa77vc8RuHVHNeHjrkRath53M3Vo7qeu6uYQEdmPKAL67Kr5bLkbIAhlFnN2dsbzzz+P9evX45133oFQ8J5vv/0WeXl5GDlyJLKzs9GxY0fMmTMHHh4e2LFjByIjI9GkSRN07ty5zM8wGo0YOnQofHx8EBMTg/T0dIv5RmZqtRrr169HYGAgTp8+jfHjx0OtVuO1117D8OHDcebMGURFRUnbdWg0mhJ1ZGdno1+/fujSpQuOHz+O5ORkvPjii5g8ebJF6Nu3bx8CAgKwb98+XLhwAcOHD8cjjzyC8ePHl/oddu7ciVGjRuGTTz7BE088gYsXL0pDgvPmzZPKzZs3D4sXL8aKFSsgk8mwbt06XLhwAf/973/x3XffQSaTAQCGDBkClUqFAwcOID8/HxMnTsTw4cOxf/9+qa7S3ucIDETVhLdKgQvgxGoiqoX02cCiwKr57DduAQqVVUXHjh2LDz74APv370fPnj0BmIbLhg4dCk9PT3h6emL27NlS+SlTpiAqKgrffvutVYFo9+7diI+Px5UrV9CgQQMAwKJFi0rM+3nrrbek540aNcKsWbOwdetWvPbaa3B1dYW7uzucnZ3h7+9/38/avHkzcnJysGHDBqhUpu+/cuVKDBw4EEuXLoWfnx8AwNPTEytXroRMJkOLFi3w9NNPY8+ePfcNRAsXLsTrr7+O0aNHAwCaNGmCf//733jttdcsAtGIESMwduxYi/fm5eVh48aNqF+/PgAgOjoaf/75Jy5fvoygoCAAwMaNG9G6dWscP34cjz76aKnvcxQGomrCPLGaizMSEVWNFi1aoGvXrvjyyy/Rs2dPXLx4EQcPHsSuXbsAAAaDAUuWLMHWrVtx8+ZN6HQ66HQ6KXCUJT4+Hg0bNpTCEACEhYWVKPe///0PH330ES5cuIDMzEzk5+fDw8PDpu8SHx+Pdu3aWbTt8ccfh9FoREJCghSIWrdubdHrEhAQgNOnT9+33tjYWBw/fhwLFy6UzhkMBuTm5iI7O1uaL9WpU6cS7w0ODrYINfHx8QgKCpLCEAC0atUK9erVQ3x8vBSIir/PURiIqgkfd27fQUS1lNzN1FNTVZ9tg3HjxmHy5Mn4v//7P6xbtw7BwcHo3bs3AGDZsmVYsWIFPvroI7Rp0wYqlQrTp09HXp51/26XNvdFKDacFxMTg3/9619YsGABIiIioNFosGXLFixbtsym7yGKYom6S/tMuVxe4prRaLxvvUajEQsWLMDQoUNLXHNxcZGelxYSi5+7XxuLn7c2cFYUA1E14c3FGYmothIEq4etqtqwYcMwbdo0fP311/jqq68wfvx46ZfzwYMHMXjwYIwaNQqAKRycP38eLVu2tKruVq1a4dq1a7h16xYCA01DiEeOHLEo8/vvvyM4OBhvvvmmdK74nW8KhQIGg6HMz/rqq6+QlZUlBYrff/8dTk5OaN68uVXtLU2HDh2QkJCApk2blruOom28du0arl+/LvUS/fXXX9BqtVb/mdoT7zKrJgpXq2YPERFRVXF3d8fw4cPxxhtv4NatWxgzZox0rWnTpoiOjsbhw4cRHx+Pl156CUlJSVbXHR4ejpCQEDz//PP4448/cPDgQYvgY/6Ma9euYcuWLbh48SI++eQTbNu2zaJMo0aNcPnyZcTFxeHu3bvQ6Ur+j/TIkSPh4uKC0aNH48yZM9i3bx+mTJmCyMhIabisPN555x1s2LAB8+fPx9mzZxEfH4+tW7dazHuyVnh4ONq2bYuRI0fi5MmTOHbsGJ5//nl079691CE3R2MgqibMq1WnZLGHiIioKo0bNw6pqakIDw9Hw4YNpfNvv/02OnTogIiICPTo0QP+/v4YMmSI1fU6OTlh27Zt0Ol0eOyxx/Diiy9azMUBgMGDB2PGjBmYPHkyHnnkERw+fBhvv/22RZlnn30W/fr1Q8+ePVG/fv1Sb/13c3PDzp07ce/ePTz66KP4xz/+gd69e2PlypW2/WEUExERgZ9//hnR0dF49NFH0aVLFyxfvhzBwcE212VeJsDT0xNPPvkkwsPD0aRJE2zdurVCbSwvQXTUDf21THp6OjQaDbRarc2T26wRe/Uenl11BEFerjj4Wi+7109EVFlyc3Nx+fJlNG7c2GJeCZGjPOjvnLW/v9lDVE0U3mXGITMiIqLKVm0C0eLFiyEIgsUiVaIoYv78+QgMDISrqyt69OiBs2fPWrxPp9NhypQp8PHxgUqlwqBBg3Djxg2LMqmpqYiMjIRGo4FGo0FkZCTS0tIq4VtZzzypOjvPgOy8/DJKExERkT1Vi0B0/PhxrF69Gm3btrU4//7772P58uVYuXIljh8/Dn9/f/Tp0wcZGRlSmenTp2Pbtm3YsmULDh06hMzMTAwYMMBiBv6IESMQFxeHqKgoREVFIS4uDpGRkZX2/ayhUsjgIjf952AvERERUeWq8kCUmZmJkSNHYs2aNfD09JTOi6KIjz76CG+++SaGDh2K0NBQfPXVV8jOzsbXX38NANBqtVi7di2WLVuG8PBwtG/fHps2bcLp06elJc3j4+MRFRWFL774AmFhYQgLC8OaNWvw888/IyEhoUq+c2kEQYC3irfeExERVYUqD0STJk3C008/jfDwcIvzly9fRlJSEvr27SudUyqV6N69Ow4fPgzAtGKmXq+3KBMYGIjQ0FCpzJEjR6DRaCyWVe/SpQs0Go1UpjQ6nQ7p6ekWh6OZF2fkrfdEVBvwnh2qLPb4u1algWjLli04efIkFi9eXOKaeW2H4usl+Pn5SdeSkpKgUCgsepZKK+Pr61uifl9f3weuH7F48WJpzpFGo7FYWtxRuH0HEdUG5tWPs7OraENXqnPMf9eKr7xtiypbqfr69euYNm0adu3a9cDbMosv6/2g5cjvV8aapcGLmzt3LmbOnCm9Tk9Pd3go8pZ6iBiIiKjmkslkqFevHpKTkwGY1sQp699tovIQRRHZ2dlITk5GvXr1LPZls1WVBaLY2FgkJyejY8eO0jmDwYDffvsNK1eulOb3JCUlISAgQCqTnJws9Rr5+/sjLy8PqampFr1EycnJ6Nq1q1Tm9u3bJT7/zp07D1ytU6lUQqlUVuxL2oirVRNRbWHeid0ciogcqV69etLfufKqskDUu3fvEjvqvvDCC2jRogXmzJmDJk2awN/fH9HR0Wjfvj0AIC8vDwcOHMDSpUsBAB07doRcLkd0dDSGDRsGAEhMTMSZM2fw/vvvAzDtJKzVanHs2DE89thjAICjR49Cq9VKoam6MN96n5LFQERENZsgCAgICICvry/0en1VN4dqMblcXqGeIbMqC0RqtRqhoaEW51QqFby9vaXz06dPx6JFi9CsWTM0a9YMixYtgpubG0aMGAEA0Gg0GDduHGbNmgVvb294eXlh9uzZaNOmjTRJu2XLlujXrx/Gjx+Pzz//HAAwYcIEDBgwACEhIZX4jcsmTarO4JAZEdUOMpnMLr+siBytWu92/9prryEnJwcTJ05EamoqOnfujF27dkGtVktlVqxYAWdnZwwbNgw5OTno3bs31q9fb/EDuHnzZkydOlW6G23QoEEV3s/FEaRJ1dzPjIiIqFJxLzMrOXovMwD4Oykd/T46CC+VAiff7uOQzyAiIqpLuJdZDWTuIUrNzkO+wVjFrSEiIqo7GIiqEU83BQQBEEUgNZuTEImIiCoLA1E1InMS4OXGtYiIiIgqGwNRNVO4WjVvvSciIqosDETVjHm1at5pRkREVHkYiKoZ8+KMd7gWERERUaVhIKpmfKQeIg6ZERERVRYGompG2s+MPURERESVhoGommEPERERUeVjIKpmvFXmu8zYQ0RERFRZGIiqGfNdZnd52z0REVGlYSCqZqQ5RJk6cJs5IiKiysFAVM2YA5Eu34hMXX4Vt4aIiKhuYCCqZlwVMqgUMgBcrZqIiKiyMBBVQ+bFGblaNRERUeVgIKqGzBOr72Swh4iIiKgyMBBVQz7sISIiIqpUDETVkHlxxrvsISIiIqoUDETVEHuIiIiIKhcDUTXkrSrYvoN3mREREVUKBqJqyHyX2R1u30FERFQpGIiqIWnIjIGIiIioUjAQVUM+3M+MiIioUjEQVUPmHiJtjh55+cYqbg0REVHtx0BUDWlc5ZA5CQCA1Gz2EhERETkaA1E15OQkwEtlXq2a84iIiIgcjYGomipci4g9RERERI7GQFRNmSdW804zIiIix2MgqqbMPUR3GYiIiIgcjoGomuJq1URERJWHgaia4mrVRERElYeBqJoqnEPEHiIiIiJHYyCqprjjPRERUeVhIKqmvM3bd2Swh4iIiMjRGIiqqaI9RKIoVnFriIiIarcqDUSrVq1C27Zt4eHhAQ8PD4SFheHXX3+Vro8ZMwaCIFgcXbp0sahDp9NhypQp8PHxgUqlwqBBg3Djxg2LMqmpqYiMjIRGo4FGo0FkZCTS0tIq4yuWm3mlar1BRHpOfhW3hoiIqHar0kDUoEEDLFmyBCdOnMCJEyfQq1cvDB48GGfPnpXK9OvXD4mJidLxyy+/WNQxffp0bNu2DVu2bMGhQ4eQmZmJAQMGwGAwSGVGjBiBuLg4REVFISoqCnFxcYiMjKy071keLnIZ1C7OAIC7nEdERETkUM5V+eEDBw60eL1w4UKsWrUKMTExaN26NQBAqVTC39+/1PdrtVqsXbsWGzduRHh4OABg06ZNCAoKwu7duxEREYH4+HhERUUhJiYGnTt3BgCsWbMGYWFhSEhIQEhIiAO/YcX4uCuRkZuPlMw8PFy/qltDRERUe1WbOUQGgwFbtmxBVlYWwsLCpPP79++Hr68vmjdvjvHjxyM5OVm6FhsbC71ej759+0rnAgMDERoaisOHDwMAjhw5Ao1GI4UhAOjSpQs0Go1UpjQ6nQ7p6ekWR2UzL87I1aqJiIgcq8oD0enTp+Hu7g6lUomXX34Z27ZtQ6tWrQAA/fv3x+bNm7F3714sW7YMx48fR69evaDTmQJCUlISFAoFPD09Ler08/NDUlKSVMbX17fE5/r6+kplSrN48WJpzpFGo0FQUJC9vrLVpInVDEREREQOVaVDZgAQEhKCuLg4pKWl4bvvvsPo0aNx4MABtGrVCsOHD5fKhYaGolOnTggODsaOHTswdOjQ+9YpiiIEQZBeF31+vzLFzZ07FzNnzpRep6enV3ooMt96f4eLMxIRETmUTT1E+fn5WLBgAa5fv263BigUCjRt2hSdOnXC4sWL0a5dO3z88cellg0ICEBwcDDOnz8PAPD390deXh5SU1MtyiUnJ8PPz08qc/v27RJ13blzRypTGqVSKd39Zj4qG3uIiIiIKodNgcjZ2RkffPCBxR1c9iaKojQkVlxKSgquX7+OgIAAAEDHjh0hl8sRHR0tlUlMTMSZM2fQtWtXAEBYWBi0Wi2OHTsmlTl69Ci0Wq1Uprri9h1ERESVw+Y5ROHh4di/f79dPvyNN97AwYMHceXKFZw+fRpvvvkm9u/fj5EjRyIzMxOzZ8/GkSNHcOXKFezfvx8DBw6Ej48PnnnmGQCARqPBuHHjMGvWLOzZswenTp3CqFGj0KZNG+mus5YtW6Jfv34YP348YmJiEBMTg/Hjx2PAgAHV+g4zoHCDV06qJiIiciyb5xD1798fc+fOxZkzZ9CxY0eoVCqL64MGDbK6rtu3byMyMhKJiYnQaDRo27YtoqKi0KdPH+Tk5OD06dPYsGED0tLSEBAQgJ49e2Lr1q1Qq9VSHStWrICzszOGDRuGnJwc9O7dG+vXr4dMJpPKbN68GVOnTpXuRhs0aBBWrlxp61evdIWrVbOHiIiIyJEE0cZ9IZyc7t+pJAiCQ4fTqlJ6ejo0Gg20Wm2lzSe6eCcTvZcdgFrpjNMLIirlM4mIiGoTa39/29xDZDQaK9Qwsp65hyhDl49cvQEuclkZ7yAiIqLyqPJ1iOj+PFycIZeZlga4x2EzIiIihylXIDpw4AAGDhyIpk2bolmzZhg0aBAOHjxo77bVeYIgwFvFidVERESOZnMg2rRpE8LDw+Hm5oapU6di8uTJcHV1Re/evfH11187oo11mo+at94TERE5ms1ziBYuXIj3338fM2bMkM5NmzYNy5cvx7///W+MGDHCrg2s69hDRERE5Hg29xBdunSpxC71gOlW9suXL9ulUVTIR1qLiD1EREREjmJzIAoKCsKePXtKnN+zZ0+VbIBa2xWuVs0eIiIiIkexechs1qxZmDp1KuLi4tC1a1cIgoBDhw5h/fr1992DjMrPvMErh8yIiIgcx+ZA9Morr8Df3x/Lli3Df//7XwCm7TG2bt2KwYMH272BdR1XqyYiInI8mwJRfn4+Fi5ciLFjx+LQoUOOahMV4c05RERERA5X7Xa7J0veKg6ZEREROVqV7nZPZauvNvUQ3cvKg9Fo07ZzREREZKUq3e2eyuZV0ENkMIpIy9FLr4mIiMh+yjWpGgCWL19e4lpt3u2+qshlTqjnJkdath4pmToGIiIiIgewecjMaDTe92AYcozCeUScWE1EROQINgWi/Px8ODs748yZM45qD5Wi8E4zTqwmIiJyBJvvMgsODmZPUCWrb16LiIGIiIjIIWweMnvrrbcwd+5c3Lt3zxHtoVIUrlbNITMiIiJHsHlS9SeffIILFy4gMDAQwcHBJe4yO3nypN0aRyaFq1Wzh4iIiMgRbA5EQ4YMcUAz6EHYQ0RERORYNgeiefPmOaId9ADeKk6qJiIiciSr5xAdO3bMYjK1KFqumqzT6aTNXsm+6qtNPUQp7CEiIiJyCKsDUVhYGFJSUqTXGo0Gly5dkl6npaXhueees2/rCEBhDxHvMiMiInIMqwNR8R6h4q/vd44qzqdgP7OsPANy8rjkARERkb3ZfNv9gwiCYM/qqIBKIYPS2fSfivOIiIiI7M+ugYgcQxAE6dZ7BiIiIiL7s+kus7/++gtJSUkATMNjf//9NzIzMwEAd+/etX/rSOLjrsDNtBxOrCYiInIAmwJR7969LeYJDRgwAICpB0MURQ6ZOZA3F2ckIiJyGKsD0eXLlx3ZDiqDDxdnJCIichirA1FwcLAj20Fl4I73REREjsNJ1TWEt4o9RERERI7CQFRD1FdzcUYiIiJHYSCqIQpXq2YPERERkb0xENUQPmrzkBl7iIiIiOyNgaiGMPcQ3cvOg8HILVKIiIjsyaq7zNq3b2/1GkMnT56sUIOodJ5ucggCIIrAvaw8aU4RERERVZxVPURDhgzB4MGDMXjwYERERODixYtQKpXo0aMHevToARcXF1y8eBERERE2ffiqVavQtm1beHh4wMPDA2FhYfj111+l66IoYv78+QgMDISrqyt69OiBs2fPWtSh0+kwZcoU+Pj4QKVSYdCgQbhx44ZFmdTUVERGRkKj0UCj0SAyMhJpaWk2tbWqOcuc4OVmGjbj4oxERET2ZVUP0bx586TnL774IqZOnYp///vfJcpcv37dpg9v0KABlixZgqZNmwIAvvrqKwwePBinTp1C69at8f7772P58uVYv349mjdvjvfeew99+vRBQkIC1Go1AGD69OnYvn07tmzZAm9vb8yaNQsDBgxAbGwsZDIZAGDEiBG4ceMGoqKiAAATJkxAZGQktm/fblN7q5q3uwIpWXmcWE1ERGRvoo08PDzEc+fOlTh/7tw50cPDw9bqSvD09BS/+OIL0Wg0iv7+/uKSJUuka7m5uaJGoxE/++wzURRFMS0tTZTL5eKWLVukMjdv3hSdnJzEqKgoURRF8a+//hIBiDExMVKZI0eOiADEv//+2+p2abVaEYCo1Wor+hXL7V+fHxGD5/ws/nDqRpW1gYiIqCax9ve3zZOqXV1dcejQoRLnDx06BBcXl3IHM4PBgC1btiArKwthYWG4fPkykpKS0LdvX6mMUqlE9+7dcfjwYQBAbGws9Hq9RZnAwECEhoZKZY4cOQKNRoPOnTtLZbp06QKNRiOVKY1Op0N6errFUdV81ObVqtlDREREZE82be4KmIaoXnnlFcTGxqJLly4AgJiYGHz55Zd45513bG7A6dOnERYWhtzcXLi7u2Pbtm1o1aqVFFb8/Pwsyvv5+eHq1asAgKSkJCgUCnh6epYok5SUJJXx9fUt8bm+vr5SmdIsXrwYCxYssPn7OFLhatWcQ0RERGRPNgei119/HU2aNMHHH3+Mr7/+GgDQsmVLrF+/HsOGDbO5ASEhIYiLi0NaWhq+++47jB49GgcOHJCuF7+7TRTFMu94K16mtPJl1TN37lzMnDlTep2eno6goKAyv48jcbVqIiIix7A5EAHAsGHDyhV+SqNQKKRJ1Z06dcLx48fx8ccfY86cOQBMPTwBAQFS+eTkZKnXyN/fH3l5eUhNTbXoJUpOTkbXrl2lMrdv3y7xuXfu3CnR+1SUUqmEUlm9bm039xBxUjUREZF9lWthxrS0NHzxxRd44403cO/ePQCm9Ydu3rxZ4QaJogidTofGjRvD398f0dHR0rW8vDwcOHBACjsdO3aEXC63KJOYmIgzZ85IZcLCwqDVanHs2DGpzNGjR6HVaqUyNQV3vCciInIMm3uI/vzzT4SHh0Oj0eDKlSt48cUX4eXlhW3btuHq1avYsGGD1XW98cYb6N+/P4KCgpCRkYEtW7Zg//79iIqKgiAImD59OhYtWoRmzZqhWbNmWLRoEdzc3DBixAgAgEajwbhx4zBr1ix4e3vDy8sLs2fPRps2bRAeHg7ANJzXr18/jB8/Hp9//jkA0233AwYMQEhIiK1fv0r5uHPHeyIiIkewORDNnDkTY8aMwfvvvy+tBQQA/fv3l4KKtW7fvo3IyEgkJiZCo9Ggbdu2iIqKQp8+fQAAr732GnJycjBx4kSkpqaic+fO2LVrl8XnrlixAs7Ozhg2bBhycnLQu3dvrF+/XlqDCAA2b96MqVOnSnejDRo0CCtXrrT1q1c5n4IeopQsnVVzqYiIiMg6giiKNm2MpdFocPLkSTz88MNQq9X4448/0KRJE1y9ehUhISHIzc11VFurVHp6OjQaDbRaLTw8PKqkDdl5+Wj1zk4AwJkFEXBXlmsKGBERUZ1h7e9vm+cQubi4lLomT0JCAurXr29rdWQDN4Uz3BSmni/eaUZERGQ/NgeiwYMH491334VerwdguqX92rVreP311/Hss8/avYFkydudaxERERHZm82B6MMPP8SdO3fg6+uLnJwcdO/eHU2bNoVarcbChQsd0UYqwsedq1UTERHZm82TUDw8PHDo0CHs3bsXJ0+ehNFoRIcOHaS7usixvFXmxRkZiIiIiOzFpkCUn58PFxcXxMXFoVevXujVq5ej2kX3UV/NITMiIiJ7s2nIzNnZGcHBwTAYDI5qD5WhsIeIgYiIiMhebJ5D9NZbb2Hu3LnSCtVUuby5OCMREZHd2TyH6JNPPsGFCxcQGBiI4OBgqFQqi+snT560W+OoJB9u30FERGR3NgeiIUOGOKAZZC1zD1FKFnuIiIiI7MXmQDRv3jxHtIOsVJ89RERERHZXrt3uqeqYd7xPy9ZDbzBWcWuIiIhqB5sDkcFgwIcffojHHnsM/v7+8PLysjjIseq5yiFzMm3qeo/DZkRERHZhcyBasGABli9fjmHDhkGr1WLmzJkYOnQonJycMH/+fAc0kYpychLgpeJaRERERPZkcyDavHkz1qxZg9mzZ8PZ2RnPPfccvvjiC7zzzjuIiYlxRBupGO+CQMTVqomIiOzD5kCUlJSENm3aAADc3d2h1WoBAAMGDMCOHTvs2zoqVX01J1YTERHZk82BqEGDBkhMTAQANG3aFLt27QIAHD9+HEql0r6to1Kxh4iIiMi+bA5EzzzzDPbs2QMAmDZtGt5++200a9YMzz//PMaOHWv3BlJJ3rz1noiIyK5sXodoyZIl0vN//OMfaNCgAQ4fPoymTZti0KBBdm0cla5wtWr2EBEREdmDzYGouC5duqBLly72aAtZqXC1avYQERER2YPNgWjDhg0PvP7888+XuzFkHR933nZPRERkTzYHomnTplm81uv1yM7OhkKhgJubGwNRJTAPmXFSNRERkX3YPKk6NTXV4sjMzERCQgK6deuGb775xhFtpGK8iwQiURSruDVEREQ1n132MmvWrBmWLFlSoveIHMN8232ewYj03Pwqbg0REVHNZ7fNXWUyGW7dumWv6ugBXOQyqJWm0c4UziMiIiKqMJvnEP30008Wr0VRRGJiIlauXInHH3/cbg2jB/N2VyBDl4+7mXloUr+qW0NERFSz2RyIhgwZYvFaEATUr18fvXr1wrJly+zVLiqDj7sSV1Ky2UNERERkBzYHIqPR6Ih2kI3MaxHdzeKdZkRERBVltzlEVLmk1aoz2ENERERUUTb3EM2cOdPqssuXL7e1erKSdOs9V6smIiKqMJsD0alTp3Dy5Enk5+cjJCQEAHDu3DnIZDJ06NBBKicIgv1aSSVIq1VncMiMiIioomwORAMHDoRarcZXX30FT09PAKbFGl944QU88cQTmDVrlt0bSSX5sIeIiIjIbmyeQ7Rs2TIsXrxYCkMA4Onpiffee493mVUi8+KM3L6DiIio4mwOROnp6bh9+3aJ88nJycjIyLBLo6hsPmpTD9Ed3nZPRERUYTYHomeeeQYvvPAC/ve//+HGjRu4ceMG/ve//2HcuHEYOnSoI9pIpfBRmQJRRm4+dPmGKm4NERFRzWbzHKLPPvsMs2fPxqhRo6DX602VODtj3Lhx+OCDD+zeQCqdh6sz5DIBeoOIlMw8BNZzreomERER1Vg2ByI3Nzd8+umn+OCDD3Dx4kWIooimTZtCpVI5on10H4IgwFulRFJ6LgMRERFRBZV7YUaVSoW2bduiXr16uHr1arlWsF68eDEeffRRqNVq+Pr6YsiQIUhISLAoM2bMGAiCYHF06dLFooxOp8OUKVPg4+MDlUqFQYMG4caNGxZlUlNTERkZCY1GA41Gg8jISKSlpdnc5uqkcLVqziMiIiKqCKsD0VdffYWPPvrI4tyECRPQpEkTtGnTBqGhobh+/bpNH37gwAFMmjQJMTExiI6ORn5+Pvr27YusrCyLcv369UNiYqJ0/PLLLxbXp0+fjm3btmHLli04dOgQMjMzMWDAABgMhXNrRowYgbi4OERFRSEqKgpxcXGIjIy0qb3VDVerJiIisg+rh8w+++wzTJgwQXodFRWFdevWYcOGDWjZsiUmT56MBQsW4IsvvrD6w6Oioixer1u3Dr6+voiNjcWTTz4pnVcqlfD39y+1Dq1Wi7Vr12Ljxo0IDw8HAGzatAlBQUHYvXs3IiIiEB8fj6ioKMTExKBz584AgDVr1iAsLAwJCQnSApM1jbmHKIX7mREREVWI1T1E586dQ6dOnaTXP/74IwYNGoSRI0eiQ4cOWLRoEfbs2VOhxmi1WgCAl5eXxfn9+/fD19cXzZs3x/jx45GcnCxdi42NhV6vR9++faVzgYGBCA0NxeHDhwEAR44cgUajkcIQAHTp0gUajUYqU5xOp0N6errFUd1IizPy1nsiIqIKsToQ5eTkwMPDQ3p9+PBhi16cJk2aICkpqdwNEUURM2fORLdu3RAaGiqd79+/PzZv3oy9e/di2bJlOH78OHr16gWdzhQCkpKSoFAoLBaKBAA/Pz+pPUlJSfD19S3xmb6+vvdt8+LFi6X5RhqNBkFBQeX+bo4ibd/BxRmJiIgqxOohs+DgYMTGxiI4OBh3797F2bNn0a1bN+l6UlISNBpNuRsyefJk/Pnnnzh06JDF+eHDh0vPQ0ND0alTJwQHB2PHjh0PXPdIFEWL/dRK21uteJmi5s6da7GRbXp6erULRd4FaxHdZQ8RERFRhVgdiJ5//nlMmjQJZ8+exd69e9GiRQt07NhRun748GGLnh1bTJkyBT/99BN+++03NGjQ4IFlAwICEBwcjPPnzwMA/P39kZeXh9TUVIteouTkZHTt2lUqU9rq2nfu3IGfn1+pn6NUKqFUKsv1fSqLebVq9hARERFVjNVDZnPmzMGLL76I77//Hi4uLvj2228trv/+++947rnnbPpwURQxefJkfP/999i7dy8aN25c5ntSUlJw/fp1BAQEAAA6duwIuVyO6OhoqUxiYiLOnDkjBaKwsDBotVocO3ZMKnP06FFotVqpTE1UuJ8Ze4iIiIgqQhBFUayqD584cSK+/vpr/PjjjxZ3emk0Gri6uiIzMxPz58/Hs88+i4CAAFy5cgVvvPEGrl27hvj4eKjVagDAK6+8gp9//hnr16+Hl5cXZs+ejZSUFMTGxkImkwEwzUW6desWPv/8cwCmJQOCg4Oxfft2q9qanp4OjUYDrVZrMZeqKiVpc9Fl8R44Owk4915/ODmVPvxHRERUV1n7+9vmlartadWqVQCAHj16WJxft24dxowZA5lMhtOnT2PDhg1IS0tDQEAAevbsia1bt0phCABWrFgBZ2dnDBs2DDk5OejduzfWr18vhSEA2Lx5M6ZOnSrdjTZo0CCsXLnS8V/SgbwKeojyjSK0OXp4FrwmIiIi21RpD1FNUh17iACg3YJd0ObosXvmk2jqqy77DURERHWItb+/y711B1UP5sUZ72RwYjUREVF5MRDVcNLijNzPjIiIqNwYiGo48+KMKbz1noiIqNxsnlRtMBiwfv167NmzB8nJySV2ud+7d6/dGkdlkzZ45a33RERE5WZzIJo2bRrWr1+Pp59+GqGhofdd6ZkqR+Fq1ewhIiIiKi+bA9GWLVvw3//+F0899ZQj2kM28pb2M2MPERERUXnZPIdIoVCgadOmjmgLlQN3vCciIqo4mwPRrFmz8PHHH4PLF1UP0qTqLA6ZERERlZfNQ2aHDh3Cvn378Ouvv6J169aQy+UW17///nu7NY7KJk2qzmAPERERUXnZHIjq1auHZ555xhFtoXIwzyHKyjMgJ88AV4WsjHcQERFRcTYHonXr1jmiHVRO7kpnKJydkJdvxN1MHYK83Kq6SURERDUOF2as4QRBQH1ptWrOIyIiIiqPcu12/7///Q///e9/ce3aNeTlWf4SPnnypF0aRtbzdlfgZloO7zQjIiIqJ5t7iD755BO88MIL8PX1xalTp/DYY4/B29sbly5dQv/+/R3RRioDV6smIiKqGJsD0aefforVq1dj5cqVUCgUeO211xAdHY2pU6dCq9U6oo1UBm+VeXFGDpkRERGVh82B6Nq1a+jatSsAwNXVFRkZGQCAyMhIfPPNN/ZtHVnFW1qckYGIiIioPGwORP7+/khJSQEABAcHIyYmBgBw+fJlLtZYRXy4fQcREVGF2ByIevXqhe3btwMAxo0bhxkzZqBPnz4YPnw41yeqItL2HVkMREREROVh811mq1evhtFoBAC8/PLL8PLywqFDhzBw4EC8/PLLdm8gla1wtWoOmREREZWHzYHIyckJTk6FHUvDhg3DsGHD7Nooso23tJ8Ze4iIiIjKo1wLMx48eBCjRo1CWFgYbt68CQDYuHEjDh06ZNfGkXXMgeheVh4MRs7jIiIispXNgei7775DREQEXF1dcerUKeh0pl6JjIwMLFq0yO4NpLJ5uSkgCIBRBFKzOWxGRERkK5sD0XvvvYfPPvsMa9assdjpvmvXrlyluoo4y5zg6VYwbMZb74mIiGxmcyBKSEjAk08+WeK8h4cH0tLS7NEmKgfeek9ERFR+NgeigIAAXLhwocT5Q4cOoUmTJnZpFNnOW8XtO4iIiMrL5kD00ksvYdq0aTh69CgEQcCtW7ewefNmzJ49GxMnTnREG8kK0p1mHDIjIiKymc233b/22mvQarXo2bMncnNz8eSTT0KpVGL27NmYPHmyI9pIVuAGr0REROVncyACgIULF+LNN9/EX3/9BaPRiFatWsHd3d3ebSMb+LCHiIiIqNzKFYgAwM3NDZ06dbJnW6gCvNlDREREVG5WB6KxY8daVe7LL78sd2Oo/KQhsyz2EBEREdnK6kC0fv16BAcHo3379tzVvhoqnFTNHiIiIiJbWR2IXn75ZWzZsgWXLl3C2LFjMWrUKHh5eTmybWSD+kWGzERRhCAIVdwiIiKimsPq2+4//fRTJCYmYs6cOdi+fTuCgoIwbNgw7Ny5kz1G1YC5hyhXb0R2nqGKW0NERFSz2LQOkVKpxHPPPYfo6Gj89ddfaN26NSZOnIjg4GBkZmY6qo1kBTeFM1zlMgCcWE1ERGSrcu12DwCCIEAQBIiiCKPRaM82UTn5qM3bd3BiNRERkS1sCkQ6nQ7ffPMN+vTpg5CQEJw+fRorV67EtWvXyrUO0eLFi/Hoo49CrVbD19cXQ4YMQUJCgkUZURQxf/58BAYGwtXVFT169MDZs2dLtGvKlCnw8fGBSqXCoEGDcOPGDYsyqampiIyMhEajgUajQWRkZK3be828fQcnVhMREdnG6kA0ceJEBAQEYOnSpRgwYABu3LiBb7/9Fk899RScnMrX0XTgwAFMmjQJMTExiI6ORn5+Pvr27YusrCypzPvvv4/ly5dj5cqVOH78OPz9/dGnTx9kZGRIZaZPn45t27Zhy5YtOHToEDIzMzFgwAAYDIVzaUaMGIG4uDhERUUhKioKcXFxiIyMLFe7q6vC1arZQ0RERGQLQbRyRrSTkxMaNmyI9u3bP/AOpu+//77cjblz5w58fX1x4MABPPnkkxBFEYGBgZg+fTrmzJkDwNQb5Ofnh6VLl+Kll16CVqtF/fr1sXHjRgwfPhwAcOvWLQQFBeGXX35BREQE4uPj0apVK8TExKBz584AgJiYGISFheHvv/9GSEhImW1LT0+HRqOBVquFh4dHub+jI73+3Z/Ycvw6ZvVpjim9m1V1c4iIiKqctb+/rb7t/vnnn3f4rdxarRYApNv5L1++jKSkJPTt21cqo1Qq0b17dxw+fBgvvfQSYmNjodfrLcoEBgYiNDQUhw8fRkREBI4cOQKNRiOFIQDo0qULNBoNDh8+XGog0ul00OkKh57S09Pt/n3tTVqLiIszEhER2cSmhRkdSRRFzJw5E926dUNoaCgAICkpCQDg5+dnUdbPzw9Xr16VyigUCnh6epYoY35/UlISfH19S3ymr6+vVKa4xYsXY8GCBRX7UpXMPGR2h3OIiIiIbFLuu8zsbfLkyfjzzz/xzTfflLhWvGfKmoUHi5cprfyD6pk7dy60Wq10XL9+3ZqvUaXM+5lxUjUREZFtqkUgmjJlCn766Sfs27cPDRo0kM77+/sDQIlenOTkZKnXyN/fH3l5eUhNTX1gmdu3b5f43Dt37pTofTJTKpXw8PCwOKo78473nFRNRERkmyoNRKIoYvLkyfj++++xd+9eNG7c2OJ648aN4e/vj+joaOlcXl4eDhw4gK5duwIAOnbsCLlcblEmMTERZ86ckcqEhYVBq9Xi2LFjUpmjR49Cq9VKZWoDH/YQERERlYvVc4gcYdKkSfj666/x448/Qq1WSz1BGo0Grq6uEAQB06dPx6JFi9CsWTM0a9YMixYtgpubG0aMGCGVHTduHGbNmgVvb294eXlh9uzZaNOmDcLDwwEALVu2RL9+/TB+/Hh8/vnnAIAJEyZgwIABVt1h5lBnfwDitwN93gU0D1WoKm+VqYcoNVuPfIMRzrJq0QFIRERU7dn8G/O3335Dfn5+ifP5+fn47bffbKpr1apV0Gq16NGjBwICAqRj69atUpnXXnsN06dPx8SJE9GpUyfcvHkTu3btglqtlsqsWLECQ4YMwbBhw/D444/Dzc0N27dvh0wmk8ps3rwZbdq0Qd++fdG3b1+0bdsWGzdutPXr21/Mp8CZ/wEJv1S4Kk83BZwKpkTd451mREREVrN6HSIzmUyGxMTEEndtpaSkwNfX12IxxNrEYesQHfoI2D0PeLgXELmtwtV1em837mbq8MvUJ9AqsPrPeyIiInIka39/29xDdL87s1JSUqBSqWytjlo8bXq8fBDI1Va4usKJ1ZxHREREZC2r5xANHToUgOn29TFjxkCpVErXDAYD/vzzz1o1QbnS+DQDvJsBKeeB89FAm39UrDp3JYAMpGQxEBEREVnL6kCk0WgAmHqI1Go1XF1dpWsKhQJdunTB+PHj7d/CuqDFU8DvH5vmEVUwEEmrVfPWeyIiIqtZHYjWrVsHAGjUqBFmz57N4TF7ajHAFIjORwP5eYCzotxVcbVqIiIi29l82/28efMAmBY1TEhIgCAIaN68OerXr2/3xtUZD3UCVL5AVjJw5SDQtHe5q2IPERERke1snlSdnZ2NsWPHIiAgAE8++SSeeOIJBAYGYty4ccjOznZEG2s/JycgpJ/peQVvv/dRmXqIOKmaiIjIejYHohkzZuDAgQPYvn070tLSkJaWhh9//BEHDhzArFmzHNHGuiGk4G6zhF8B21ZCsOCjZg8RERGRrWweMvvuu+/wv//9Dz169JDOPfXUU3B1dcWwYcOwatUqe7av7mjSHZCrgPSbQGIcENi+XNV4q7h9BxERka3KNWRW2oaovr6+HDKrCLkr0LSX6fnf5R8281Gbh8zyYOOam0RERHWWzYEoLCwM8+bNQ25urnQuJycHCxYsQFhYmF0bV+eYh83+3lHuKsz7meUZjMjQldxihYiIiEqyecjs448/Rr9+/dCgQQO0a9cOgiAgLi4OLi4u2LlzpyPaWHc0jwAEGZB8Fki9Ang2srkKF7kM7kpnZOrykZKZBw8Xud2bSUREVNvY3EMUGhqK8+fPY/HixXjkkUfQtm1bLFmyBOfPn0fr1q0d0ca6w80LCC5Y7bsiw2bcvoOIiMgmNvcQAYCrqytXpXaUkKdMaxEl/AKETSxXFd7uSlxJyebEaiIiIivZ3EMEABcvXsSUKVMQHh6OPn36YOrUqbh48aK921Y3tXjK9Hj1dyD7XrmqMPcQ3eGt90RERFaxORDt3LkTrVq1wrFjx9C2bVuEhobi6NGjaN26NaKjox3RxrrFsxHg2xoQjcC58s3J8nbnrfdERES2sHnI7PXXX8eMGTOwZMmSEufnzJmDPn362K1xdVaLp0wTqxN2AI88Z/PbfVRcnJGIiMgWNvcQxcfHY9y4cSXOjx07Fn/99ZddGlXntSi4/f7CXkCf++CypShci4g9RERERNawORDVr18fcXFxJc7HxcXB19fXHm2igEcAj4cAfRZw+YDNby9crZo9RERERNawechs/PjxmDBhAi5duoSuXbtCEAQcOnQIS5cu5V5m9iIIQEh/4PgXwN8/m9YnsgFvuyciIrKNzYHo7bffhlqtxrJlyzB37lwAQGBgIObPn4+pU6favYF1VshTpkCUEAUYjYCT9Z155knVDERERETWsXnITBAEzJgxAzdu3IBWq4VWq8WNGzcwbdo03Lp1yxFtrJsaPQEoPYCsZODmCZveau4hSs/NR16+0RGtIyIiqlXKtQ6RmVqthlqtRlJSEqZMmYKmTZvaq13krACaFdyxZ+PeZhpXOZydBABAShZ7iYiIiMpidSBKS0vDyJEjUb9+fQQGBuKTTz6B0WjEO++8gyZNmiAmJgZffvmlI9ta94QULNJoYyASBAHe7rz1noiIyFpWzyF644038Ntvv2H06NGIiorCjBkzEBUVhdzcXPz666/o3r27I9tZNzXrAzjJgZTzwN3zgE8zq9/q467E7XQd7nAeERERUZms7iHasWMH1q1bhw8//BA//fQTRFFE8+bNsXfvXoYhR3HRAI26mZ7b2EtUuFo1e4iIiIjKYnUgunXrFlq1agUAaNKkCVxcXPDiiy86rGFUwLxIY8IvNr2tcLVq9hARERGVxepAZDQaIZfLpdcymQwqlcohjaIizPOIrh8DMpOtfhtXqyYiIrKe1XOIRFHEmDFjoFSaftHm5ubi5ZdfLhGKvv/+e/u2sK7TPGRauToxDkj4Feg42qq3eXM/MyIiIqtZHYhGj7b8RTxq1Ci7N4buo8XTBYHoF6sDkU/BHCJOqiYiIiqb1YFo3bp1jmwHPUiLp4F9C4FL+4G8LEBR9lAlb7snIiKyXoUWZqRK4tsKqBcM5OcCF/da9RZzDxEXZiQiIiobA1FNIAiFd5v9bd3dZj5Fbrs3GkVHtYyIiKhWYCCqKcx3m537FTDkl1ncq2BSdb5RRHqu3pEtIyIiqvEYiGqKhmGAqyeQkwpcjymzuMLZCR4upilidzmPiIiI6IEYiGoKmTPQvJ/pubXDZlyLiIiIyCoMRDWJedgsYQcglj0vyEfF7TuIiIisUaWB6LfffsPAgQMRGBgIQRDwww8/WFwfM2YMBEGwOLp06WJRRqfTYcqUKfDx8YFKpcKgQYNw48YNizKpqamIjIyERqOBRqNBZGQk0tLSHPztHODhXoBMCaReAZL/KrO4j9o0j4g9RERERA9WpYEoKysL7dq1w8qVK+9bpl+/fkhMTJSOX36xHC6aPn06tm3bhi1btuDQoUPIzMzEgAEDYDAYpDIjRoxAXFwcoqKiEBUVhbi4OERGRjrsezmM0h1o0sP03IphM2+ph4iBiIiI6EGsXpjREfr374/+/fs/sIxSqYS/v3+p17RaLdauXYuNGzciPDwcALBp0yYEBQVh9+7diIiIQHx8PKKiohATE4POnTsDANasWYOwsDAkJCQgJCTEvl/K0Vo8DZzfaRo26/7qA4uaF2e8m8UhMyIiogep9nOI9u/fD19fXzRv3hzjx49HcnLhBqexsbHQ6/Xo27evdC4wMBChoaE4fPgwAODIkSPQaDRSGAKALl26QKPRSGVKo9PpkJ6ebnFUCyH9AQjArVNA+q0HFjWvRXQ3gz1ERERED1KtA1H//v2xefNm7N27F8uWLcPx48fRq1cv6HSmX/BJSUlQKBTw9PS0eJ+fnx+SkpKkMr6+viXq9vX1lcqUZvHixdKcI41Gg6CgIDt+swpw9wUaPGp6nvDgYTMf8/Yd7CEiIiJ6oGodiIYPH46nn34aoaGhGDhwIH799VecO3cOO3bseOD7RFGEIAjS66LP71emuLlz50Kr1UrH9evXy/9F7K1Fwd1mfz/4z0HqIeIcIiIiogeq1oGouICAAAQHB+P8+fMAAH9/f+Tl5SE1NdWiXHJyMvz8/KQyt2/fLlHXnTt3pDKlUSqV8PDwsDiqjRYDTI+XDwK52vsW83bnbfdERETWqFGBKCUlBdevX0dAQAAAoGPHjpDL5YiOjpbKJCYm4syZM+jatSsAICwsDFqtFseOHZPKHD16FFqtVipT4/g0A7ybAUY9cGH3fYuZJ1Vn6vKRnVf2dh9ERER1VZUGoszMTMTFxSEuLg4AcPnyZcTFxeHatWvIzMzE7NmzceTIEVy5cgX79+/HwIED4ePjg2eeeQYAoNFoMG7cOMyaNQt79uzBqVOnMGrUKLRp00a666xly5bo168fxo8fj5iYGMTExGD8+PEYMGBAzbvDrChp2Oz+84jUSmfUL1it+pM9FyqjVURERDVSlQaiEydOoH379mjfvj0AYObMmWjfvj3eeecdyGQynD59GoMHD0bz5s0xevRoNG/eHEeOHIFarZbqWLFiBYYMGYJhw4bh8ccfh5ubG7Zv3w6ZTCaV2bx5M9q0aYO+ffuib9++aNu2LTZu3Fjp39euQp42PZ7fBeSXPiQmCAL+Pbg1AOCzAxexLyG51HJERER1nSCKVuwBQUhPT4dGo4FWq60e84mMBmBZCJB1B4jcZlrF+j7m/XgGXx25Ci+VAr9MfQL+GpdKbCgREVHVsfb3d42aQ0RFOMkK1iRCmatWz32qJVoHeuBeVh6mbjmFfIOxEhpIRERUczAQ1WTmYbOEXx+42auLXIaVIzpApZDh2OV7+GQv5xMREREVxUBUkzXpDsjdgPQbQOIfDyza2EeFRUPbAAD+s/c8fr9wtzJaSEREVCMwENVkctfCuUNlLNIIAIMfeQj/ejQIoghM2xKHO9zSg4iICAADUc1nXqSxjG08zOYNbI0QPzXuZuowY2scjEbOqSciImIgqumaRwCCDLh9Bki9UmZxV4UMK0e0h6tchkMX7mLVgYuObyMREVE1x0BU07l5AQ3DTM8TfrXqLc381Hi3YH2iZbsScOzyPUe1joiIqEZgIKoNrNzstah/dGyAoe0fglEEpn5zCveyuN8ZERHVXQxEtUFIQSC6ehjItq63RxAE/HtIKJrUVyEpPRezv/2D84mIiKjOYiCqDbwaA76tAdFg2srDSiqlM/5vRAconJ2w9+9krD102YGNJCIiqr4YiGqLcgybAUDLAA/MG9gKALA06m+cvJZq75YRERFVewxEtYV52OzCHkCfa9NbRzzWEE+3DUC+UcSUr09Bm613QAOJiIiqLwai2iKwPaAOBPRZwOUDNr1VEAQsHtoGDb3ccDMtB6999we45y8REdUlDES1hSCUe9gMADxc5Pi/ER0glwnYefY2Nhy5aucGEhERVV8MRLWJedjsXBRgtH1H+zYNNHjjqZYAgIU74nHmptaerSMiIqq2GIhqk0ZPAEoPIPM2cDO2XFWM6doIfVr5Ic9gxKSvTyIjl/OJiIio9mMgqk2cFUDTcNPzv38uVxWCIOCDf7TFQ/VccTUlG3O/P835REREVOsxENU2LZ42PVq52Wtp6rkp8J8R7eHsJODnPxOx5fh1OzWOiIioemIgqm2a9QGc5MDdc8DdC+WupkNDT7waEQIAmP/TWcQnpturhURERNUOA1Ft46IBGnUzPU+w/W6zosY/0QQ9QupDl2/E5K9PIkuXb4cGEhERVT8MRLWRedjs7/IPmwGAk5OAZf9sBz8PJS7eycI7P561Q+OIiIiqHwai2iikv+nx+lEgM7lCVXm7K/HJv9rDSQC+O3kD/4u9YYcGEhERVS8MRLWRpgEQ8AgA0bQmUQV1buKNGeHNAQBv/3AGF5IzKlwnERFRdcJAVFvZadjMbGLPpni8qTdy9AZM2nwKuXqDXeolIiKqDhiIaivzqtWX9gF5WRWuTuYkYMXwR+DjrkDC7Qws2P5XheskIiKqLhiIaiu/1kC9hkB+LnBxn12q9FW74KPh7SEIwDfHruGnP27ZpV4iIqKqxkBUWwkC0GKA6Xk5Nnu9n27NfDC5Z1MAwBvfn8aVuxXvfSIiIqpqDES1mXnYLGEHcGk/YKctOKb1bobHGnkhU5ePSV+fhC6f84mIiKhmYyCqzRqGAV5NgFwtsGEwsO4p4NKBCgcjZ5kTPn7uEXi6yXH2VjqeWx2D/9t3AUcvpXCyNRER1UiCyJ07rZKeng6NRgOtVgsPD4+qbo71Mm4DB5cBsesBg850LvhxoMfrQKMnTENr5bTv72S8uOEEDMbCv0IKmRPaNNDg0UZeeLSRJzoGe6Kem6KCX4KIiKh8rP39zUBkpRobiMzSbwGHVhQEozzTueDHgR5zgcZPlLvai3cy8du5Ozh+5R6OXU7F3UxdiTIhfmp0auSJxxp7oVMjLzxUz7Xcn0dERGQLBiI7q/GByEx7E/j9o2LBqBvQc27hHmjlJIoirqZk4/iVezh+5R5OXEnFpVImXT9UzxWdGnmiUyMvPNbIC8183eHkVP6eKiIiovthILKzWhOIzLQ3TT1GJ78qDEaNnigYSqtYMCrqbqYOJ67cw/ErqTh+5R7O3kq3GGIDAI2rHJ2CCwJSY0+EPqSB0llmtzYQEVHdxUBkZ7UuEJlpbxQEow3FgtFcoNHjdv+4LF0+4q6n4djlezhx9R5OXk1DTrGJ2EpnJ7QLqodHG3miU7AXGvuo4K9xgYucIYmIiGzDQGRntTYQmWlvAAeXm4KRUW861/hJUzAK7uqwj9UbjPjrVrrFMFtKVl6pZX3clXiongsC67lKR9HX3ioFhApMEiciotqHgcjOan0gMku7XthjZBGM3gCCwxz+8aIo4tLdLJwomKT9x4003EzNKdGLVBqlsxMeksKSS5HQZHoMYC8TEVGdUyMC0W+//YYPPvgAsbGxSExMxLZt2zBkyBDpuiiKWLBgAVavXo3U1FR07twZ//d//4fWrVtLZXQ6HWbPno1vvvkGOTk56N27Nz799FM0aNBAKpOamoqpU6fip59+AgAMGjQI//nPf1CvXj2r21pnApFZ2nXg0HLg5MYiwah7QY+R44NRUaIoIi1bj5tpObhlPrS5Fq+TM3RWLa/k464wBSWNKx7yNIUkXw8X+KqV8Ct4VCmdHf+liIioUtSIQPTrr7/i999/R4cOHfDss8+WCERLly7FwoULsX79ejRv3hzvvfcefvvtNyQkJECtVgMAXnnlFWzfvh3r16+Ht7c3Zs2ahXv37iE2NhYymak3oH///rhx4wZWr14NAJgwYQIaNWqE7du3W93WOheIzNKumYbSTm0qDEZNepiCUcMuVdq0ovLyjbidnosbqUVDUw5upuXiVlqO1b1MAKBSyKSQVBiWlPBVFznnoYRa6cwhOiKiaq5GBKKiBEGwCESiKCIwMBDTp0/HnDlzAJh6g/z8/LB06VK89NJL0Gq1qF+/PjZu3Ijhw4cDAG7duoWgoCD88ssviIiIQHx8PFq1aoWYmBh07twZABATE4OwsDD8/fffCAkJsap9dTYQmaVdMy3weGoTYMw3nWvSsyAYda7atllBFEVoc8y9TLkWPU3J6blIztAhOT0XWXnWr7TtIneCr9pFCkv1i/Qy+RYJUPXc5AxORERVxNrf39V2bODy5ctISkpC3759pXNKpRLdu3fH4cOH8dJLLyE2NhZ6vd6iTGBgIEJDQ3H48GFERETgyJEj0Gg0UhgCgC5dukCj0eDw4cP3DUQ6nQ46XeEig+np6Q74ljVIvYbAwI+BbjNNwShuM3Bpn+moFwz4NAO8mxYcDwPezQCPhwCn6rE7jCAIqOemQD03BVoHau5bLlOXXxiQCkJS0cfbBY8ZufnI1Rtx7V42rt3LfuBny2UCvFVK1Fcr4eOugI+7+bnlY313JTxc2etERFQVqm0gSkpKAgD4+flZnPfz88PVq1elMgqFAp6eniXKmN+flJQEX1/fEvX7+vpKZUqzePFiLFiwoELfoVbyDAYGfQI8MaswGKVdNR0XdluWdXYBvB42BSSLwNQUcPOqmvaXwV3pDPf67mhS3/2B5XLyDEjOMIelwqCUnJGL5HSddC0tWw+9QURSei6S0nPL/HyFzAk+7opSA1Pho+m6O4fsiIjsptoGIrPi/+CLoljmL4HiZUorX1Y9c+fOxcyZM6XX6enpCAoKsrbZtZ85GIXPB5LjgZQLBcdFIOU8cO8ykJ8LJJ81HcW5ehXrUWpqCk1eTQB59d/aw1UhQ7C3CsHeqgeW0+UbkJKZh7uZOtzJ0BV5zMOdYucycvORZzDiljYXt7RlhyelsxO8VQp4qhTwUing6Vb0UW4671Z4vZ6bnAteEhHdR7UNRP7+/gBMPTwBAQHS+eTkZKnXyN/fH3l5eUhNTbXoJUpOTkbXrl2lMrdv3y5R/507d0r0PhWlVCqhVCrt8l1qNTcv0wKOxRdxNOQD2mumgHT3vGVgSr8B5NwDbhwzHcVpggpDkndTQB0AqP0Bdz/TYw0ITGZKZ5l0+39ZcvUG3M0sCEsW4alYkMrQIVOXD12+9eHJzF3pDE+VHF4Fw4cPClCebgpoXOVQOFePYU8iIkeqtoGocePG8Pf3R3R0NNq3bw8AyMvLw4EDB7B06VIAQMeOHSGXyxEdHY1hw4YBABITE3HmzBm8//77AICwsDBotVocO3YMjz32GADg6NGj0Gq1UmgiB5A5m3p7vJoAzfpYXsvLBu5dtAxJd8+bepZytYD2uum4tL/0upUeheFIevQF3P0BtZ/p0d0XcPUEatCQkotchgaebmjg6VZm2Zw8U3i6l5WHe9l5SM3Kw72sPKRm5+Felt70uuB8anYeUrP1MBhFZOrykanLx/V7OVa3y00hg8ZVLh313MyPitLPu5rOq12cuUcdEdUYVRqIMjMzceHCBen15cuXERcXBy8vLzRs2BDTp0/HokWL0KxZMzRr1gyLFi2Cm5sbRowYAQDQaDQYN24cZs2aBW9vb3h5eWH27Nlo06YNwsPDAQAtW7ZEv379MH78eHz++ecATLfdDxgwwOo7zMjOFG6AfxvTUZQoAtn3igSl88C9S0DGbSAzyfSYnwPo0k1HyvkHf45MWRCY/EyPpYUolS/gogEUqhoVnlwVMgR5uSHIq+zwBABGo4iM3HxTYCojQJkf03L0pv8keQZk5xmQaENPFGD64/RwKQxKpQYnNznqFYSrouW4gCYRVbYqve1+//796NmzZ4nzo0ePxvr166WFGT///HOLhRlDQ0Olsrm5uXj11Vfx9ddfWyzMWHS+z71790oszLhy5UouzFjTiKIpCJkDUmYykJFUGJaKnstNs61uQWYKRi4epkdlwaP5kF57lHKu4Lms2na4lovBKCIjVw9tjulIyy54zNEjPUePtOw8i/NFy1m75tP9uMidUM9VUaQ3Sl742q2wF8riupsCKoWME82JyEKNW4eoumMgqmH0uUDm7cIjI6mUx2Qg6w4gVuyXt0SuKhmaXL0KhvPMvVS+hY81bEjPFrp8A7RScCojUOXooc02PaZl58FYgX+RnJ0EKSR5uMrh4WIauvMoGMLzcJHDo8hrtYtlGQYqotqHgcjOGIhqKVEE9NmmuUu56aZHXcGj+ZBeF79e8KjPKt9nO8lLhiSLxyLPFdYNjdV0RqOIzLx8U0DK1iMtJ6/gsTBEmV9ri17P1iPPYKzw5zsJgNqlMDw9KEyZrpcsw0noRNVLjV+YkahSCIJp/pBCBXgElq8Ogx7QZZiG6YqHpuwUU0+U1FtV8Dwn1bQVSvoN01EWhbr04OTmVdAbVa/g0ACuBY8yefm+TxVychIKgoccQTYsVSWKInL1RqTlmHqdUrP0SM/VIyM3H+k5BY+5emTk6pGek48MXcFjrh7pBWXyjSKMIqShP8D6iedFKZ2dioUm54LeqpIhS62UF5YteHRXcDI6UVVgD5GV2ENEdpWvMw3XZd4umP90u/TglHnbtJ5TecjdSoYkKTxp7n/etZ4pgFWTVcYrgzlQmQJSYUgqDFKWr83Pi17P1OXbpS2CULBAqNIZqoLDXSmDSmE656aUmc4pzNfM5WTS86LnuPYU1XXsISKqzpyVgKaB6XgQUTT1Pt0vLOWkFQzfpVkO8QGmoUB9NpBxqxwNFEwTxZXuhT1oiqLPVaY5U6VeK1auaPlqGrIEQYCrQgbXgo19y8NgFJFpDky5lj1QGUVeW4SsImErPde0qrkoQgpb9iCXCaZwVCRQmQOXOTipXSyfqxTOcHcpWUbp7MQ5VlRrMRARVWeCUDBJ2wPwaWrdewz5BUN2aYUhKafIc/P50s7lagt6pERApzUd9iR3KxKS1EV6qerd/7FoGWeFfdtjRzInAZqCu+DKQxRF6PKNUkjKKlgzKktnKPLcfL7gXF7huSydAVl5he/L1ZvmVOkNojTPyh7f0TJMyeDuIod7kd4pdcGjm9IZKoUMbgpTOXMoc1OYnrspZAxYVK0wEBHVNjJn09yi8u4Xp88tDEd5mUBelunQZxU+L3peep19/2soGJk391pl3Slf28zDgA8KTdI5j8LeKqXa9FzuWm3v7BMEAS5yGVzkMviqK15fvsGIrDxDkRBlCk1SsMrLtwhembp8ZOaazmfm5iPD/L7cfGTlme7ENBjFInOsKk7mJJgCUpHQZH5dNFC5K2UWr90UMrgoZHCTm167KmRwU8jgKjf18jFoUXkwEBGRJbmL6VDff2sbm4gioM8pGapyzb1YaQW9VWmWQ4DSuSI9VRUaBgQgOBWEJHNQci98LQ0PuhcEqNKeF3kvBNOSDUaD6VEUC58bDYBoLHhuLOWcoci1YudEo6mdqvoFq6/7mz7XRs4yJ2hcnaBxrfjkeqNRLOh9MiBTp0emzoDM3MIgVVqoyi7SY5WdZ7A4Z+69MhQsGGqv4UEzJwFSUHKVF4Qli9DkDDd58XOFYavk+5yLlJFBLqueQ79UMQxERORYgmBaNkDhBqB++eowGiyH9ywCVFrpQUqXAegyLXupRGPhSuc1icK9cIV1tX/hNjXqAMsV2F00DukBc3ISCpYYkAMo3xyrogxGEdl5hcN85qBkPidd05l6p4qeNw0HmlZPzylYRT27IGSZl14wipACmiPIZYJFiCoangqfm8KVm8LU62d+7qpwhouzk1TWpaAeF3lBMJOberh4p2HlYyAiourPSVaxYUCj0dSzZA5Huoz7PM8sGPLLLBKmigUrcxlBMPXkCDJT+wQn0+EkM50r+tzJqVhZ8/Xi7y94bswvXHVdX/C59zJNewA+iLNr4X5+pQUm80bJVbwoqMwiYNmP3mBEjt4UlMxhKUefL20/Yw5SpjCVX3C9aLAylS98b8H78gzI1htgKFg1VG8QoTfkIz03H4DOrt/BzEXuVBiYigQn03OnwgBVJFiZzjlZBixFyfdzaLF0DEREVPs5OZmGnZTuAOw0FFhZdBlF9vNLKrldTUbBc53WtNdf6hXT8UCCaT6Vs4tpXpbcpeC1a8Fzt2LXzK9dS3nfg8q6me6orKRfunKZE+QyJ3jYOWgBpknveQajRViy7KEqGraKlikIZEWCWm5+waO+sJ7cfCPy8gsXF83VGwuGFu0zX6s0ggC4OFsGLYsAVUqgcnGWQSl3gouzkxTClAXPlQVBTVnkmouzE5QFj87VfKiRgYiIqDpTqk1HWXcZ5mUX2ZYmyXJT5IzEwms59wCIhfOxcu45+AsIhUFK7lYsULlaBjKLcOVqGbKkMFYQ2pyLHEVfOyh8CYIApbNpXad6Dlo43mAULUOS3oBcfUGvl8U5g3QuN89Q5LoRufnFzxULXkWGFkURUrnK4OwklAxQzqYgpix4nNGnOdo2qFcp7SnRvir5VCIisi+FG+DV2HQ8SL7ONM8qP8d0R6E+27TUgj7HdOQXnLO4Vvx1TpHyOcXeW/DcaO7ZKBK+kOLgPwQAMmXJwOSsLAhTSlOgKut1qb1i9ztvvxAmcxKkxTgdKd9gRG6+sURYKj1kFS1TELj0BujyjdAVBLZcvanXS6c3XzdKZYr2euUbxYK5Xfdv29huZfz9dSAGIiKiusRZab87CB/EoC8lNGUXPOYWeV40dOUUO0q7lm0Kdfm5pnryc0yT5aXP1ZkO2HkNrQd5UFgy93I5FznnrDAFN2eF6bX5ucWjEpApipU3nyv6qLR5wVNnmRPcZU5wd3DwAkx3KOryCwOSOTzl6gsClflcwfXmfnZYc6KcGIiIiMj+ZHLT4VIJWx0Z9EUCUpGj+Ot8XWFP1v3KmF/fr1fMfM1Y5A62/ILQl5Pq+O9aGid5yQBl7hkzBylnZSnnipSVFXnP/crKFAU3EwgAhCI9Y8XPFT46CQJcAbgWvSYXADlKr8e16nYTYyAiIqKazRy+lJXYu2DItxwulHrCyhiGzM8B8vNMvVj5OsCQV8pj7gOumXvAijDqgTzHTb6uVKO+B5r2rpKPZiAiIiKylcwZkKkrN4SZiWLpISlfVyxU5RX2fBUNWtJR9HzR8kXrK3YeounzpUeUcq7Io7m9EAtellHGqeo2I2YgIiIiqkkEoXBoi+ymei8KQERERFQJGIiIiIiozmMgIiIiojqPgYiIiIjqPAYiIiIiqvMYiIiIiKjOYyAiIiKiOo+BiIiIiOo8BiIiIiKq8xiIiIiIqM5jICIiIqI6j4GIiIiI6jwGIiIiIqrzGIiIiIioznOu6gbUFKIoAgDS09OruCVERERkLfPvbfPv8fthILJSRkYGACAoKKiKW0JERES2ysjIgEajue91QSwrMhEAwGg04tatW1Cr1RAEoaqbY7X09HQEBQXh+vXr8PDwYP2VVHdNr78mt72m11+T217T66/Jba/p9TuyblEUkZGRgcDAQDg53X+mEHuIrOTk5IQGDRpUdTPKzcPDwyE/ILWh/prcdkfXX5PbXtPrr8ltr+n11+S21/T6HVX3g3qGzDipmoiIiOo8BiIiIiKq8xiIajmlUol58+ZBqVSy/kqsu6bXX5PbXtPrr8ltr+n11+S21/T6Hd12a3BSNREREdV57CEiIiKiOo+BiIiIiOo8BiIiIiKq8xiIiIiIqM5jIKqlfvvtNwwcOBCBgYEQBAE//PCD3epevHgxHn30UajVavj6+mLIkCFISEiwW/2rVq1C27ZtpQW6wsLC8Ouvv9qt/uIWL14MQRAwffp0u9Q3f/58CIJgcfj7+9ulbgC4efMmRo0aBW9vb7i5ueGRRx5BbGysXepu1KhRibYLgoBJkybZpf78/Hy89dZbaNy4MVxdXdGkSRO8++67MBqNdqk/IyMD06dPR3BwMFxdXdG1a1ccP368XHWV9TMkiiLmz5+PwMBAuLq6okePHjh79qzd6v/+++8REREBHx8fCIKAuLg4u7Vfr9djzpw5aNOmDVQqFQIDA/H888/j1q1bdmv//Pnz0aJFC6hUKnh6eiI8PBxHjx61S91FvfTSSxAEAR999JHd2j5mzJgSPwNdunSxW/0AEB8fj0GDBkGj0UCtVqNLly64du1ahesu7edXEAR88MEHdml7ZmYmJk+ejAYNGsDV1RUtW7bEqlWrrKrbmvpv376NMWPGIDAwEG5ubujXrx/Onz9vdf0VwUBUS2VlZaFdu3ZYuXKl3es+cOAAJk2ahJiYGERHRyM/Px99+/ZFVlaWXepv0KABlixZghMnTuDEiRPo1asXBg8ebNMvG2sdP34cq1evRtu2be1ab+vWrZGYmCgdp0+ftku9qampePzxxyGXy/Hrr7/ir7/+wrJly1CvXj271H/8+HGLdkdHRwMA/vnPf9ql/qVLl+Kzzz7DypUrER8fj/fffx8ffPAB/vOf/9il/hdffBHR0dHYuHEjTp8+jb59+yI8PBw3b960ua6yfobef/99LF++HCtXrsTx48fh7++PPn36SPseVrT+rKwsPP7441iyZInNbS+r/uzsbJw8eRJvv/02Tp48ie+//x7nzp3DoEGD7FI/ADRv3hwrV67E6dOncejQITRq1Ah9+/bFnTt3Kly32Q8//ICjR48iMDDQ6nZbW3+/fv0sfhZ++eUXu9V/8eJFdOvWDS1atMD+/fvxxx9/4O2334aLi0uF6y7a5sTERHz55ZcQBAHPPvusXdo+Y8YMREVFYdOmTYiPj8eMGTMwZcoU/PjjjxWuXxRFDBkyBJcuXcKPP/6IU6dOITg4GOHh4Xb7/fJAItV6AMRt27Y5rP7k5GQRgHjgwAGHfYanp6f4xRdf2LXOjIwMsVmzZmJ0dLTYvXt3cdq0aXapd968eWK7du3sUldxc+bMEbt16+aQukszbdo08eGHHxaNRqNd6nv66afFsWPHWpwbOnSoOGrUqArXnZ2dLcpkMvHnn3+2ON+uXTvxzTffrFDdxX+GjEaj6O/vLy5ZskQ6l5ubK2o0GvGzzz6rcP1FXb58WQQgnjp1yuZ6ranf7NixYyIA8erVqw6pX6vVigDE3bt326XuGzduiA899JB45swZMTg4WFyxYoVN9T6o/tGjR4uDBw8uV33W1D98+HC7/J235s998ODBYq9evexWf+vWrcV3333X4lyHDh3Et956q8L1JyQkiADEM2fOSOfy8/NFLy8vcc2aNTbXbyv2EFGFabVaAICXl5fd6zYYDNiyZQuysrIQFhZm17onTZqEp59+GuHh4XatFwDOnz+PwMBANG7cGP/6179w6dIlu9T7008/oVOnTvjnP/8JX19ftG/fHmvWrLFL3cXl5eVh06ZNGDt2rN02NO7WrRv27NmDc+fOAQD++OMPHDp0CE899VSF687Pz4fBYCjxf9murq44dOhQhesv6vLly0hKSkLfvn2lc0qlEt27d8fhw4ft+lmVRavVQhAEu/U2FpWXl4fVq1dDo9GgXbt2Fa7PaDQiMjISr776Klq3bm2HFpa0f/9++Pr6onnz5hg/fjySk5PtUq/RaMSOHTvQvHlzREREwNfXF507d7brtAaz27dvY8eOHRg3bpzd6uzWrRt++ukn3Lx5E6IoYt++fTh37hwiIiIqXLdOpwMAi59hmUwGhUJh95/h0jAQUYWIooiZM2eiW7duCA0NtVu9p0+fhru7O5RKJV5++WVs27YNrVq1slv9W7ZswcmTJ7F48WK71WnWuXNnbNiwATt37sSaNWuQlJSErl27IiUlpcJ1X7p0CatWrUKzZs2wc+dOvPzyy5g6dSo2bNhgh5Zb+uGHH5CWloYxY8bYrc45c+bgueeeQ4sWLSCXy9G+fXtMnz4dzz33XIXrVqvVCAsLw7///W/cunULBoMBmzZtwtGjR5GYmGiH1hdKSkoCAPj5+Vmc9/Pzk67VJLm5uXj99dcxYsQIu26s+fPPP8Pd3R0uLi5YsWIFoqOj4ePjU+F6ly5dCmdnZ0ydOtUOrSypf//+2Lx5M/bu3Ytly5bh+PHj6NWrl/QLuyKSk5ORmZmJJUuWoF+/fti1axeeeeYZDB06FAcOHLBD6wt99dVXUKvVGDp0qN3q/OSTT9CqVSs0aNAACoUC/fr1w6effopu3bpVuO4WLVogODgYc+fORWpqKvLy8rBkyRIkJSXZ/We4NNztnipk8uTJ+PPPP+2e3kNCQhAXF4e0tDR89913GD16NA4cOGCXUHT9+nVMmzYNu3btsmrM3lb9+/eXnrdp0wZhYWF4+OGH8dVXX2HmzJkVqttoNKJTp05YtGgRAKB9+/Y4e/YsVq1aheeff75CdRe3du1a9O/f3+b5GQ+ydetWbNq0CV9//TVat26NuLg4TJ8+HYGBgRg9enSF69+4cSPGjh2Lhx56CDKZDB06dMCIESNw8uRJO7S+pOI9Z6Io2q03rbLo9Xr861//gtFoxKeffmrXunv27Im4uDjcvXsXa9aswbBhw3D06FH4+vqWu87Y2Fh8/PHHOHnypMP+rIcPHy49Dw0NRadOnRAcHIwdO3ZUOFyYbyAYPHgwZsyYAQB45JFHcPjwYXz22Wfo3r17heov6ssvv8TIkSPt+u/cJ598gpiYGPz0008IDg7Gb7/9hokTJyIgIKDCve1yuRzfffcdxo0bBy8vL8hkMoSHh1v8m+pI7CGicpsyZQp++ukn7Nu3Dw0aNLBr3QqFAk2bNkWnTp2wePFitGvXDh9//LFd6o6NjUVycjI6duwIZ2dnODs748CBA/jkk0/g7OwMg8Fgl88xU6lUaNOmjV3ulAgICCgRClu2bGnV3Sm2uHr1Knbv3o0XX3zRrvW++uqreP311/Gvf/0Lbdq0QWRkJGbMmGG3nrqHH34YBw4cQGZmJq5fv45jx45Br9ejcePGdqnfzHzXYPHeoOTk5BK9RtWZXq/HsGHDcPnyZURHR9u1dwgw/d1v2rQpunTpgrVr18LZ2Rlr166tUJ0HDx5EcnIyGjZsKP38Xr16FbNmzUKjRo3s0/BiAgICEBwcbJefYR8fHzg7Ozv85/jgwYNISEiw689wTk4O3njjDSxfvhwDBw5E27ZtMXnyZAwfPhwffvihXT6jY8eO0v8MJyYmIioqCikpKXb/GS4NAxHZTBRFTJ48Gd9//z327t1bKX9RRVG0S3c1APTu3RunT59GXFycdHTq1AkjR45EXFwcZDKZXT7HTKfTIT4+HgEBARWu6/HHHy+xxMG5c+cQHBxc4bqLWrduHXx9ffH000/btd7s7Gw4OVn+syOTyex2272ZSqVCQEAAUlNTsXPnTgwePNiu9Tdu3Bj+/v7SXXiAaZ7MgQMH0LVrV7t+lqOYw9D58+exe/dueHt7O/wz7fFzHBkZiT///NPi5zcwMBCvvvoqdu7caaeWWkpJScH169ft8jOsUCjw6KOPOvzneO3atejYsaNd5myZ6fV66PX6SvkZ1mg0qF+/Ps6fP48TJ07Y/We4NBwyq6UyMzNx4cIF6fXly5cRFxcHLy8vNGzYsEJ1T5o0CV9//TV+/PFHqNVq6f+SNRoNXF1dK1Q3ALzxxhvo378/goKCkJGRgS1btmD//v2IioqqcN2Aaa5J8flOKpUK3t7edpkHNXv2bAwcOBANGzZEcnIy3nvvPaSnp9tlSGjGjBno2rUrFi1ahGHDhuHYsWNYvXo1Vq9eXeG6zYxGI9atW4fRo0fD2dm+/0QMHDgQCxcuRMOGDdG6dWucOnUKy5cvx9ixY+1S/86dOyGKIkJCQnDhwgW8+uqrCAkJwQsvvGBzXWX9DE2fPh2LFi1Cs2bN0KxZMyxatAhubm4YMWKEXeq/d+8erl27Jq0NZP4F6u/vb9W6Vg+qPzAwEP/4xz9w8uRJ/PzzzzAYDNLPsZeXFxQKRYXq9/b2xsKFCzFo0CAEBAQgJSUFn376KW7cuGHVEg5l/dkUD29yuRz+/v4ICQkps+6y6vfy8sL8+fPx7LPPIiAgAFeuXMEbb7wBHx8fPPPMMxWuv2HDhnj11VcxfPhwPPnkk+jZsyeioqKwfft27N+/v8J1A0B6ejq+/fZbLFu2zKr22lJ/9+7d8eqrr8LV1RXBwcE4cOAANmzYgOXLl9ul/m+//Rb169dHw4YNcfr0aUybNg1DhgyxuIHBYRx+HxtViX379okAShyjR4+ucN2l1QtAXLduXYXrFkVRHDt2rBgcHCwqFAqxfv36Yu/evcVdu3bZpe77sedt98OHDxcDAgJEuVwuBgYGikOHDhXPnj1rl7pFURS3b98uhoaGikqlUmzRooW4evVqu9UtiqK4c+dOEYCYkJBg13pFURTT09PFadOmiQ0bNhRdXFzEJk2aiG+++aao0+nsUv/WrVvFJk2aiAqFQvT39xcnTZokpqWllauusn6GjEajOG/ePNHf319UKpXik08+KZ4+fdpu9a9bt67U6/Pmzatw/eZb+Us79u3bV+H6c3JyxGeeeUYMDAwUFQqFGBAQIA4aNEg8duyYXf5sirP1tvsH1Z+dnS327dtXrF+/viiXy8WGDRuKo0ePFq9du2aX+s3Wrl0rNm3aVHRxcRHbtWsn/vDDD3ar+/PPPxddXV3L9Xe/rPoTExPFMWPGiIGBgaKLi4sYEhIiLlu2zOqlOcqq/+OPPxYbNGgg/dm/9dZbdvv3oSyCKIpiudMUERERUS3AOURERERU5zEQERERUZ3HQERERER1HgMRERER1XkMRERERFTnMRARERFRncdARERERHUeAxERERHVeQxERERWEgQBP/zwQ1U3g4gcgIGIiGqEMWPGQBCEEke/fv2qumlEVAtwc1ciqjH69euHdevWWZxTKpVV1Boiqk3YQ0RENYZSqZR2ezcfnp6eAEzDWatWrUL//v3h6uqKxo0b49tvv7V4/+nTp9GrVy+4urrC29sbEyZMQGZmpkWZL7/8Eq1bt4ZSqURAQAAmT55scf3u3bt45pln4ObmhmbNmuGnn36SrqWmpmLkyJGoX78+XF1d0axZsxIBjoiqJwYiIqo13n77bTz77LP4448/MGrUKDz33HOIj48HAGRnZ6Nfv37w9PTE8ePH8e2332L37t0WgWfVqlWYNGkSJkyYgNOnT+Onn35C06ZNLT5jwYIFGDZsGP7880889dRTGDlyJO7duyd9/l9//YVff/0V8fHxWLVqFXx8fCrvD4CIyk8kIqoBRo8eLcpkMlGlUlkc7777riiKoghAfPnlly3e07lzZ/GVV14RRVEUV69eLXp6eoqZmZnS9R07dohOTk5iUlKSKIqiGBgYKL755pv3bQMA8a233pJeZ2ZmioIgiL/++qsoiqI4cOBA8YUXXrDPFyaiSsU5RERUY/Ts2ROrVq2yOOfl5SU9DwsLs7gWFhaGuLg4AEB8fDzatWsHlUolXX/88cdhNBqRkJAAQRBw69Yt9O7d+4FtaNu2rfRcpVJBrVYjOTkZAPDKK6/g2WefxcmTJ9G3b18MGTIEXbt2Ldd3JaLKxUBERDWGSqUqMYRVFkEQAACiKErPSyvj6upqVX1yubzEe41GIwCgf//+uHr1Knbs2IHdu3ejd+/emDRpEj788EOb2kxElY9ziIio1oiJiSnxukWLFgCAVq1aIS4uDllZWdL133//HU5OTmjevDnUajUaNWqEPXv2VKgN9evXx5gxY7Bp0yZ89NFHWL16dYXqI6LKwR4iIqoxdDodkpKSLM45OztLE5e//fZbdOrUCd26dcPmzZtx7NgxrF27FgAwcuRIzJs3D6NHj8b8+fNx584dTJkyBZGRkfDz8wMAzJ8/Hy+//DJ8fX3Rv39/ZGRk4Pfff8eUKVOsat8777yDjh07onXr1tDpdPj555/RsmVLO/4JEJGjMBARUY0RFRWFgIAAi3MhISH4+++/AZjuANuyZQsmTpwIf39/bN68Ga1atQIAuLm5YefOnZg2bRoeffRRuLm54dlnn8Xy5culukaPHo3c3FysWLECs2fPho+PD/7xj39Y3T6FQoG5c+fiypUrcHV1xRNPPIEtW7bY4ZsTkaMJoiiKVd0IIqKKEgQB27Ztw5AhQ6q6KURUA3EOEREREdV5DERERERU53EOERHVChz9J6KKYA8RERER1XkMRERERFTnMRARERFRncdARERERHUeAxERERHVeQxEREREVOcxEBEREVGdx0BEREREdd7/Aw4aJqRFh3RuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.Figure(figsize=(14,6), dpi=100)\n",
    "\n",
    "plt.plot(root_metrics_df[\"rmse\"], label = 'Training error')\n",
    "plt.plot(root_metrics_df[\"val_rmse\"], label = 'Validation error')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "# plt.xlim([0, epochs])\n",
    "plt.xticks(range(1,20))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  686.3221619890909\n",
      "MAE:  382.1221505234525\n"
     ]
    }
   ],
   "source": [
    "# Report regression performance on test set\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** In this workshop notebook, you learned how to use the keras framework for both classifcation and regression prediction. The classification example above was for a binary output (cancer cells being benign or malignant). Now we would like to employ neural network for multi-class classification on the flower example.\n",
    "\n",
    "1. Use the `../data/iris.csv` data set and preproccess it as usual\n",
    "2. Think of an architecture you would employ to enable multi-class classification. You can get some inspiration here: https://keras.io/guides/sequential_model/\n",
    "3. Implement a pipeline that consists of the following:\n",
    "    1. Train the model on training data set\n",
    "    3. Evaluate and visualize loss on training and validation set throughout the fitting of the network\n",
    "    4. [optional] Visualize classification along relevant dimensions\n",
    "4. Use that pipeline to test different architectures / hyperparameters\n",
    "5. Give a reasoning for complexity vs. performance of your final model - is this the best overall model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
